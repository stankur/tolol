
const content: Record<
	string,
	{ index: string; half: string; quarter: string }
> = {
	"": {
		index: `Before you go anywhere else, let me tell you what the heck this whole thing is. This is an experiment I am doing to address a specific problem I have in mind.

If  I invited you here,  I think you enjoy reading because you think new concepts are interesting. Especially if they enhance your understanding of the world through some particular lens, perhaps business, science, or economics.

My problem with reading is that sometimes I go through a book, and I miss the points that the author is trying to make. So, I just read through the book paragraph by paragraph, and I suddenly realize, how the heck did the author get here. Some people call this “Reading with the eyes, and not the brain“.

Authors have the points they want to make in their mind, but they don’t always convey them explicitly. They try to elaborate, add details here and there. That is perhaps why I think it is easy to get lost. It is easy to read a book front to end, but get very little out of it.

I think it is unfortunate that we could get a glimpse of the minds of brilliant people like **Nikola Tesla** (*My Inventions: The Autobiography of Nikola Tesla*), **Reid Hoffman** (*Blitzscaling: The Lightning-Fast Path to Building Massively Valuable Companies*), **Peter Thiel** (*Zero to One: Notes on Startups, or How to Build the Future*), **Daniel kahneman** (*Thinking, Fast and Slow*), but gain very little from that view.

My proposed solution is a tool where you can control how “summarized“ the content you are reading is. If you feel like you forget what is the context that got the author yapping about the small details that you are currently reading, you could pull a slider, and it will summarize the current paragraph, along with its relevant neighbors that are still talking about the same topic.

So, if you get lost in the small details, you have the power to “zoom out“ just a bit. If you are afraid of the cognitively impenetrable wall of text, you can zoom out as much as you want until you feel comfortable.

My solution is probably not perfect. It might even be addressing the problem in the wrong way. That is a valid concern. In fact, I think all the existing solutions are not addressing the problem properly. For instance, Blinkist. No matter how complex, how information dense the book is, it will shrink it down to 15 minutes. You are only presented with two options, either a summary that is way too basic, or a scary wall of text that goes through every small details.

Now go to **demo** in the left sidebar. Sorry that this whole thing is just very scrappy. I feel somewhat embarrassed because it is so buggy, but heck, I’d rather be embarrassed now then spend a significant portion of time addressing things wrongly. So you should be critical about my approach. Saying that the problem is too hard and I should stop is not acceptable, but arguing  possibly better alternatives than what I have in mind, or how my idea could be improved are more than welcome.`,
		half: `Before you go anywhere else, let me tell you what this whole thing is. It’s an experiment I'm running to tackle a problem I face with reading. If I've invited you here, I believe you enjoy reading and find new concepts interesting, especially those that enhance your understanding of fields like business, science, or economics. My issue is that I sometimes read books and miss the key points the authors are making, often getting lost in the details they add. This phenomenon is sometimes called “Reading with the eyes, and not the brain.” Despite having the opportunity to glimpse the minds of brilliant individuals like Nikola Tesla, Reid Hoffman, Peter Thiel, and Daniel Kahneman, I often end up gaining very little from their works.

My proposed solution is a tool allowing you to control the degree of summarization of the content you're reading. If you lose track of the context amid the small details, a slider can summarize the current paragraph and its relevant neighbors, helping you "zoom out" a bit to reorient yourself. If faced with an overwhelming wall of text, you can zoom out as much as needed until you feel comfortable. While my solution might not be perfect and could be addressing the issue incorrectly, existing tools like Blinkist aren't solving the problem adequately either, as they overly condense content regardless of its complexity. Please check the demo in the left sidebar. Apologies for its scrappiness and bugs—I'd rather be embarrassed now than invest time in incorrect solutions. Criticism and improvements are welcome, but simply dismissing the problem as too difficult isn't helpful.`,
		quarter: `Before you go anywhere else, let me explain what this is. It’s an experiment I’m running to address a problem I face with reading. If you’re here, I believe you enjoy reading and exploring new concepts, especially in business, science, or economics. My problem is that I often miss the key points in books, getting lost in the details—a phenomenon I call “Reading with the eyes, and not the brain.” Despite reading works by brilliant minds like Tesla, Hoffman, Thiel, and Kahneman, I often gain little from them. My solution is a tool that allows you to control the degree of summarization of the content you're reading. If you get lost in details, a slider can help summarize the current paragraph and its context, letting you "zoom out" as needed. This approach, unlike existing tools like Blinkist, which overly condense content, aims to help you better reorient yourself. Please check the demo in the left sidebar. It’s scrappy and buggy, but I'd rather be embarrassed now than spend time on incorrect solutions. Criticism and suggestions for improvement are welcome, but dismissing the problem as too difficult isn’t helpful.
`,
	},

	demo: {
		index: `### There are only two controls.

Left sidebar for finding pages, where you can click on **+** or **-** to expand or collapse pages, if they have sub-pages.

“Detail Level“ slider on top for controlling how summarized the content is. It has **3** levels. The leftmost part of the range is “heavily“ summarized, and the rightmost part is just the original text.

Some pages (*like this one*) would not have **level 1** and **level 2**. Just because I think it is too short in the first place to summarize.

Below this page, I give you some example where the “Detail Level“ sliders actually work. And the examples are from different books.`,
		half: `### There are only two controls.

Left sidebar for finding pages, where you can click on **+** or **-** to expand or collapse pages, if they have sub-pages.

“Detail Level“ slider on top for controlling how summarized the content is. It has **3** levels. The leftmost part of the range is “heavily“ summarized, and the rightmost part is just the original text.

Some pages (*like this one*) would not have **level 1** and **level 2**. Just because I think it is too short in the first place to summarize.

Below this page, I give you some example where the “Detail Level“ sliders actually work. And the examples are from different books.`,
		quarter: `### There are only two controls.

Left sidebar for finding pages, where you can click on **+** or **-** to expand or collapse pages, if they have sub-pages.

“Detail Level“ slider on top for controlling how summarized the content is. It has **3** levels. The leftmost part of the range is “heavily“ summarized, and the rightmost part is just the original text.

Some pages (*like this one*) would not have **level 1** and **level 2**. Just because I think it is too short in the first place to summarize.

Below this page, I give you some example where the “Detail Level“ sliders actually work. And the examples are from different books.`,
	},
	"demo/paul_graham": {
		index: `Under this page, I offer you to see the writings of Paul Graham. I am going to show you a copy of who this guy is from Wikipedia.

**Paul Graham** ([/ɡræm/](https://en.wikipedia.org/wiki/Help:IPA/English "Help:IPA/English"); born November 13, 1964)[\[3\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-DOB_LibCongress-3) is an English-American [computer scientist](https://en.wikipedia.org/wiki/Computer_scientist "Computer scientist"), writer, entrepreneur and investor. His work has included the programming language [Arc](https://en.wikipedia.org/wiki/Arc_\(programming_language\) "Arc (programming language)"), the startup [Viaweb](https://en.wikipedia.org/wiki/Viaweb "Viaweb") (later renamed *Yahoo! Store*), co-founding the [startup accelerator](https://en.wikipedia.org/wiki/Startup_accelerator "Startup accelerator") and seed capital firm [Y Combinator](https://en.wikipedia.org/wiki/Y_Combinator "Y Combinator"), his essays, and [Hacker News](https://en.wikipedia.org/wiki/Hacker_News "Hacker News").

He is the author of the computer programming books *[On Lisp](https://en.wikipedia.org/wiki/On_Lisp "On Lisp")*,[\[4\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-onlisp-4) *ANSI Common Lisp*,[\[5\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-ansi-5) and *[Hackers & Painters](https://en.wikipedia.org/wiki/Hackers_%26_Painters "Hackers & Painters")*.[\[6\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-hackersandpainters-6) Technology journalist [Steven Levy](https://en.wikipedia.org/wiki/Steven_Levy "Steven Levy") has described Graham as a "hacker philosopher".[\[7\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-7)

Graham was born in England, where he and his family have maintained a permanent residence since 2016. He is also a citizen of the United States, where he attended all of his schooling and lived for 48 years prior to returning to England.

## Education and early life

Graham and his family moved to [Pittsburgh](https://en.wikipedia.org/wiki/Pittsburgh "Pittsburgh"), [Pennsylvania](https://en.wikipedia.org/wiki/Pennsylvania "Pennsylvania") in 1968, where he later attended [Gateway High School](https://en.wikipedia.org/wiki/Gateway_High_School_\(Pennsylvania\) "Gateway High School (Pennsylvania)"). Graham gained interest in science and mathematics from his father who was a [nuclear physicist](https://en.wikipedia.org/wiki/Nuclear_physicist "Nuclear physicist").[\[8\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-early_interest-8)

Graham received a [Bachelor of Arts](https://en.wikipedia.org/wiki/Bachelor_of_Arts "Bachelor of Arts") with a major in [philosophy](https://en.wikipedia.org/wiki/Philosophy "Philosophy") from [Cornell University](https://en.wikipedia.org/wiki/Cornell_University "Cornell University") in 1986.[\[9\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-bio-9)[\[10\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-10)[\[11\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-11) He then received a [Master of Science](https://en.wikipedia.org/wiki/Master_of_Science "Master of Science") in 1988, and a [Doctor of Philosophy](https://en.wikipedia.org/wiki/Doctor_of_Philosophy "Doctor of Philosophy") in 1990, both in [computer science](https://en.wikipedia.org/wiki/Computer_science "Computer science") from [Harvard University](https://en.wikipedia.org/wiki/Harvard_University "Harvard University").[\[9\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-bio-9)[\[12\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-SpeakerMix_bio-12)

Graham has also studied painting at the [Rhode Island School of Design](https://en.wikipedia.org/wiki/Rhode_Island_School_of_Design "Rhode Island School of Design") and at the [Accademia di Belle Arti](https://en.wikipedia.org/wiki/Accademia_di_Belle_Arti_Firenze "Accademia di Belle Arti Firenze") in [Florence](https://en.wikipedia.org/wiki/Florence "Florence").[\[9\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-bio-9)[\[12\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-SpeakerMix_bio-12)

## Career\[[edit](https://en.wikipedia.org/w/index.php?title=Paul_Graham_\(programmer\)&action=edit&section=2 "Edit section: Career")\]

In 1996, Graham and [Robert Morris](https://en.wikipedia.org/wiki/Robert_Tappan_Morris "Robert Tappan Morris") founded [Viaweb](https://en.wikipedia.org/wiki/Viaweb "Viaweb") and recruited [Trevor Blackwell](https://en.wikipedia.org/wiki/Trevor_Blackwell "Trevor Blackwell") shortly after. They believed that Viaweb was the first [application service provider](https://en.wikipedia.org/wiki/Application_service_provider "Application service provider").[\[13\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-13) Graham received a patent for webapps based on his work at Viaweb.[\[14\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-14) Viaweb's software, written mostly in [Common Lisp](https://en.wikipedia.org/wiki/Common_Lisp "Common Lisp"), allowed users to make their own [Internet stores](https://en.wikipedia.org/wiki/Internet_store "Internet store"). In the summer of 1998, after [Jerry Yang](https://en.wikipedia.org/wiki/Jerry_Yang "Jerry Yang") received a strong recommendation from [Ali Partovi](https://en.wikipedia.org/wiki/Ali_Partovi "Ali Partovi"),[\[15\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-15) Viaweb was sold to [Yahoo!](https://en.wikipedia.org/wiki/Yahoo! "Yahoo!") for 455,000 shares of Yahoo! stock, valued at $49.6 million.[\[16\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-16) After the acquisition, the product became [Yahoo! Store](https://en.wikipedia.org/wiki/Yahoo!_Store "Yahoo! Store").

Graham later gained notice for his essays, which he posts on his personal website. Essay subjects range from *Beating the Averages*,[\[17\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-17) which compares Lisp to other [programming languages](https://en.wikipedia.org/wiki/Programming_language "Programming language") and introduced the hypothetical programming language *Blub*, to *Why Nerds are Unpopular*,[\[18\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-18) a discussion of [nerd](https://en.wikipedia.org/wiki/Nerd "Nerd") life in high school. A collection of his essays has been published as *[Hackers & Painters](https://en.wikipedia.org/wiki/Hackers_%26_Painters "Hackers & Painters")*[\[6\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-hackersandpainters-6) by [O'Reilly Media](https://en.wikipedia.org/wiki/O%27Reilly_Media "O'Reilly Media"), which includes a discussion of the growth of Viaweb and the advantages of Lisp to program it.

In 2001, Graham announced that he was working on a new [dialect](https://en.wikipedia.org/wiki/Dialect_\(computing\) "Dialect (computing)") of Lisp named [Arc](https://en.wikipedia.org/wiki/Arc_\(programming_language\) "Arc (programming language)"). It was released on 29 January 2008.[\[19\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-19) Over the years since, he has written several essays describing features or goals of the language, and some internal projects at Y Combinator have been written in Arc, including the Hacker News web forum and news aggregator program.

In 2005, after giving a talk at the [Harvard Computer Society](https://en.wikipedia.org/w/index.php?title=Harvard_Computer_Society&action=edit&redlink=1 "Harvard Computer Society (page does not exist)") later published as *How to Start a Startup*, Graham along with [Trevor Blackwell](https://en.wikipedia.org/wiki/Trevor_Blackwell "Trevor Blackwell"), [Jessica Livingston](https://en.wikipedia.org/wiki/Jessica_Livingston "Jessica Livingston"), and [Robert Morris](https://en.wikipedia.org/wiki/Robert_Tappan_Morris "Robert Tappan Morris") started [Y Combinator](https://en.wikipedia.org/wiki/Y_Combinator "Y Combinator") to provide [seed funding](https://en.wikipedia.org/wiki/Seed_funding "Seed funding") to [startups](https://en.wikipedia.org/wiki/Startup_company "Startup company"), particularly those started by younger, more technically oriented founders. Y Combinator has invested in more than 1300 startups, including [Reddit](https://en.wikipedia.org/wiki/Reddit "Reddit"), [Twitch](https://en.wikipedia.org/wiki/Twitch_\(service\) "Twitch (service)") (formerly [Justin.tv](https://en.wikipedia.org/wiki/Justin.tv "Justin.tv")), [Xobni](https://en.wikipedia.org/wiki/Xobni "Xobni"), [Dropbox](https://en.wikipedia.org/wiki/Dropbox_\(service\) "Dropbox (service)"), [Airbnb](https://en.wikipedia.org/wiki/Airbnb "Airbnb"), and [Stripe](https://en.wikipedia.org/wiki/Stripe_\(company\) "Stripe (company)").[\[20\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-20)

*[BusinessWeek](https://en.wikipedia.org/wiki/BusinessWeek "BusinessWeek")* included Paul Graham in the 2008 edition of its annual feature, *The 25 Most Influential People on the Web*.[\[21\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-21)

In response to the proposed [Stop Online Piracy Act](https://en.wikipedia.org/wiki/Stop_Online_Piracy_Act "Stop Online Piracy Act") (SOPA), Graham announced in late 2011 that no representatives of any company supporting it would be invited to Y Combinator's Demo Day events.[\[22\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-Demo_Day_SOPA_cutoff-22)

In February 2014, Graham stepped down from his day-to-day role at Y Combinator.[\[23\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-23)

In October 2019, Graham announced a [specification](https://en.wikipedia.org/wiki/Technical_specification "Technical specification") for another new dialect of Lisp, written in itself, named Bel.[\[24\]](https://en.wikipedia.org/wiki/Paul_Graham_\(programmer\)#cite_note-24)`,
		half: `### About Paul Graham

Under this page, I'd like to introduce you to Paul Graham, a prominent figure in the tech industry. According to Wikipedia, Paul Graham (/ɡræm/; born November 13, 1964) is an English-American computer scientist, writer, entrepreneur, and investor. Renowned for developing the programming language Arc and co-founding the startup accelerator Y Combinator, Graham also created the startup Viaweb (later Yahoo! Store). He’s authored several influential programming books, such as *On Lisp*, *ANSI Common Lisp*, and *Hackers & Painters*. Technology journalist Steven Levy has aptly described him as a "hacker philosopher." Though born in England, Graham spent 48 years in the United States where he completed his education before returning to his native country in 2016.

In 1968, Graham and his family relocated to Pittsburgh, Pennsylvania, where he later attended Gateway High School. Influenced by his father, a nuclear physicist, Graham developed a keen interest in science and mathematics. He earned a Bachelor of Arts with a major in philosophy from Cornell University in 1986. Following this, he achieved a Master of Science in 1988 and a Doctor of Philosophy in 1990, both in computer science from Harvard University. Additionally, Graham has pursued studies in painting at the Rhode Island School of Design and the Accademia di Belle Arti in Florence.

In 1996, Graham and Robert Morris founded Viaweb, recruiting Trevor Blackwell soon after. They believed Viaweb was the first application service provider. Graham later received a patent for webapps based on his work with Viaweb, which allowed users to create Internet stores using software primarily written in Common Lisp. In 1998, Viaweb was sold to Yahoo! for $49.6 million and became Yahoo! Store. Graham gained recognition for his essays on various topics, ranging from programming languages to high school nerd life, and published a collection titled *Hackers & Painters*. In 2001, he began working on a new Lisp dialect named Arc, releasing it in 2008. Some Y Combinator projects, including Hacker News, were developed using Arc. In 2005, after a Harvard talk, Graham, along with Blackwell, Jessica Livingston, and Morris, founded Y Combinator, which has since invested in over 1300 startups such as Reddit, Dropbox, and Airbnb. Graham was featured in BusinessWeek’s 2008 list of The 25 Most Influential People on the Web. He took a stand against SOPA in 2011 by excluding supporters from Y Combinator events. In 2014, he stepped down from his daily role at Y Combinator and announced another Lisp dialect named Bel in 2019.`,
		quarter: `
### About Paul Graham

Paul Graham, a significant figure in the tech industry, was born on November 13, 1964. He is an English-American computer scientist, writer, entrepreneur, and investor, renowned for developing the programming language Arc and co-founding the startup accelerator Y Combinator. Graham also created the startup Viaweb, later known as Yahoo! Store. His influential programming books include "On Lisp," "ANSI Common Lisp," and "Hackers & Painters," earning him the title of "hacker philosopher" by Steven Levy. Although born in England, Graham spent 48 years in the U.S., where he completed his education and returned to England in 2016. He moved to Pittsburgh in 1968 and was inspired by his father, a nuclear physicist, to pursue science and mathematics. He graduated from Cornell University with a BA in philosophy and later earned an MS and PhD in computer science from Harvard University. Additionally, he studied painting at the Rhode Island School of Design and the Accademia di Belle Arti in Florence. In 1996, Graham co-founded Viaweb, later sold to Yahoo! for $49.6 million. He is known for his essays on various topics and released "Hackers & Painters" in 2004. In 2001, he developed the Lisp dialect Arc, used in some Y Combinator projects. In 2005, after a Harvard talk, Graham co-founded Y Combinator, which invested in over 1300 startups including Reddit, Dropbox, and Airbnb. He was named one of BusinessWeek’s 25 Most Influential People on the Web in 2008. He opposed SOPA in 2011 and stepped down from his daily role at Y Combinator in 2014, later announcing another Lisp dialect named Bel in 2019.
`,
	},
	"demo/darwins_cathederal": {
		index: `Darwin's Cathedral: Evolution, Religion, and the Nature of Society`,
		half: `Darwin's Cathedral: Evolution, Religion, and the Nature of Society`,
		quarter: `Darwin's Cathedral: Evolution, Religion, and the Nature of Society`,
	},
	"demo/darwins_cathederal/chapter_1": {
		index: `CHAPTER 1

THE VIEW FROM EVOLUTIONARY BIOLOGY

There can be no doubt that a tribe including many members who, from possessing in a high degree the spirit of patriotism, fidelity, obedience, courage, and sympathy, were always ready to aid one another, and to sacrifice themselves for the common good would be victorious over most other tribes; and this would be natural selection.

—Darwin 1871, 166

Religion is often used to explain purpose and order at all levels, from celestial bodies, to human society, to the actions of individual people and other creatures. Darwin showed how the properties inherent in words such as “purpose,” “order,” “adaptation,” and “organism” can arise by the process of natural selection. However, the evolutionary concept of purpose and order is highly restrictive and may well apply to individuals but not to groups. The image of society as a single organism writ large, which has so often been taken for granted by religious and other nonevolutionary thinkers, must be questioned very seriously in the light of evolution.

To evaluate religious groups as organisms, we must begin with the more general question of whether any kind of group qualifies as an organism. This chapter will lay the groundwork by reviewing the history of thinking on groups in evolutionary biology, from Darwin to the present, with special reference to human evolution (see Sober and Wilson 1998 for a book-length account). It is a tumultuous and fascinating history. Although Darwin was characteristically clear-sighted, many of his successors uncritically assumed that adaptive societies can evolve as easily as adaptive individuals. The term “for the good of the group” was used as freely as “for the good of the individual.” Then, starting in the 1960s, adaptation at the level of groups was rejected so strongly that the ensuing period could be called the age of individualism in evolutionary biology. Fortunately, science is not destined to be a frictionless pendulum that swings back and forth between extreme positions. A middle ground is becoming established in which groups are acknowledged to evolve into adaptive units, but only if special conditions are met. Ironically, in human groups it is often religion that provides the special conditions. Religion returns to center stage, not as a theological explanation of purpose and order, but as itself a product of evolution that enables groups to function as adaptive units—at least to a degree.

ADAPTATION AND FUNCTIONALIST THINKING

The basic concept of adaptation and the interpretation of groups as adaptive units existed far before Darwin’s theory of evolution. The *Oxford English Dictionary* defines adaptation as “the action or process of fitting or suiting one thing to another.” Human artifacts are often clearly adapted to perform a given function. A bow is designed to shoot an arrow. An arrow is designed to fly through the air and pierce its target. Likewise, the form and behavior of organisms are often clearly adapted to achieve certain goals. The coat of a polar bear is designed to keep it warm and to prevent it from being seen. The behavior of a polar bear stalking its prey is designed to get close enough to attack while avoiding detection.

Thinking about an object or an organism as if it has a purpose can be called functionalist thinking. Functionalist thinking can be highly effective when applied to things that actually have a purpose, but in other contexts it can be misleading. Wondering about the purpose of your neighbor’s behavior can help you discern his intentions, but wondering about the purpose of the moon leads only to a folk tale. The reverse is true for non-functionalist thinking. A boulder rolling down a hill has no purpose, but merely a path which must be predicted to get out of the way. It would be disastrous to think of a boulder as like an attacking predator or an attacking predator as like a boulder. Functionalist and nonfunctionalist ways of thought are so different from each other, and so useful in some contexts but misleading in others, that they may actually have evolved as separate cognitive skills (Hauser and Carey 1998; Tomasello 1999).

Functionalist thinking has been applied to social groups throughout history. Plato compared the various classes of society to the organs of a single organism. Religious thought is rife with organismic allusions—as in Paul’s description (1 Cor. 12) of the body of the church, united under the head of Christ. Similarly, the Anglican bishop Joseph Butler (\[1726\] 1950, 21) claimed that “it is as manifest that we were made for society and to promote the happiness of it, as that we were intended to take care of our own life and health and private good.” The founders of the social sciences talked unabashedly about societal organisms, complete with group minds (Wegner 1986). However, although the metaphor of society as organism appears plausible in some cases, it is misleading in others. A well-organized attacking army seems more like a single predator than a passing boulder, but the class of beggars has no organ-like function in society, although it may be explained by functionalist thinking at a lower level, such as individual greed resulting in an unequal division of resources. Thus, social groups are a nebulous and heterogeneous category with respect to the concept of adaptation.

THE FUNDAMENTAL PROBLEM OF SOCIAL LIFE

Darwin provided the first successful scientific theory of adaptations. Evolution explains adaptive design on the basis of three principles: phenotypic variation, heritability, and fitness consequences. A phenotypic trait is anything that can be observed or measured. Individuals in a population are seldom identical and usually vary in their phenotypic traits. Furthermore, offspring frequently resemble their parents, sometimes because of shared genes but also because of other factors such as cultural transmission. It is important to think of heritability as a correlation between parents and offspring, caused by any mechanism. This definition will enable us to go beyond genes in our analysis of human evolution. Finally, the fitness of individuals—their propensity to survive and reproduce in their environment—often depends on their phenotypic traits. Taken together, the three principles lead to a seemingly inevitable outcome—a tendency for fitness-enhancing phenotypic traits to increase in frequency over multiple generations. Darwin’s theory is so simple that it can be explained in a single paragraph, but its implications are so profound that the study of life was transformed, enabling the great geneticist Theodosius Dobzhansky (1973) to say: “Nothing in biology makes sense except in the light of evolution.”

The fact that adaptation is defined in terms of survival and reproduction places limits on the kinds of adaptation that can evolve. To appreciate the limitations, let’s first consider the evolution of an individual-level adaptation, such as cryptic coloration. Imagine a population of moths that vary in the degree to which they match their background. Every generation, the most conspicuous moths are detected and eaten by predators while the most cryptic moths survive and reproduce. If offspring resemble their parents, then the average moth will become more cryptic with every generation. Anyone who has beheld an insect that looks exactly like a leaf, right down to the veins and simulated herbivore damage, cannot fail to be impressed by the ability of natural selection to produce breathtaking adaptations at the individual level.

Now consider the same process for a group-level adaptation, such as members of a group warning each other about approaching predators. Imagine a flock of birds that vary in their tendency to scan the horizon for predators and to utter a call when one is spotted. The most vigilant individuals will not necessarily survive and reproduce better than the least vigilant. If scanning the horizon detracts from feeding, the most vigilant birds will gather less food than their more oblivious neighbors. If uttering a cry attracts the attention of the predator, then sentinels place themselves at risk by warning others. Birds that do not scan the horizon and that remain silent when they see a predator may well survive and reproduce better than their vigilant neighbors.

These two examples show that the evolutionary concept of adaptation does not always conform to the intuitive concept, especially at the group level. It is easy to imagine a bird flock as an adaptive unit and to use functionalist thinking to predict its properties. We would expect members of the flock to adopt the creed “all for one and one for all.” We might expect sentries to be posted at all times to detect predators at the earliest possible moment and to relay the information to feeding members of the flock. Unfortunately, individuals who display these prosocial behaviors do not necessarily survive and reproduce better than those who enjoy the benefits without sharing the costs. Since Darwin’s theory relies entirely on differences in survival and reproduction, it appears unable to explain groups as adaptive units. This can be called the fundamental problem of social life. Groups function best when their members provide benefits for each other, but it is difficult to convert this kind of social organization into the currency of biological fitness.

Now we can begin to see why the concept of religious groups as adaptive units does not emerge automatically from evolutionary theory. On the basis of what we have considered so far, the theory has difficulty explaining any kind of group as an adaptive unit, including those that might be found in our own species.

DARWIN’S SOLUTION TO THE FUNDAMENTAL PROBLEM

Darwin was aware of the fundamental problem of social life and proposed a solution. Suppose there is not just one flock of birds but many flocks. Furthermore, suppose that the flocks vary in their proportion of callers. Even if a caller does not have a fitness advantage within its own flock, groups of callers will be more successful than groups of noncallers. In the following famous passage from *The Descent of Man,* Darwin (1871, 166) used this reasoning to explain the evolution of human moral virtues that appear designed to promote group welfare:

It must not be forgotten that although a high standard of morality gives but a slight or no advantage to each individual man and his children over the other men of the same tribe, yet that an increase in the number of well-endowed men and advancement in the standard of morality will certainly give an immense advantage to one tribe over another. There can be no doubt that a tribe including many members who, from possessing in a high degree the spirit of patriotism, fidelity, obedience, courage, and sympathy, were always ready to aid one another, and to sacrifice themselves for the common good would be victorious over most other tribes; and this would be natural selection. At all times throughout the world tribes have supplanted other tribes; and as morality is one important element in their success, the standard of morality and the number of well-endowed men will thus everywhere tend to rise and increase.

Darwin was proposing that the three ingredients of natural selection—phenotypic variation, heritability, and fitness consequences—can exist at the level of groups. There can be a population of groups (many tribes of humans, many flocks of birds) that vary in their phenotypic properties (standard of morality, warning cries), with consequences for survival and reproduction (intertribal warfare, avoiding predators). If current groups resemble the previous groups from which they were derived, then groups can evolve into adaptive units in just the same way that individuals evolve into adaptive units.

Darwin’s solution to the fundamental problem of social life is elegant and perhaps even obvious in retrospect. After all, if adaptations evolve by differential survival and reproduction, it makes sense that group-level adaptations evolve by the differential survival and reproduction of groups. However, Darwin’s solution has two limitations that must always be kept in mind. First, just because groups can evolve into adaptive units doesn’t mean that they do. The days of axiomatically thinking of groups as adaptive units are gone forever. Special conditions are required that may or may not be satisfied in the real world. Opposing forces exist that may or may not be overcome. In the case of our birds, group selection favors vigilant callers but selection within groups favors birds that stuff their crops and think only of saving their own feathers when a predator appears on the horizon. If we wish to explain bird flocks as adaptive units, not only must we demonstrate a process of among-group selection, but we also must show that it operates more strongly than the opposing process of within-group selection. The term multilevel selection expresses the possibility that natural selection can operate at more than one level of the biological hierarchy.

Second, even when groups do evolve into adaptive units, often they are adapted to behave aggressively toward other groups. In Darwin’s scenario, the moral virtues are practiced among members of a tribe and are directed against other tribes. Group selection does not eliminate conflict but rather elevates it up the biological hierarchy, from among individuals within groups to among groups within a larger population. The most that group selection can do is produce groups that are like organisms in the harmony and coordination of their parts. We already know about the competitive and predatory interactions that take place among individual organisms in ecological communities, and the same can be expected of well-adapted groups. This might be a disappointment for those searching for a universal morality that transcends group boundaries, but it follows directly from the organismic concept of groups. I do not mean to imply that the search for a universal morality is hopeless, only that it does not follow automatically from group selection theory. Religions are well known for their in-group morality and out-group hostility, so we will return to this theme repeatedly in future chapters.

Looking forward, we can anticipate that evolutionary theory will turn the study of religion into quite a complex subject. It is possible to imagine religious groups as adaptive units, but this outcome is by no means obvious or inevitable. A major alternative hypothesis is that some features of religion are a product of within-group selection, benefiting some individuals at the expense of others within the same religious group. In addition, a host of nonfunctional explanations are possible, since there is more to evolution than natural selection (Gould and Lewontin 1979; Williams 1996). The likelihood of these possibilities depends on many factors, including the balance between levels of selection. To make matters even more complex, genetic and cultural evolution are both multilevel processes that interact with each other. This book is about evolution but it is not restricted to genetic evolution. At all times throughout the world (to paraphrase Darwin) religious systems have arisen in profusion, competing against each other and against nonreligious social organizations. Differences among religions are culturally based, but that does not prevent religious groups from succeeding or failing on the basis of their properties and for these properties to be transmitted with modification to descendant groups. At a different temporal scale, the human mind is a product of genetic evolution over thousands of generations during which people were subdivided into small groups of hunter-gatherers. Our genetically innate psychology might therefore reflect the influence of both within- and among-group selection, regardless of the kinds of groups in which we participate today (Barkow, Cosmides, and Tooby 1992; Boehm 1999). Evaluating these possibilities and relating them to the nature of modern religious groups will be a major undertaking requiring many scholar-decades of work.

EVOLUTIONARY THEORY’S WRONG TURN

I have portrayed group selection as a process that can occur but which also must contend against forces that pull in other directions. In the 1960s a consensus emerged that group selection is such a weak force that it can be ignored for most purposes (Williams 1966). The consensus held that even though it is theoretically possible for groups to evolve into adaptive units, it almost never happens in the real world. Konner (1999, 30–31) describes this period in the history of evolutionary biology:

Current intrusions of Darwin’s theory into our awareness stem from the mid-1960s, when the British geneticist W. D. Hamilton proposed a solution to the problem of altruism. For traditional social scientists who see societies as functioning organisms, the existence of altruism does not pose a problem. In this view, without altruism societies would not work; groups that lacked it would not survive.

But this is no comfort to strict Darwinians, who see natural selection as operating at the level of individuals, even to the extent of disrupting the cohesiveness of societies. In their view, natural selection should have long since erased altruism. Hamilton’s solution was that evolution selects for altruism if it is directed at relatives in proportion to their relatedness, for then the altruist’s kin are more likely to survive to pass on the contributing genes. . . . Reciprocal altruism, proposed by Robert Trivers in the early 1970s, was a you-scratch-my-back-and-later-I’ll scratch-yours model. Like kin selection, it required no real genetic generosity, only delayed self-interest. With these ideas, biologists seemed to have little further need for the metaphor of society as an organism.

Konner appreciates the diversity of perspectives across time and disciplines that I have also emphasized. Although many social scientists take the organismic concept of society for granted, evolutionary biologists in the 1960s rejected group selection so strongly that it became heretical to think of “society as an organism”—to use Konner’s words—for humans or any other species. Individuals are the organisms and society is merely a convenient word for what individuals do to each other in the course of maximizing their own fitness. The illusion of adaptation at the group level can be explained in terms of individuals increasing the fitness of their genes in the bodies of others, reciprocal exchange, or even more self-serving benefits such as downright deception and exploitation.

The rejection of group selection was hailed by evolutionary biologists as a major event. Alexander (1987, 3) even called it the greatest intellectual revolution of the twentieth century. It is true that the early group selection literature was an easy target for criticism. When a biologist explained a given behavior as for the good of the group or the species, it was usually a naive expression of group-level functionalism rather than a principled argument. However, the wholesale rejection of group selection was itself a wrong turn from which the field is only starting to recover. I have written extensively on this topic elsewhere, including my book-length account with Elliott Sober (Sober and Wilson 1998; Wilson 1998a, 1999a, 2000). Here I will provide a brief summary of evolutionary theory’s wrong turn and why it needs to be put behind us.[1]()

**How to see group selection**

To give the critics of group selection their due, it is perfectly possible for a behavior that seems altruistic to be individually selfish upon closer inspection.[2]() Returning to our bird example, suppose that uttering a call does not increase the risk of being attacked by an approaching predator. On the contrary, calling advertises to the predator that it has been spotted and that a less vigilant member of the group should be targeted. If these are the facts of the matter, then the evolution of calling behavior could be explained entirely by within-group selection. Calling individuals survive and reproduce better than noncalling individuals in the same group. The function of the adaptation is not to warn other members of the group but to communicate with the predator in a way that actually endangers other members of the group. We would be right to reject group selection in this case.

But now suppose that our original story is correct and calls are used to warn other members of the flock at the caller’s expense. Calling is selectively disadvantageous within groups and evolves only because groups of callers fare better than groups of noncallers. A subtle shift in perspective can make calling appear individually selfish, even though it evolves by group selection. To pick an extreme example, imagine a flock of birds with one caller and nine noncallers. Everyone has a low fitness in this flock because only one bird is looking out for predators; however, this bird has the lowest fitness of all. Let us say that the chance of surviving predators is 50 percent for the noncallers and 25 percent for the caller. A second flock of birds has nine callers and one noncaller. Everyone has a high fitness in this flock because so many members are looking out for predators; however, the shirking noncaller has the highest fitness of all. Let us say that the chance of surviving predators is 100 percent for the noncaller and 75 percent for the callers. When we compare the fitness of callers and noncallers within each group, we see that callers are the losers in both cases. However, the group with more callers fares better than the group with fewer callers. This is the classic group selection scenario that began with Darwin. Now for the subtle shift in perspective: Let’s calculate the average survival of callers and noncallers across the groups. One noncaller has a survival probability of 100 percent and nine have a survival probability of 50 percent for an average of 55 percent. One caller has a survival probability of 25 percent and nine have a survival probability of 75 percent for an average of 70 percent. The average caller is more fit than the average noncaller, so why not say that calling evolves by individual selection? Like a magician’s trick, the need to invoke group selection appears to vanish! Of course, the disappearance is just an illusion. The need for multiple groups and variation among groups is absolutely essential for the calling behavior to evolve.

It follows that a certain procedure is required to see group selection. First, we must identify the relevant groups, a point to which I will return below. Second, we must compare the fitnesses of individuals within groups. Third, we must compare the fitnesses of groups in the total population. Finally we must combine these effects to determine the net result of what evolves. Employing this procedure for our bird flock example, the groups are flocks, callers are less fit than noncallers within flocks, but flocks with more callers are more fit than flocks with fewer callers. When the variation among groups is as extreme as in my example (one caller in the first group and nine callers in the second group) group selection is by far the strongest evolutionary force and the calling behavior evolves despite its selective disadvantage within groups.[3]() However, all of this clarity is lost when we average the fitness of individuals across groups. In this case we correctly conclude that the calling behavior evolves, but we are unable to say whether it evolves on the strength of a fitness advantage within groups or between groups—the very distinction required to determine if calling evolves by group selection! If we define “individual selection” in terms of fitness averaged across groups rather than fitness within single groups, we have defined group selection out of existence, making “individual selection” a vacuous term for “whatever evolves.” Elliott Sober and I call the practice of first subsuming group selection into the definition of individual selection, and then using this expanded definition to argue against group selection, “the averaging fallacy.”[4]()

It turns out that the rejection of group selection in the 1960s was based largely on the averaging fallacy. The verdict seemed to be that within-group selection is invariably stronger than between-group selection, but the theories that replaced group selection also assumed the existence of groups. How could they fail to, since social interactions almost invariably take place in groups that are small compared to the total population? To proceed further, we need to confront the crucial question of how groups are defined in evolutionary models of social behavior.

**How to define groups**

The procedure for seeing group selection requires an unambiguous definition of groups. At first this might seem like a hopeless enterprise. The early biologists who thought uncritically about “the good of the group” saw adaptive groupings everywhere: from bird flocks, ant colonies, and fish schools at one end of the spectrum to whole species and ecosystems at the other end. The groups considered by modern multilevel selectionists are only slightly less diverse. Nevertheless, this diversity only exists when we consider a diversity of phenotypic traits. When we consider the evolution of a single trait, there is much less ambiguity about what constitutes a group.

Let’s begin with our trusty bird example before deriving the general rule. Why did bird flocks seem like such appropriate groups for the evolution of warning calls? Because it was assumed as part of the example that all members of a flock are at risk from the approaching predator and hear the cry of any member of the flock. Uttering a cry alters fitness within the flock and has no effect on other flocks. If it turned out that the predator targets several flocks at once and that a warning cry is heard by all the flocks, we would need to change our definition of groups. Similarly, if it turned out that a cry is only heard by one’s nearest neighbor rather than the whole flock, we might need to change our definition of groups yet again. The reason that the definition of groups is so closely tied to the details of the trait is because we are trying to predict the evolution of the trait. When the trait is a nonsocial behavior that alters the fitness of the individual alone, we needn’t concern ourselves with groups. But when the trait is a social behavior, the fitness of an individual is determined by its own trait and the traits of the individuals with whom it interacts. These individuals constitute the group, which must be identified accurately to calculate the fitnesses that determine the outcome of evolution.[5]()

It follows that groups must be defined separately for each and every trait. Suppose that we decide to study resource conservation in our birds. Birds that eat moderately have fewer offspring than birds in the same group that stuff their crops, but groups of moderate birds persist while groups of gluttonous birds overexploit their resources and go extinct (as proposed by Wynne-Edwards 1962). This is the same problem of altruism and selfishness that we encountered for warning cries, but here we need to find the appropriate groups for resource conservation. Bird flocks may be appropriate if they live on exclusive territories but not if many flocks share the same resources. If the birds live on an archipelago of islands, then perhaps a single island is the appropriate group for this particular trait. However, group selection might be less effective at the scale of islands than at the scale of bird flocks. If so, then the birds might behave altruistically with respect to warning cries but not with respect to feeding.

I coined the term “trait-group” to emphasize the intimate relationship between traits and groups in multilevel selection theory (Wilson 1975). However, this term merely recognizes something that has always been implicit in the definition of groups, inside and outside of biology. My bowling group is the people with whom I bowl, my study group is the people with whom I study, my platoon is the group of people with whom I fight, my nation is the group of people who share the same set of laws, my church is the group of people with whom I worship. All of these groups are defined in terms of the individuals who interact with respect to a given activity. There is an infinite variety of groups, but only when we consider an infinite variety of activities. For any particular activity, there is a single appropriate grouping. We all use the concept of trait-groups in our everyday lives without thinking about it.

Returning to biology, all theories of social behavior must identify the appropriate grouping to explain the evolution of a given behavior. Let’s say that the behavior involves fighting over a resource. We imagine one type of individual who shares amicably and another type who fights to take it all. If the individuals always meet in pairs, then pairs are the appropriate groups. If the individuals meet in triads or in free-for-alls of one hundred, then those are the appropriate groups. The groups are decided by the biology of the organism, not the whim of the biologist. Evolutionary game theory, one of the theoretical frameworks that was developed as an alternative to group selection, is very careful in this regard (Maynard Smith 1982; Dugatkin 1998; Skyrms 1996). Its formal name is N-person evolutionary game theory, where N is the number of individuals who socially interact, thereby influencing each other’s fitness. A game theory model of fighting, alarm calls, or resource conservation must identify the same groupings as a group selection model of fighting, alarm calls, or resource conservation. The same is true for all other theories of social behavior that were developed as alternatives to group selection, such as inclusive fitness theory (Hamilton 1964, 1975) and selfish gene theory (Williams 1966; Dawkins 1976).

The nonarbitrary definition of groups and the need for all theories to converge upon the same definition for any particular trait allows the averaging fallacy to be revealed to its fullest extent. Take any evolutionary theory of social behavior, including those that were developed as alternatives to group selection, and find the groups that are identified within their own frameworks. Employ the procedure outlined above for seeing group selection, and you will find it. Most of the behaviors that have been rendered as only “apparently” altruistic but “really” selfish during the age of individualism are selectively disadvantageous within groups and evolve only by increasing the fitness of groups, relative to other groups, exactly as Darwin proposed.[6]()

It should be clear by now that the revival of multilevel selection theory involves more than acknowledging one or two examples of group selection. Once the averaging fallacy is avoided, group selection is required to explain many traits whose evolution is already well documented and accepted. However, remember that my own account of group selection was cautious. Just because it happens doesn’t mean that it happens all the time or invariably prevails against within-group selection. There are plenty of cases in which group selection remains a meager evolutionary force, even after we see it clearly. The importance of group selection in human genetic and cultural evolution remains to be determined. Above all, we do not want to return to the days when groups were axiomatically assumed to function as adaptive units. The point is to achieve a middle ground in which the importance of the various levels of natural selection are examined on a case-by-case basis, using a procedure that allows group selection to be seen where it exists.[7]() The belief that group selection can be categorically rejected belongs on the rubbish heap of history, alongside the earlier belief that groups always function as adaptive units.

MAJOR TRANSITIONS OF LIFE

The trait-group concept conflicts with the image of an organism as a unit that is adaptive with respect to many traits. After all, an individual organism like a bird eats as a unit, flies as a unit, fights as a unit, and so on. Some animal groups such as social insect colonies are integrated with respect to many traits. Similarly, some human groups organize the lives of their members from cradle to grave. In many other cases, however, groups are adaptive only with respect to one or a few traits. When I use the term “organismic” in connection with groups, it will be synonymous with “adaptive at the group level” and will refer to particular traits and the appropriate groupings for those traits, while remaining agnostic about other traits and groupings.[8]() The fact that people often participate in many groupings whose adaptedness must be evaluated on a case-by-case basis will become clear in subsequent chapters.

When group selection was rejected in the 1960s it was believed that evolution takes place entirely by mutational change. Since then, it has become increasingly certain that evolution also takes place along a different pathway: by social groups becoming so functionally integrated that they become higher-level organisms in their own right. One of the first to propose this radical new theory was Lynn Margulis (1970), who claimed that eukaryotic cells—the nucleated cells of all organisms other than bacteria—are actually symbiotic communities of bacteria whose members led a more autonomous existence in the distant past. Now it appears likely that similar transitions, from groups *of* organisms to groups *as* organisms, have occurred throughout the history of life, right down to the origin of life itself as social groups of cooperating molecular reactions (Maynard Smith and Szathmary 1995; Michod 1999a).

These discoveries are deliciously ironic. Thinking of social groups as like organisms has been out of fashion for thirty-five years, and now it turns out that organisms are themselves social groups! Moreover, each transition requires group-level selection, exactly as Darwin proposed. For example, a bacterial cell can be regarded as a social group of genes that coordinate their activities for their collective benefit. However, this group can be exploited by genes that use the resources of the cell to replicate themselves rather than by making products that contribute to the common good. Such “selfish genes” would fare better than “solid citizen genes” within the same cell, but cells with “selfish genes” would fare more poorly than cells with “solid citizen genes.” As an aside, my use of the term “selfish gene” in the previous sentence is not the same as its meaning in selfish gene theory (Dawkins 1976). In my case, I refer to genes that gain at the expense of other genes in the same cell; in contrast, selfish gene theory would classify either gene as selfish depending on which evolves, replacing the other gene in the total population (the averaging fallacy).[9]() In any case, the problem of “solid citizen” vs. “selfish” genes within cells is identical to the problem of calling vs. noncalling birds within flocks and moral vs. immoral people within tribes that led Darwin to propose his theory of group selection.

Viewing single organisms as highly integrated social groups has vastly expanded the scope and importance of multilevel selection theory. As Robert Trivers once remarked in a lecture, those interested in the evolution of social behavior have always appreciated the need to understand genetics, but who would have guessed thirty years ago that geneticists would need to understand the evolution of social behavior? There is also a return benefit, for understanding the mechanisms that allow organisms to become so integrated can help to identify similar mechanisms in social groups that might previously have been overlooked. In particular, sociobiologists have been fascinated, even mesmerized, by the problem of explaining altruistic traits that benefit the group at great cost to the individual. As we have seen, group selection can produce altruistic traits, but it must be exceptionally strong to oppose the strong selective disadvantage of altruism within groups. In contrast, the mechanisms that allow organisms to function as adaptive units do not appear very altruistic. Returning to the “selfish gene” that replicates rather than contributing to the common good of the cell, this problem can be solved by linking all the genes together into a chromosome that replicates as a unit. By eliminating the possibility of differential replication within the cell, chromosomes concentrate the process of natural selection at the among-cell level, neatly solving the fundamental problem of social life. But the genes responsible for the evolution of the chromosome do not appear self-sacrificial. Instead, they appear to benefit the group, of which they are a part, at no special cost to themselves.

Social control, rather than highly self-sacrificial altruism, appears to solve the fundamental problem of social life at the individual level. An entire lexicon of words describing social control in human life has been borrowed to describe genetic and developmental interactions; “sheriff” genes, “parliaments” of genes, “rules of fairness,” and so on. The laws of genetics and development, which originally referred merely to general patterns, have acquired an eerie resemblance to the other meaning of the word law—a social contract enforced by punishment.[10]()

What works for individuals can also work for social groups. In their drive to explain highly self-sacrificial altruism, sociobiologists have tended to ignore an even more important question: Does benefiting the group require overt altruism on the part of individuals? If not, then group selection can favor mechanisms that organize groups into adaptive units without strong selection against these mechanisms within groups.

I use the word “overt” because a close look at social control mechanisms shows that they differ from altruism only in degree and not in kind. Returning to our bird example, suppose we discover that warning calls are indeed risky and help others at the expense of the caller. If they were performed voluntarily they would qualify as altruistic, with all the self-sacrifice implied by the word. Then we discover that they are not performed voluntarily because birds that fail to call are severely punished by other birds. Calling no longer qualifies as altruistic, but we still must explain the evolution of the punishing behavior that makes calling selfish. Punishers cause birds to issue warning calls that help everyone in the group, including free-riders who do not share the cost of enforcement. We have not solved the problem of altruism but merely moved it from the calling behavior to the punishment behavior. Economists call this a second-order public goods problem: causing another to perform a public good is itself a public good (Heckathorn 1990, 1993). There is, however, an important difference between the two kinds of altruism. The individual cost of enforcement can be much lower than the individual cost of issuing a warning cry. Social control can be regarded as a form of low-cost altruism that evolves to promote behaviors that would qualify as high-cost altruism if they were performed voluntarily. Elliott Sober and I call this “the amplification of altruism” (Sober and Wilson 1998, chap. 4). In general, social control mechanisms do not alter the basic conclusion that group-level adaptations require a corresponding process of group selection. Instead, they partially relax the trade-off between group benefit and individual self-sacrifice, allowing among-group selection to act without strong counteracting within-group selection.

The concept of organisms as social groups has transformed our understanding of multilevel selection in several ways. First, never again can it be said that higher-level selection is always weak compared to lower-level selection. Single organisms such as you and I are shining contradictions of that statement. Second, higher-level selection has always appeared unlikely because it has been linked with self-sacrificial altruism. Social control mechanisms cut this Gordian knot by partially relaxing the trade-off between group benefit and individual cost. Social control mechanisms are obviously relevant to religious groups, which are based on much more than voluntary altruism. Third, it is inconceivable that higher-level selection stops at the level currently known as individual organisms. Selection at the level of social groups is likely to be an important, if not a dominating, evolutionary force in thousands of species. In some cases such as the social insects, the groups are so thoroughly integrated that they deserve to be called organisms in their own right, as Wheeler (1928) suggested long ago and as modern social insect biologists such as Seeley (1995) increasingly acknowledge.

Against this background, the organismic concept of human groups receives new life. Thirty years ago, evolutionary biologists would have dismissed the Hutterites’ comparison of their communities to bodies and beehives as the worst kind of naive group selectionism. Now it is a vivid dot on the scientific radar screen.

HUMAN GROUPS AS ADAPTIVE UNITS

So far I have discussed basic evolutionary principles that apply to all organisms. Now it is time to focus on our own species. We evolved in small groups that are roughly approximated by modern hunter-gatherer societies, which, though fast disappearing, still dot the surface of the globe. As Konner states in the passage quoted above, evolutionary biologists have tended to regard ancestral human groups as mere collections of self-interested individuals, exhibiting nepotism and niceness toward those who can return the favor but by no means qualifying as societal organisms.[11]() Multilevel selection theory makes it appear more likely that ancestral human groups were potent units of selection (Boehm 1999; Sober and Wilson 1998).

First, some empirical facts. Anthropologists don’t agree on much, but they appear to agree that modern hunter-gatherer societies around the world are remarkably egalitarian. The most impressive fact is that meat is usually scrupulously shared. The successful hunter and his immediate family get no more than the rest of the band. The most careful studies have weighed the meat on portable scales as it is divided into portions (Kaplan and Hill 1985a, b; Kaplan, Hill, and Hurtado 1984). Even when averaged over a period of weeks, there was no bias in favor of the actual procurers of the meat. Gathered items are shared less fully, but only in comparison to meat; the same study that reported 100 percent sharing of meat reported approximately 50 percent sharing of gathered items. If a number of people are gathering, it may make little sense to put the harvest together just to divide it again, so the sharing of gathered items must be evaluated differently than the sharing of meat.

Hunter-gatherer egalitarianism extends beyond food to social relationships. The request “take me to your leader” would be met with incomprehension, or perhaps ridicule, by a hunter-gatherer. There are no leaders other than those who have earned the respect of their peers by being models of good conduct, and who can only advise and not dictate. When the British anthropologist E. E. Evans-Pritchard attempted to identify leaders among the Nuer (a pastoralist rather than a hunter-gatherer society but similar with respect to egalitarianism), all he could find was someone called the leopard-skin chief who turned out to be a specialist in conflict resolution, about whom more will be said in [chapters 2]() and [6]().

Hunter-gatherers are egalitarian, not because they lack selfish impulses but because selfish impulses are effectively controlled by other members of the group. This form of guarded egalitarianism has been called “reverse dominance” by anthropologist Chris Boehm (1993, 1999; see also Knauft 1991). In many animal groups, the strongest individuals are usually able to dominate their rivals, taking a disproportionate share of the resources. This is within-group selection pure and simple. In human hunter-gatherer groups, an individual who attempts to dominate others is likely to encounter the combined resistance of the rest of the group. In most cases even the strongest individual is no match for the collective, so self-serving acts are effectively curtailed. Boehm’s survey of hunter-gatherer societies includes many examples of reverse domination, ranging in intensity from gossip, to ridicule, to ostracism, to assassination.

Earlier theories of hunter-gatherer egalitarianism focused on ecological conditions such as dispersed and unpredictable resources. In contrast, Boehm explains egalitarianism in terms of social norms, a shared understanding of do’s and don’ts that are enforced by rewards and punishments. A hunter-gatherer society is above all a moral community with a strong sense of right and wrong that organizes the practices of the group. The specific practices regarded as right and wrong might vary across groups, but in general “right” coincides with group welfare and “wrong” coincides with self-serving acts at the expense of other members of the group.

The concept of human groups as moral communities shows how much has been missed by kin selection theory, which predicts that prosocial behaviors should be directed primarily toward genetic relatives.[12]() Kin selection models assume that behavioral similarity is proportional to genetic similarity; for example, the only way to get a behaviorally uniform group is for it to be genetically uniform. In moral communities, social norms can create a degree of behavioral uniformity within groups and differences among groups that could never be predicted from their genetic structure and which is highly favorable for among-group selection.

The concept of human groups as moral communities also shows how much has been missed by the concept of reciprocal altruism, which predicts that prosocial behavior should be directed primarily toward those who will return the favor. Consider a group whose members believe that it is right to help others in proportion to need rather than the likelihood of return gains. Individuals who abide by the norm are rewarded, those who violate the norm are punished, and the group (let us say) prospers compared to groups whose members restrict helping to those who will return the favor. This is a plausible model, and there is no reason to think of the rewards and punishments supporting the norm of giving according to need as themselves a form of reciprocity. If I shun narrow reciprocators and favor those who give according to need, I am a second-order public good provider, not someone who is maximizing my own return benefits within my group.

On the other hand, the concept of human groups as moral communities fits nicely with the emerging paradigm of major transitions, in which groups become unified by a regulatory apparatus that promotes the welfare of the group as a whole without necessarily requiring extreme self-sacrifice of its members. An example will show how a real hunter-gatherer society accomplishes this, using mechanisms that border upon religion.

The Chewong are a tribe that inhabits the rain forest of the Malay peninsula (Howell 1984).[13]() They combine hunting and gathering with shifting agriculture, and they display the same kind of egalitarianism as pure hunter-gatherer societies. The distribution of food and other scarce items is governed by a system of superstitions known as *punen,* which roughly means “a calamity or misfortune, owing to not having satisfied an urgent desire”:

In the Chewong world, desires are most likely to occur in connection with food. If someone is not immediately invited to partake of a meal which he observes, or if someone is not given her share of any foodstuff seen to be brought back from the jungle, that person is placed in a state of punen because it is assumed one would always wish to be given a share and hence \[that not being given a share would lead one to\] experience an unfulfilled desire. . . . To “eat alone” is the ultimate bad behaviour in Chewong eyes, and there are several myths that testify to this. The sanction on sharing out food originates in the myth about Yinlugen Bud, who was the chief instrument in bringing the Chewong out of their presocial state by telling them that to eat alone was not proper human behaviour. (Howell 1984, 184)

This passage suggests that the superstitions, myths, and gods of Chewong culture are intimately related to a matter of supreme practical importance—food sharing. In addition, the punen system goes beyond beliefs to include social practices that virtually assure an equal distribution of food:

The Chewong take all possible precautions against provoking punen. All food caught in the forest is brought back and publicly revealed immediately. It is then shared out equally among all the households. The women cook it and then share the food in equal proportions among all the members of their own household. As soon as a carcass is brought back, and before it has been divided up, someone of the hunter’s family touches it with his finger and makes a round touching everyone present in the settlement, each time saying “punen.” . . . This is another way of announcing to everyone present that the food will soon be theirs, and to refrain from desiring it yet awhile. If guests arrive while the hosts are in the middle of a meal, they are immediately asked to partake. If they refuse, saying that they have just eaten, they are touched with a finger dipped in the food, while the person touching says “punen.” (185)

Although food is virtually always in short supply, other non-foodstuffs can be scarce or common depending upon the time of year or other circumstances. The punen system is sufficiently flexible to include items only when they are scarce:

Thus bamboo for baking the tapioca bread must be shared equally among all households if the gatherer had to go very far to obtain it. If the bamboo grows close to the settlement, one may collect enough for oneself only. The difference is expressed as bamboo far away (lao tyotn) or bamboo nearby (lao duah). If the nearby river dries out and water has to be carried some distance, it again has to be shared, but daily water collection from the usual source need not be shared. . . . Even if one does not want something that has been brought back, one has to be made publicly and specifically aware of the existence of the thing, by touch if not by receipt of an actual share. (185–86)

It might seem that the injunction to honor other people’s desires would lead to inappropriate sharing and the opportunity to freeload. However, this is not the case:

Once a desire has been voiced, the person who can satisfy it must immediately do so. If he refrains, the person refused will suffer the consequences of punen. But unvoiced desires are just as liable to provoke the same repercussions. In fact people hardly ever make overt requests for anything, and the fear of punen may easily have prevented people from requesting gifts from me. I can recall only one instance when I was solicited to give. An old woman, Mag, asked me to give her a whetstone, which I duly did. The rest of the Chewong, when they heard what Mag had done, commented unfavourably on her behaviour. Of course, if I had refused, it would have been because of my failing to satisfy her desire that Mag would have been bitten by a tiger, snake, or whatever. To desire for oneself can be seen to be bad on two counts. First, it is an overt emotion. Secondly, it emphasizes the individual at the expense of the social. (185)

The calamity that awaits someone who has been placed in a state of punen takes the form of an attack by a tiger, a snake, or a poisonous millipede. Moreover, these animals have spirit forms that can inflict other misfortunes such as disease or physical injury. Thus, virtually any misfortune can be used as “evidence” of a previous transgression. Immunity from disproof might seem like a weakness from a narrow scientific perspective, but it can be a strength for a social system designed to regulate human behavior.

This example gives a preview of some of the major themes that will occupy us in future chapters. The Chewong engage in many activities that would qualify as altruistic if performed voluntarily and without any system of social controls. Benefits are not meted out according to a narrow calculus of genealogical relatedness or likelihood of return gain. Instead, the group is united by a system of beliefs and practices that is essentially moral in tone. There is right conduct and wrong conduct and the latter invites punishment, not only by animals and their spirits but also by disapproving Chewong.[14]() The moral system makes it hard to identify what counts as altruistic, but it obviously discourages behaviors that “emphasize the individual at the expense of the social”—to use Howell’s words. I do not mean to imply that the system works perfectly and eliminates all self-serving behaviors. However the system appears designed for this purpose and by Howell’s account works fairly well. If we conduct a thought experiment in which the system is eliminated, it is likely that food sharing would decline. The system has an otherworldly side that superficially appears irrational and dysfunctional. What simple people, to fear that unfulfilled desires invite attacks from animals and their spirits! Yet, a closer look reveals an impressive functionality with respect to the most practical aspects of Chewong life. We would be foolish to attribute function to each and every nuance of Chewong society, but we would be equally foolish to dismiss the possibility of function altogether. Remember that we are striving for the middle ground.

INNATE PSYCHOLOGY OF MORAL SYSTEMS

It is clear that our understanding of human social evolution must be brought within the paradigm of major transitions. We must go beyond kin selection and reciprocity to model a complex regulatory system that binds members of a group into a functional unit. Evolutionary biologists have only begun this endeavor, so it is important to emphasize the tentative nature of their conclusions. In the [introduction]() I said that this book is about science in motion, full of inconsistencies and loose ends that will only be resolved in the future. Nevertheless, it is even more interesting to describe the game in progress than to report the final score. In this spirit, we need to reconcile two seemingly contradictory facts: the fact that moral systems require innate psychological mechanisms, and the fact that they can rapidly evolve by cultural evolution.

Beginning with psychological mechanisms, there is a long tradition in the human sciences of trying to explain as much as possible with a few general principles, such as operant conditioning or rational choice, as if the laws of behavior are like the laws of physics. In contrast, evolutionary psychologists such as Cosmides and Tooby (2001; see also Tooby and Cosmides 1992) stress that the mind is not a single general-purpose organ but a collection of many organs that adapt organisms to specific aspects their environments. Migratory birds stare at the night sky as nestlings and learn the center of rotation, which they use as adults to travel north and south (Emlen 1975). The neural circuitry that makes this possible evolved in migratory birds but not in other species. It solves only one problem of survival and reproduction. Other problems such as feeding and mating require different specialized circuits. The desert ant *Cataglyphis bicolor* takes a meandering route in search of food but carries it in a straight path back to the colony. Its tiny mind actually represents the meandering path as a series of vectors with known length and direction with respect to the sun, which enables the direction of the starting point to be “calculated” when it is time to return (Wehner and Srinvasan 1981).[15]() This is only one specialized circuit that is packed into the tiny mind of the ant; other circuits are required to cope with other problems of survival and reproduction. The ability to navigate by the stars or to dead reckon by the sun appear miraculous to us because they exceed our own ability, at least without extensive training. However, our minds are also packed with specialized circuits that enable us to solve our own problems of survival and reproduction as naturally as celestial navigation in birds and dead reckoning in ants. Psychologists should be trying to identify and understand these specialized circuits rather than pretending that human behavior can be derived from a few law-like mechanistic principles.

Even without knowing the details, this basic conclusion almost certainly applies to our ability as a species to form into functional groups unified by moral systems. Like adaptations in other species, it requires a specialized, genetically evolved cognitive architecture of its own. A number of authors have speculated on the design features required for a moral system to work, including conformity (Boyd and Richerson 1985; E. O. Wilson 1998), docility (Simon 1990), detection of cheating (Cosmides and Tooby 1992), punishment of cheating (Boyd and Richerson 1992), symbolic thought (Deacon 1998), explicit consensus decision making (Boehm 1996), and so on. Much more work is required to refine these possibilities, but the general expectation is that small groups of people are psychologically prepared to bind themselves into functional units. Take one hundred people from anywhere, place them on a deserted island where they have a reason to work together, and they will make a pretty good job of it. Perhaps they will split into two groups of fifty that try to exterminate each other, but whether the common problem is a hostile environment or a hostile group, working together as a group comes naturally in our species, just as celestial navigation comes naturally to migratory birds and dead reckoning to desert ants.

It is important to stress that the phrase “comes naturally” does not imply that the underlying mechanisms are simple. Vision comes naturally but requires an amazing array of innate cognitive mechanisms. These mechanisms interact during development with features of the environment that are so reliable that all normal people can see without having to think about it. The cognition is automated and takes place beneath our conscious awareness. Similarly, our ability to function as groups may require sophisticated cognitive mechanisms that appear effortless only because they are automated. Decades were required to understand the neurobiology of vision, and a similar effort may be required to understand the neurobiology of moral systems.

The concept of an innate psychology of functional groups is not just a radical conjecture of evolutionary biologists. It is supported by some of the most distinguished research programs in the social sciences. One of the most famous studies in social psychology is the robber’s cave experiment (Sherif et al. 1961), in which boys at a summer camp spontaneously formed into warring tribes which nevertheless could be brought together into a single cooperative group by confronting them with a common problem. A branch of social psychology known as social identity theory shows how easily people think of themselves as members of groups, especially in opposition to other groups (Abrams and Hogg 1990, 1999). Social dilemma experiments demonstrate the fragility of cooperation in the absence of punishment but the ease with which it is achieved when the opportunity for punishment is allowed (e.g., Ostrom et al. 1994). A book aptly entitled *Order without Law* (Ellickson 1991) shows how people spontaneously establish, enforce, and largely abide by social norms in the absence of a formal legal system. Tocqueville, the French social theorist who observed American democracy with such insight, was equally perceptive about small-scale human society in general when he said that “the village or township is the only association which is so perfectly natural that, wherever a number of men are collected, it seems to constitute itself” (\[1835\] 1990, 60). There is great opportunity for a synthesis on this subject between the established branches of the social sciences and evolutionary biology, upon which all functional explanations must ultimately rest.

Applying these insights to the study of religion, we should not think of religion as a purely cultural invention or as something that can be derived from a few law-like principles. Organisms of all sorts require a complex and specialized physiology to coordinate their parts in just the right way to survive and reproduce in their environments. We should think of the psychological mechanisms activated by religion as physiological in this sense.

CULTURAL EVOLUTION OF MORAL SYSTEMS

The second basic fact that we must understand from an evolutionary perspective is that moral systems include an open-ended cultural dimension in addition to an innate psychological dimension. Our genetically evolved minds make it possible to have a moral system, but the specific contents of moral systems can change within groups and vary widely among groups, with important consequences for survival and reproduction. Far from leading to the caricature of genetic determinism that limits the capacity for change, our innate psychology creates a capacity for change by setting in motion a process of cultural evolution.

Although culture has for many decades been envisioned as an evolutionary process, there is little agreement about its precise nature, importance, or relationship to genetic evolution. The most severe critics of sociobiology rely upon culture as an alternative, which they think can be studied without reference to biology (e.g., Sahlins 1976). Some biologists regard culture as a handmaiden of genetic evolution that evolves the same phenotypic adaptations, only faster (e.g., Alexander 1979, 1987). Other biologists try to decompose culture into gene-like units that do not necessarily benefit their human hosts (e.g., Dawkins 1976; Blackmore 1999). Instead, they can act more like disease organisms as they spread from head to head.[16]()

To find our way through this wilderness of possibilities, let’s begin with the image of the mind as a collection of specialized organs, which I emphasized in the previous section. The reason the organs must be specialized is supposedly because general-purpose cognitive organs are not possible (Tooby and Cosmides 1992; Cosmides and Tooby 2001). The first artificial intelligence researchers naively thought that they could build smart general-purpose learning machines, but they soon discovered that the only way to make a machine smart is to make it specialized for a particular task. Chess playing computers are smart at playing chess but can’t do anything else. Similarly, the neural circuit that enables migratory birds to learn the axis of rotation of the night sky can’t do anything else. In general, the world is so full of stimuli and possible responses to stimuli that a smart machine, or a smart cognitive organ, must be very selective about its perception and use of information. As a Chinese proverb states, a wise man knows what to ignore.

These are valid observations, but they have been used by Cosmides, Tooby, and others most closely associated with the term “evolutionary psychology” to build an incomplete picture of the human mind as like a juke-box, in which the records are preevolved cognitive modules and the environment is the button-pusher.[17]() Whatever module that is playing at the moment requires information about the environment in the same way that a computer program requires the input of information. For example, suppose that you are riding on a bus and a member of the opposite sex sits across from you. Out pops your mate choice module, which causes you to scan the person for information relevant to their quality as a mate; their age, health, resources, availability, and so on. A degree of learning takes place during this process but it is highly formulaic. Just as a tax preparation program tells you what you owe after “learning” your income, business expenses, and so on, the mate choice module tells you how attractive the person is after “learning” his or her salient qualities.

Once again, the problem with this portrayal of human mentality is not that it is wrong but that it is partial (Wilson 1994, 1999b, 2002). Against the background of all-purpose learning theory (what Cosmides and Tooby call the “Standard Social Sciences Model” or SSSM), it is full of insights and possibilities. By itself, however, it seems to deny learning, development, and cultural change as open-ended processes. Learning, as we have seen, becomes highly circumscribed information processing. Development becomes the switching on and off of modules during various stages of the life cycle. Culture becomes a reflection of individual behavioral flexibility. If people in different locations experience different environments, different modules will be triggered which in turn will lead to different behaviors. We might call these differences cultural but they have nothing to do with socially transmitted information per se.[18]()

Self-described evolutionary psychologists might complain that I am caricaturing their position. Perhaps I am—but not by much. A glance at the index of David Buss’s *Evolutionary Psychology: Toward a New Psychology of the Mind* reveals that only one page is devoted to “learning,” seven pages to “development,” and seven pages to “culture.” The contents of these pages are as I have described in the previous paragraph (see Wilson 1999b for a detailed critique). The bulk of the book and the field that it represents employs the same algorithm again and again: For any particular feature of human behavior and psychology, try to understand it as a genetically evolved adaptation to a feature of the ancestral environment. Then try to imagine the psychological mechanism as a specialized module.

In this algorithm, everything that has taken place since the advent of agriculture counts for nothing, other than as a source of maladaptive behavior. Why do we overeat? Because we are genetically adapted to crave fats and sugars in the food-poor ancestral environment, which places us at the mercy of every fast-food restaurant in today’s food-rich environment (Stevens and Price 1996). Why are we displeased with our mates? Because the media bombards us with images of the most beautiful people on earth, making even above-average people appear like toads by comparison. In the ancestral environment, the comparison pool would be at most a few hundred individuals (Buss 1999). Why do we often behave stupidly in psychological experiments? Because we are not given information in the form of frequencies, which is how we were designed to receive information in the ancestral environment (Gigerenzer and Hoffrage 1995). The algorithm provides no explanation for why the modern environment became so different from the ancestral environment, but merely accepts the fact and tries to deal with it, like a biologist trying to study a species of rain forest lizard that has mysteriously been transported into the desert.

I must stress once again that I like these ideas, which have led to many valid insights that are new against the background of traditional psychological research. I myself have already stressed the importance of innate psychology in the study of human moral systems. My complaint is not that the algorithm is wrong but that it is partial, seeming to exclude the possibility of learning, development, culture, and other aspects of human mentality as open-ended processes. To broaden the horizon, we need to return to the question of whether cognitive processes must be specialized to be smart.

Consider the mammalian immune system. Just like the mind, it can be regarded as a collection of specialized genetically evolved mechanisms for helping us survive and reproduce in our ancestral environment. The number and sophistication of the mechanisms that comprise the immune system are mind-boggling when understood in detail. Nevertheless, the centerpiece of the immune system is an open-ended process of blind variation and selective retention. Antibodies are produced at random and those that successfully fight invading disease organisms are selected. Diseases are so numerous and evolve so fast with their short generation times that the only way to fight them is with another evolutionary process.

This comparison, between the mind and the immune system, is simple but profound in its implications.[19]() It shows that genetic evolution does not invariably lead to the kind of modularity that excludes open-ended processes. Instead, it can create processes that are themselves evolutionary and therefore capable of providing new solutions to new problems. Plotkin (1994) has aptly termed these processes “Darwin machines,” two words that reflect the essential components of an evolved system that includes evolution within its own structure. “Machine” indicates that the internal evolutionary process must be highly managed to lead to biologically adaptive outcomes. Antibodies that match antigens reproduce more, not by chance, but because the immune system has been constructed that way. “Darwin” indicates that the internal process remains evolutionary despite being managed, with all the implications associated with genetic evolution played out on a new stage. Adaptation to recent (not ancient) environments is perhaps the most important implication, but we should also expect the same kinds of historical contingencies and other constraining factors that cause adaptations to fall short of perfection.

Thinking of the mind as like the immune system allows us to appreciate its genetically evolved and highly specialized features without denying its open-ended potential. Against this background, we can return to the subjects of cultural evolution, moral systems, and religion. As many authors have noted, there was no single human ancestral environment but rather many environments that varied over time and space. The physical environment was exceptionally variable during our emergence as a species, due to unstable climatic conditions (Richerson and Boyd 2000). In addition, human social interactions have the same what-I-do-depends-on-what-you-do quality that marks the interactions between hosts and their disease organisms. When physical and social environments become sufficiently variable, juke-box solutions are inadequate and the only recourse is to evolve Darwin machines.

Cultural evolution can be seen in part as a Darwin machine in action, highly managed but nevertheless genuinely open-ended in its outcome. Confront a human group with a novel problem, even one that never existed in the so-called ancestral environment, and its members may well come up with a workable solution. The solution might be based on trial and error or on rational thought. However, rational thought is itself a Darwin machine, rapidly generating and selecting symbolic representations inside the head. Confront many human groups with the same novel problem and they will come up with different solutions, some much better than others. If the groups are isolated from each other, they may never converge on the best solution; evolution is not such a deterministic process. If the groups are in contact, they might compare solutions and the worst might quickly imitate the best. If convergence by imitation does not occur, then the worst might simply succumb to the best in between-group interactions. Either way, the final outcome is a degree of adaptation to the problem, without any genetic evolution taking place at all. Evolution took place, but not at the genetic level.

This description of human cultural evolution sounds so familiar that the reader might wonder if I have said anything new. Scientific progress does not always involve replacing the familiar with the counterintuitive. Some things are familiar because they are true. A good theory acknowledges the valid aspects of the familiar and goes on to achieve a new level of understanding. In this spirit, multilevel selection theory contributes at least four major insights to the “familiar” process of cultural evolution.

First, cultural evolution requires specialized mechanisms—the machine part of the Darwin machine. Familiar-sounding terms such as “trial and error,” “rational thought,” and “imitation” probably don’t even begin to describe the number and sophistication of the mechanisms that actually guide the process of cultural evolution. More generally, thinking of cultural evolution as itself a product of genetic evolution with many sophisticated design features is anything but familiar.

Second, many of the mechanisms guiding cultural evolution take place beneath conscious awareness. We have a tendency to attribute too much importance to conscious rational thought. We imagine ourselves solving problems by explicitly thinking, talking, experimenting, imitating, and so on. These conscious processes are important agents of cultural change (Boehm 1996), but they are the tip of an iceberg of automated cognitive processes that take place beneath our conscious awareness, some of which are very sophisticated. This means that cultures can evolve to be smart in ways that are invisible to their own members.

Third, the mechanisms guiding cultural evolution can be distributed processes involving many individuals rather than being processes contained within single individuals. There is a pervasive tendency both in biology and in the human sciences to regard individuals as self-contained cognitive units. An individual might rely on outside information and might decide to cooperate with others, but it is still the individual’s decision. The evolutionary justification for this claim is as follows: A brain is a group of neurons whose members interact intricately for the common good. There is a big difference between a brain and a single neuron; most of what we attribute to the mind involves the circuitry connecting the neurons, not the on/off states of the neurons themselves. The reason that neurons in a brain act for their common good is because they exist within a single individual organism that survives and reproduces as a unit. Brains are self-contained cognitive units because individuals are units of selection.

This reasoning, along with so much else that until recently appeared on solid ground, must be questioned in the light of multilevel selection theory. If the individual is no longer a privileged unit of selection, it is no longer a privileged unit of cognition. We are free to imagine individuals in a social group connected in a circuitry that gives the group the status of the brain and the individual the status of the neuron.

The concept of a group brain might seem like science fiction, but only against the background of the last fifty years of intellectual thought. As I mentioned earlier, the founding fathers of the human social sciences were fully comfortable with the idea of group organisms, complete with group minds (Wegner 1986). Moreover, modern social insect biologists have established the reality of group minds in impressive detail (Seeley 1995; Detrain et al. 1999). An example from honeybees will help to restore our intuition for our own species.

The challenges of survival for a honeybee colony are awesome when sufficiently appreciated. To function adaptively, the colony must make decisions on an hourly basis about which flower patches to visit and which to ignore over an area of several square miles, whether to gather nectar, pollen, or water, the allocation of workers to foraging vs. hive maintenance, and so on. In an elegant series of experiments, T. D. Seeley and his colleagues worked out in detail how some of these decisions are actually made (reviewed by Seeley 1995). In one experiment, a colony in which every bee was individually marked was taken deep into the Adirondack woods where virtually no natural resources were available. The colony was then provided with artificial nectar sources whose quality could be experimentally manipulated. When the quality of a food patch was lowered below alternative patches, the colony responded by shifting workers away from the patch, yet individual bees visited only one patch and therefore had no frame of comparison. Instead, individuals contributed one link to a chain of events that allowed the comparison to be made at the colony level. Bees returning from the low-quality patch danced less and themselves were less likely to revisit. With fewer bees returning from the poor resource, bees from better patches were able to unload their nectar faster, which they used as a cue to dance more. Newly recruited bees were therefore directed to the best patches. Adaptive foraging decisions were made by a decentralized process in which individuals acted more as neurons than as decision-making agents in their own right. Even the physical architecture of the hive, such as the location and dimensions of the dance floor, honeycomb, and brood chambers, has been shown to play an important role in the cognitive architecture of adaptive decision making at the group level.

A more recently documented example of group cognition in honeybees involves the selection of a new site (Seeley and Buhrman 1999). When the colony becomes large enough to split, the old queen departs with about half the workers and forms an exposed mass of bees called a swarm from which scouts emanate to search for suitable sites. Scouts returning from different sites interact on the surface of the swarm in such a way that the best site is chosen. As with foraging for nectar, however, no single scout visits more than one site, so decision making is a distributed process that requires a group of bees interacting in just the right way. This example is instructive because it is equivalent to a “best-of-n” decision-making algorithm that is also employed by individual humans (Payne et al. 1993). The algorithm is the same, regardless of whether it involves a group of neurons or a group of bees.

Social insect colonies have taken the concept of group minds and group organisms beyond the realm of mysticism and science fiction. In addition, it is entirely likely that the same concepts apply to our own species (Wilson 1997). As much as we might laud the individual human mind, its capacity is vastly exceeded by the demands of language and culture that are the hallmark of our species and that evolved in tandem with human brain evolution. Theories of human evolution frequently emphasize various forms of cooperation in the context of physical activities (e.g., hunting, intergroup warfare); why not also in the context of mental activities? If widespread cognitive cooperation did evolve in our species, we need be no more aware of the role that we play in the group mind than honey bees as they perform their waggle-dance.

The fourth insight that multilevel selection theory contributes to the “familiar” process of cultural evolution is that such evolution takes place largely at the group level. Cultural evolution is not merely a handmaiden of genetic evolution but changes the parameters of the evolutionary process, favoring traits that would not evolve by genetic evolution alone (Boyd and Richerson 1985; Boehm 1999; Wilson and Kniffin 1999). To understand the significance of this statement, consider a genetic mutation that occurs in a large population that is subdivided into groups. There is now genetic variation both within groups (the single mutant vs. everyone else in the group) and between groups (a group with a single mutant vs. many groups with no mutant). The gene can be favored by group selection if the mutant individual single-handedly increases the fitness of its group, relative to other groups, but this advantage must be weighed against the fitness of the individual, relative to the other members of the same group. The group effect is likely to be more powerful if the groups are small (e.g., 1 out of 5) than large (e.g., 1 out of 1,000). Group selection would work better if we could concentrate mutants into a single group, but it is not obvious how this can happen if the mutant gene is at a low frequency in the total population. These are some of the limiting factors that set the tone of the group selection debate in the 1960s.

Now consider a cultural mutation; a new belief or practice that arises in one group by chance, rational thought, or any other process. Unlike the genetic mutation, the cultural mutation need not remain at a low frequency within the group. A variety of factors can swiftly make the mutant behavior the majority or even the exclusive behavior practiced by the group. Perhaps members think explicitly about the new belief or practice, appreciate its wisdom, and establish it as the new norm. Perhaps they follow it “mindlessly” because it is espoused by a charismatic member of the group. If the mutant behavior is altruistic (when practiced voluntarily), its costs and benefits can be modified by the full panoply of social control mechanisms available in our species. These factors can cause a rare behavior to become common even in very large groups. In short, cultural evolution increases the potency of selection among groups and decreases the potency of selection within groups, compared to what would be expected on the basis of genetic evolution alone. This is not an inevitable consequence of cultural evolution, but it is how cultural evolution appears to work in our species—a design feature of a Darwin machine.[20]()

Applying these insights to the study of religion, we should think of religious groups as rapidly evolving entities adapting to their current environments. Religions appeal to many people in part because they promise transformative change—a path to salvation. The word evolution means change, so it would seem that evolution and religion share much in common. It is unfortunate that evolution is so often associated with genetic evolution, a slow process that gives the impression of an incapacity for change over the time scales that matter most to living people struggling with their problems. When we expand our view of evolution to include all Darwinian processes, we can begin to see how religions actually can produce transformative change, even from a purely evolutionary perspective.

MODERN HUMAN GROUPS AS ADAPTIVE UNITS

Most modern societies are vastly different from the hunter-gatherer groups of the ancient past. Although significant genetic evolution can occur in a small number of generations (Endler 1986; Weiner 1994), the basic genetic architecture of the human mind has probably not changed much since the advent of agriculture approximately ten thousand years ago. As we have seen, when evolution is interpreted too narrowly as genetic evolution, all of recorded history becomes a mystery from an evolutionary perspective, something that happened but cannot be explained. The best we can do is try to understand how the stone-age mind is likely to react to the strange new world for which it is not prepared. An expanded view of evolution allows us to interpret recorded history as a fossil record of cultural evolution in action. As with genetic multilevel selection, a cultural variant can spread at the expense of other variants within a group, or by causing its group to spread at the expense of other groups.

Superficially, large-scale human societies appear much less egalitarian than hunter-gatherer groups, but the apparent inequities can be interpreted in two very different ways. On the one hand, social control mechanisms are probably strongest in small groups in which everyone knows and depends on everyone else. Many inequities that exist in large-scale societies are therefore exactly what they seem—some individuals profiting at the expense of others within the society. These should not be interpreted as group-level adaptations but rather as individual-level adaptations with consequences that are often dysfunctional at the society level. On the other hand, purely from the group-level functional standpoint, societies must become differentiated as they increase in size. Thirty people can sit around the campfire and arrive at a consensual decision; thirty million people cannot. It is therefore an open question whether extreme status differences and other seeming inequalities in large-scale societies represent domination pure and simple or rather design features that enable the society to function at a large scale, especially in competition with other societies. There can be little doubt that size itself can be a group-level adaptation. Larger societies tend to replace smaller societies unless their larger size is offset by problems of coordination and internal conflicts of interest. It is possible to imagine major transitions occurring in cultural evolution, in which smaller groups coalesce into larger groups, just as for long-term biological evolution.

Our progress so far can be summarized as follows. Organismic groups do not automatically evolve but require a process of group selection. Group selection can be a potent evolutionary force, despite its widespread rejection during the age of individualism. In fact, the organisms of today are the social groups of past ages, which have become so functionally integrated that we see the whole more than the parts. These developments in evolutionary biology make the organismic view of human society a legitimate possibility—at least to a degree. Human societal organisms rely critically on moral systems to define appropriate behaviors and to prevent subversion from within. Moral systems have an innate psychological dimension but also an open-ended dimension that allows human history to be seen as a fast-paced evolutionary process with cultural rather than genetic mechanisms of inheritance.

Two more issues need to be discussed to complete our survey of evolutionary concepts relevant to the study of religion. First, we must take a closer look at the concept of fitness. Second, we must ask why morality is so often expressed in the form of religion, which seems so different from other modes of thought.

WHAT CONSTITUTES FITNESS?

Studying religion (or any other subject) from an evolutionary perspective requires a clear definition of fitness. Sometimes it is obvious how an organism must be structured to survive and reproduce in its environment. Flight requires certain aerodynamic shapes, and the efficiency of a bird’s wing can be measured with the same precision as the efficiency of an airplane’s wing. The efficiency of behaviors can also be measured with precision. Traveling salesmen must move between cities to sell their wares. There are many ways to construct a path through a number of cities, in fact so many ways that even large computers cannot evaluate them all. Nevertheless, we can easily test whether traveling salesmen choose relatively efficient paths. We can also test whether hummingbirds choose relatively efficient paths on their trips from flower to flower.

It is important to remember that the evidence for design in nature is so compelling that it cries out for an explanation. The great question in Darwin’s day was not “Is there any function in nature?” but “What explains all the function that we see in nature?” Thus, at a certain basic level the question “what constitutes fitness” can have a satisfying and highly intuitive answer. However, a closer look reveals a host of complicating factors that can make fitness difficult to define and study (Michod 1999a).

One of the complicating factors has already been discussed and forms the heart of this book: Fitness is a relative concept. It doesn’t matter how well an organism survives and reproduces. It only matters that it survives and reproduces better than alternative types of organisms. Males of some species are adapted to kill infants, which enables them to mate with the infants’ mothers faster than they could otherwise (Van Schaik and Janson 2000). This behavior is not adaptive for the infants, the mothers, the group, the species, or the ecosystem. It is adaptive only for the males, compared to males who behave otherwise. Nevertheless, these males must be regarded as fit from an evolutionary perspective. Some species of bees have evolved to drink nectar without becoming dusted with pollen, by chewing a hole in the base of the flower. This behavior is not adaptive for the flower-bearing plants or even the bee species, which depends upon the plants for its long-term survival. It is adaptive only for the individual bee, compared to bees who behave otherwise. It is hard to avoid a feeling of moral revulsion at calling such behaviors fit when they are so destructive to other organisms and even the “fit” organism itself over the long term. As we have seen, group selection is a partial solution to this problem. Groups of males who do not kill each other’s infants might survive and reproduce better than other groups. The feeling of moral revulsion that I just described can itself be explained as part of the innate psychology of moral systems that evolved by group selection to suppress self-serving behaviors in our own species. But alas, group selection merely takes us out of the frying pan of within-group interactions and into the fire of between-group interactions. Those groups of males who do not kill each other’s offspring might well kill the offspring and appropriate the females from other groups (Wrangham and Peterson 1997).

These points must be kept firmly in mind when we proceed to our study of religion. Whenever I strike up a conversation about religion, I am likely to receive a litany of evils perpetrated in God’s name. In most cases, these are horrors committed by religious groups against other groups. How can I call religion adaptive in the face of such evidence? The answer is “easily,” as long as we understand fitness in relative terms. It is important to stress that a behavior can be explained from an evolutionary perspective without being morally condoned. Immoral behaviors almost invariably benefit the immoral individual or group; why else would immorality be a temptation? Evolution is not required to tell us something so basic. Religious discussions of self-will are a breath away from evolutionary discussions of self-interest. Open-minded religious believers are perfectly aware that solving the problem of self-will within religious groups can lead to even greater problems of group-will with respect to other groups. These parallels between religious and evolutionary thought are not coincidental; they both spring from the fundamental problem of social life and its partial solution that lies at the heart of religion and which can be explained by multilevel selection theory.

Not only is fitness a relative concept, but it is also a local concept. The English system of measuring in feet and inches is inferior to the metric system, but it persists in certain populations because it is common. The cost of switching to the metric system outweigh the benefits, at least over the short term. This is known as a majority effect, and examples abound in both biological and cultural evolution. IBM-compatibles have an advantage over Apple computers and Microsoft Word has an advantage over other word processing programs because of the majority effect. These examples do not violate the principle of evolution as a fitness-maximizing process but simply illustrate its local nature, which is often illustrated with the metaphor of an adaptive landscape.[21]() Imagine the English measurement system as a meager hill of low fitness and the metric system as a taller hill of high fitness. Evolution is a hill-climbing process, but if it starts out on the slope of the meager hill, all it can do is climb to the top of that hill. Moving from a short hill to a tall hill requires crossing a valley of low fitness and is actually resisted by the evolutionary process. The more rugged the adaptive landscape, the more an evolving system will reflect its original starting point (the particular hill upon whose slope it landed) and will fail to find the best global solution.[22]()

A third complication involves mechanisms of inheritance. The sickle cell gene (S) in humans is an adaptation to malaria, but it does not spread to fixation because it is only advantageous in heterozygotic form (AS). As a homozygote (SS) it leads to debilitating anemia. The result is a genetic polymorphism in which some individuals are protected from malaria (AS) while many others are either unprotected (AA) or suffer from a genetic defect (SS). Some adaptation! In general, the more we complicate the mechanisms of genetic inheritance, making genes fit in some combinations but unfit in others, the messier the process of adaptation becomes.

A fourth complication involves modes of transmission. In diploid organisms such as ourselves, most genes exist in the autosomes and are inherited from both parents, but some genes exist in the cytoplasm and are inherited only from the mother. All cytoplasmic genes in males are doomed to extinction because they will not enter the male’s sperm. A mutant gene that causes females to raise daughters instead of sons will be favored by natural selection if the gene is cytoplasmic but not if it is autosomal. Similarly, a gene that causes males to raise sons instead of daughters will be favored if it is located on the y-chromosome, which is transmitted only through males. These conflicts of interest among genes reveal that even individual organisms fall short of the ideal of internal harmony implied by the word “organism” (Pomiankowski 1999). The fact that fitness depends on the mode of transmission has important implications for models of cultural evolution, which include many possible modes of transmission (Boyd and Richerson 1985).

A fifth complication involves distinguishing the product of natural selection from the process. An adaptation is a product of natural selection and is expected to be well designed with respect to the environment. However, the process of natural selection involves many failures for each success. Like laws and sausages, the manufacture of adaptations is not a pretty sight! Religious experiments that fail are not an argument against evolution, if we are observing the process in addition to the product. The question is whether religious experiments that succeed do so on the basis of their properties, and whether these properties are transmitted (with modification) to subsequent religions.

All of these complications (and others) are important and must be kept in mind as we proceed to our study of religion. However, they should not obscure the progress that can be made at a basic level. Religions are often concerned with the necessities of life—food, shelter, health, safety, marriage, child development, social relations of all sorts. These are so obviously related to survival and reproduction that, at least to a first approximation, we needn’t puzzle over the details any more than Darwin needed to puzzle over the details of a thick beak useful for cracking hard seeds. In addition, it is often clear enough whether people are obtaining the necessities of life at the expense of others or by coordinating with others. The fundamental problem of social life and the role of religion in its (partial) solution are too basic to be obscured by the many complications surrounding the concept of fitness, or so I will try to show.

THE RELIGIOUS EXPRESSION OF MORALITY

So far I have said much about evolution, human evolution, morality, and culture, but little about religion per se. Even if we accept that moral systems enable human groups to function as adaptive units, what accounts for the religious expression of morality? Why can’t people just talk about right and wrong in practical terms without appealing to supernatural agents and other beliefs that to a nonbeliever seem detached from reality? Religion attracts the attention of scientists (and often the scorn of nonbelievers) in part because it seems to flaunt the canons of scientific thought. For many people, the otherworldly nature of religion is more interesting and important to explain than its communal nature.

One possibility is that religions are naive scientific theories, attempts by simple people to understand their complex world that just happen to be false. Religious folk should abandon their beliefs in the face of superior knowledge and if they don’t they are being irrational. This idea surfaces again and again in casual discussions and also forms the basis of more formal theories of religion (Frazer 1890; Tylor 1871). However, it fails to fit the facts. In the first place, people in all cultures—even the most “primitive”—possess the foundation of scientific thought: a sophisticated factual understanding of their world and the ability to reason on the basis of evidence (Malinowski 1948; Boehm 1978). They do not live in an otherworldly fog in all respects. The fog—if that is what it deserves to be called—only descends in some contexts. In the second place, there is no evidence that scientific understanding replaces religious belief in modern cultures. America has become more religious over the course of its history, not less, despite the influence of science and engineering (Finke and Stark 1992). A very high proportion of scientists themselves profess a belief in God and participate in organized religions (Stark and Finke 2000). Clearly, we must think of religious thought as something that coexists with scientific thought, not as an inferior version of it.

A proper understanding of epistemology from an evolutionary perspective can shed light on this issue. Before Darwin, the human ability to know (i.e., to accurately perceive the properties of the external world) could be explained as a gift from God. After Darwin, numerous philosophers and biologists tried to place epistemology on an evolutionary foundation by saying that the ability to know is adaptive (Bradie 1986). Those who did it well survived and reproduced while those who did it poorly were not among our ancestors. This argument has an element of truth; clearly, I need to accurately perceive the location of a rabbit to hit it with my throwing stick. However, there are many, many other situations in which it can be adaptive to distort reality (Wilson 1990, 1995). Even massively fictitious beliefs can be adaptive, as long as they motivate behaviors that are adaptive in the real world. At best, our vaunted ability to know is just one tool in a mental toolkit that is frequently passed over in favor of other tools—just as we observe in all cultures, including our own.

From this perspective, we should expect moral systems to frequently depart from narrow reasoning on the basis of factual evidence. Once this kind of reasoning is removed from its pedestal as the only adaptive way to think, a host of alternatives become available. Emotions are evolved mechanisms for motivating adaptive behavior that are far more ancient than the cognitive processes typically associated with scientific thought. We might therefore expect moral systems to be designed to trigger powerful emotional impulses, linking joy with right, fear with wrong, anger with transgressions. We might expect stories, music, and rituals to be at least as important as logical arguments in orchestrating the behavior of groups. Supernatural agents and events that never happened can provide blueprints for action that far surpass factual accounts of the natural world in clarity and motivating power. These otherworldly elements of religion cannot completely eclipse scientific modes of thought, which are superior in some contexts, but the reverse statement is equally true.

A second example of hunter-gatherer morality will make our discussion less abstract. The following passage from Turnbull (1965, 180) describes how men of the Mbuti tribe, which inhabits the rain forest of equatorial Africa, make decisions on a consensus basis:

Njobo was an undisputed great hunter, knew the territory as well as anyone and had killed four elephants single-handed. He was a good enough Mbuti not to attempt to dominate any hunting discussion in the forest, merely to take a normal part. If he ever appeared to be overly aggressive or insistent he was shouted down and ridiculed, although highly popular. He was also the one chosen to represent the band to the villagers. Ekianga, on the other hand, was less generally popular and was the source of some friction, having three wives (one the sister of another prominent member of the band), but he was a fine hunter, endowed with exceptional physical stamina, and he too knew the territory well. Even at the height of his unpopularity he was one of the most effective “leaders” of the hunt. So was Nikiabo, a youth who had achieved some notoriety by killing a buffalo when barely out of childhood. Although a bachelor, he had a net of his own and took a prominent part in all hunting discussions. Makubasi, a young married hunter, was also accorded special respect because of his hunting prowess and his physical strength, combined with his knowledge of the territory. But while these four can be singled out as exceptional, they could either separately or together be outvoted by the rest of the hunters. On such occasions they were compelled either to give their assent to the popular decision or to refrain from joining the hunt that day. None of them had the slightest authority over the others. Nor was any moral pressure brought to bear in influencing a decision through personal considerations or respect. The only such moral consideration ever mentioned was that when the band arrived at a decision, it was considered “good” and that it would “please the forest.” Anyone not associating himself with the decision was, then, likely to displease the forest, and this was considered “bad.” Any individual intent on strengthening his own argument might appeal to the forest on grounds that his point of view was “good” and “pleasing”; only the ultimate general decision, however, would determine the validity of his claim.

This passage provides a fine illustration of hunter-gatherer egalitarianism, in which the will of the group prevails over the will of the strongest individuals, at least some of whom would gladly become more dominant in the absence of social controls. Their decision about where to hunt almost certainly relied upon practical reasoning on the basis of detailed factual knowledge that we associate with scientific thought. Nevertheless, this mode of thought blended seamlessly with belief in a forest capable of experiencing pleasure, which happens to correspond to the welfare of the group. It is interesting to ask why Mbuti thought took this “irrational” turn when discussion of shared interest could have remained on a purely pragmatic and “rational” plane. However, the answer to this question must be based primarily on the adaptedness of the actions motivated by alternative modes of thought. Once the reasoning associated with scientific thought loses its status as the only adaptive way to think, other forms of thought associated with religion cease to be objects of scorn and incomprehension and can be studied as potential adaptations in their own right.

SURVEYING THE VIEW FROM EVOLUTIONARY BIOLOGY

The main purpose of this book is to treat the organismic concept of religious groups as a serious scientific hypothesis. The contribution of this chapter is to review the relevant concepts in evolutionary biology. We have covered an enormous amount of ground and touched upon many complex issues, but the basic argument can be briefly and simply stated: Natural selection is a multilevel process that operates among groups in addition to among individuals within groups. Any unit becomes endowed with the properties inherent in the word organism to the degree that it is a unit of selection. The history of life on earth has been marked by many transitions from groups of organisms to groups as organisms. Organismic groups achieve their unity with mechanisms that suppress selection within groups without themselves being overtly altruistic. Human evolution falls within the paradigm of multilevel selection and the major transitions of life. Moral systems provide many of the mechanisms that enable human groups to function as adaptive units. Moral systems include both an innate psychological component and an open-ended cultural component that enables groups to adapt to their recent environments. Belief in supernatural agents and other elements that are associated specifically with religion can play an important role in the structure and function of moral communities.

In the [Introduction]() I stated that science works best when it tests among well-framed hypotheses that make different predictions about measurable aspects of the world. Evolutionary theory offers not one but several hypotheses about religion that differ in their predictions, as shown in [table 1.1](). The most important division concerns adaptive vs. nonadaptive explanations. Among adaptive explanations, religion might be a group-level adaptation (the thesis of this book; see also E. O. Wilson 1998), an individual-level adaptation (Alexander 1987), or a cultural parasite that spreads at the expense of both human individuals and groups (Dawkins 1976; Boyer 1994, 2001; Blackmore 1999). Among nonadaptive explanations, religion can be interpreted as an adaptation to past environments that has become maladaptive in modern environments or as a byproduct of evolution whose function, if any, is secondary to a more general adaptive design (Guthrie 1995; Boyer 2001). In a famous essay that criticized evolutionary biologists for relying too heavily on the concept of adaptation, Gould and Lewontin (1979), themselves eminent evolutionary biologists, said that many biological structures are like a spandrel, which is the area created by two adjoining arches. Arches are clearly functional in the design of a building but spandrels are merely the byproducts of arches. These spaces are sometimes used for artistic purposes, but their “function” is secondary at best. Similarly, noses hold up our glasses, but this “function” of noses is clearly secondary to breathing and smelling. One example of a spandrel hypothesis for religion is that self-awareness evolved by natural selection for its survival value, with the unfortunate byproduct that self-aware individuals can foresee their own deaths. Religion might then have arisen to help allay the fear of death, a secondary adaptation that can be understood only in the context of a more primary adaptation (self-awareness).

The hypotheses in [table 1.1]() are used by evolutionary biologists to organize the study of many subjects. When applied to religion, they make vastly different predictions that can be pitted against each other with empirical tests. A religion designed to allay the fear of death will be different than a religion designed to promote the common good, which in turn will be different than a religion designed as a tool of within-group exploitation, which in turn will be different than a religion for which the word “design” makes no sense at all. There is ample empirical information about religion to discriminate among such different hypotheses, resulting in genuine scientific progress. In short, even if my hypothesis turns out to be incorrect, religion can and should be a subject of mainstream evolutionary research.[23]()

Throughout this chapter I have stressed the need to achieve a middle ground in which groups can and do evolve into adaptive units, but only if special conditions are met. It is definitely not my intention to adopt an extreme stance on religious groups as organismic units. I think that group selection can explain much about religion, but by no means all. Evolution is a notoriously messy process that defies single explanations. Nothing is perfectly adaptive or a product of only one level of selection. Even individual organisms have not entirely solved the fundamental problem of social life within themselves. All of the hypotheses listed in [table 1.1]() have at least some merit; our challenge is to discover their relative importance. Also, religion is not a single trait; it is a heterogeneous set of traits that might require different explanations. Finally, science involves comparing hypotheses, so all must be considered even if only one prevails.

Thus, in many respects I will be evaluating all of the hypotheses listed in [table 1.1](). However, the group selection hypothesis deserves special recognition, in part because it explains so much about religion and in part because it has been so maligned and neglected. I believe that future generations will be amazed at the degree to which groups were made to disappear as adaptive units of life in the minds of intellectuals during the second half of the twentieth century. Against this background, thinking of groups as organisms whose function requires a complex and highly organized physiology is so new, and leads to so many predictions that would not be forthcoming otherwise, that it deserves recognition even if it turns out to be only partially true.

There is another reason why group selection explains the essence of religion in a way that the other hypotheses do not. When religious believers describe their church as like a body or a beehive, they are speaking idealistically. According to the Hutterite passage quoted at the beginning of the [introduction](), it is *true* love that means growth for the whole organism. Real churches only approach the ideal of true love, but their failures are interpreted as corruptions and aberrations of religion, not as a part of religion itself. When we study religion as it is actually practiced, we see group selection contending with, and not always prevailing against, other strong forces. When we study religion as it is idealized, we see something much closer to an expression of what would evolve by pure group-level selection.

Our study of religion will repeatedly draw upon the evolutionary themes that were developed in this chapter. First, however, we must survey the view from the social sciences, where religion has already been studied for well over a century.
`,
		half: `## Chapter 1: The View from Evolutionary Biology

Darwin posited that tribes characterized by high levels of traits like patriotism, fidelity, obedience, courage, and sympathy — traits that lead individuals to aid one another and make sacrifices for the common good — would outcompete others, an example of natural selection. Religion has traditionally been used to explain order and purpose at various levels, but Darwin demonstrated that concepts like "purpose" and "order" can arise from natural selection, with a restrictive application often limited to individuals rather than groups. Evolutionary perspectives challenge the notion of society as a single organism, likened to religious or nonevolutionary views. To assess religious groups as organisms, it's vital to question whether any group qualifies as an organism. This chapter discusses the history of group thinking in evolutionary biology, highlighting that while Darwin was clear-sighted, many successors assumed societies evolved as easily as individuals. Starting in the 1960s, strong rejection of group-level adaptation ushered in an age of individualism in evolutionary biology. However, a balanced view now recognizes that groups can evolve into adaptive units under certain conditions, often facilitated by religion, thus positioning religion not as mere theological explanation but as an evolutionary product enabling groups to function adaptively. The concept of adaptation predates Darwin, defined broadly as fitting or suiting one thing to another, illustrated by both human artifacts and organismal traits and behaviors designed to perform specific functions effectively.

Functionalist thinking, which interprets objects or organisms as having a purpose, is effective with purpose-driven items but can be misleading in other contexts. For example, this approach helps discern a neighbor's intentions but leads to folk tales when applied to the moon. Conversely, non-functionalist thinking is useful for predicting the path of purposeless objects like a rolling boulder. Mistaking a predator for a boulder or vice versa can be disastrous. These thinking styles may have evolved as separate cognitive skills due to their contextual utility (Hauser and Carey 1998; Tomasello 1999). Throughout history, functionalist thinking has been applied to social groups. Plato likened society’s classes to the organs of an organism, and religious texts, like Paul’s description of the church (1 Cor. 12), use similar analogies. The Anglican bishop Joseph Butler (\[1726\] 1950, 21) asserted that humans were made for society and mutual happiness, and early social scientists often spoke of societal organisms with group minds (Wegner 1986). However, while society-as-organism metaphors can seem plausible, they can also be misleading. For instance, an organized army can be seen as a single predator, but the class of beggars lacks an organ-like function and might be better explained by individual greed leading to resource inequality. Thus, social groups are a nebulous category regarding adaptation.

Social life fundamentally hinges on balancing individual interests with group welfare. At its core, human cooperation and societal structures are essential to address conflicts between personal desires and collective needs. By fostering mutual trust and utilizing social norms, societies can navigate this dilemma, ensuring both personal freedom and social cohesion. This equilibrium is crucial for achieving sustainable and thriving communities.

Darwin’s theory of adaptations explains adaptive design via phenotypic variation, heritability, and fitness consequences. Phenotypic traits are observable characteristics that vary among individuals in a population. Offspring often resemble their parents due to shared genes and other factors like cultural transmission, making heritability a key component in evolution, defined as the correlation between parent and offspring traits. Fitness refers to an individual's ability to survive and reproduce, influenced by their phenotypic traits. Consequently, fitness-enhancing traits tend to increase over generations. Darwin’s theory radically transformed biology, encapsulated by geneticist Theodosius Dobzhansky’s assertion, “Nothing in biology makes sense except in the light of evolution.” Survival and reproduction define adaptation, imposing limits on evolution. For example, moths with better camouflage survive predation, making their cryptic coloration more common. However, group-level adaptations like predator warnings show different dynamics; vigilant individuals may gather less food or attract predators, reducing their survival compared to their less vigilant peers. This exemplifies how individual and group-level adaptations have distinct evolutionary paths and limitations.

The evolutionary concept of adaptation often clashes with intuitive ideas, particularly at the group level. While one might expect bird flocks to behave as cohesive units with members acting for the collective good, Darwin's theory indicates this is not straightforward due to individual survival and reproduction advantages. Darwin recognized this "fundamental problem of social life" and proposed that natural selection could occur at multiple levels, including groups. He suggested that groups with more altruistic members would outperform less cooperative groups, a concept known as group selection. However, for groups to act as adaptive units, among-group selection must outweigh the opposing within-group selection. This complexity extends to understanding religious groups, which might or might not function as adaptive units. The interplay between genetic and cultural evolution, as well as forces like within-group selection and nonadaptive aspects, further complicates this. While evolutionary theory can provide insights into the development of religions, it emphasizes that group selection does not guarantee universal altruism and often results in in-group cohesion coupled with out-group hostility. This exploration requires extensive scholarly investigation to unravel the evolutionary dynamics of religious groups and their influence on human social organization.

In the mid-1960s, W. D. Hamilton proposed a solution to the problem of altruism that aligned with strict Darwinian principles, suggesting that evolution favors altruism when directed towards relatives, enhancing the survival of shared genes. Robert Trivers later introduced the concept of reciprocal altruism, highlighting a system of delayed self-interest rather than genuine generosity. These ideas diminished the need for the metaphor of society as an organism, a concept traditional social scientists often take for granted. However, evolutionary biologists rejected group selection so vehemently that it seemed heretical to consider society as an organism, instead focusing on individual fitness and actions such as reciprocal exchanges or exploitation. This strong rejection, heralded as a major intellectual shift, overlooked the potential benefits of group selection. Although early arguments for group selection were often naive, the wholesale dismissal was a misstep. I've discussed this extensively, including in collaborative work with Elliott Sober, advocating for re-evaluating and moving past the rejection of group-level adaptation in evolutionary theory.

To address critics of group selection, it's acknowledged that behaviors, such as a bird's warning call, can appear altruistic but actually be individually selfish. For example, a bird's call could serve to indicate to a predator that it has been spotted, thus deflecting danger to less vigilant flock members. This behavior could then be explained by within-group selection, as calling individuals would have higher survival rates than noncallers, contradicting group selection. Conversely, if calling genuinely warns others at the caller's expense —lowering its individual fitness but improving group survival—then calling evolves through group selection. This complex interplay blurs the lines between individual and group selection, especially when fitness is averaged across groups. The concept of "group selection" becomes clearer when groups are precisely defined per trait, such as bird flocks benefiting from warning calls. Misinterpretations leading to the rejection of group selection often stem from the "averaging fallacy," where individual fitness across groups is confused with within-group selection. Recognizing the importance of defining groups relevant to specific traits reveals the role of group selection in evolution, challenging the exclusive focus on individual selection. Thus, while group selection is not omnipresent, its impact should be assessed case by case, avoiding outdated assumptions that either reject or overly universalize group selection.

---

This markdown preserves the key points of the original text, ensuring that the nuanced arguments about group selection versus individual selection are maintained.

In the 1960s, the concept of group selection in evolution was dismissed in favor of the belief that evolutionary changes occur exclusively through mutational changes. However, evidence has since accumulated that evolution also occurs through the formation of functionally integrated social groups, effectively becoming higher-level organisms. Lynn Margulis was among the first to propose this, suggesting that eukaryotic cells are symbiotic communities of bacteria. Similar transitions are now thought to have occurred throughout life's history, reaffirming Darwin's idea of group selection. This perspective reveals that single organisms can be seen as social groups of genes coordinating for the collective benefit, but facing exploitation challenges from "selfish genes." This necessitates understanding genetic social behavior to fully grasp evolutionary dynamics. The realization that organisms themselves are social groups has expanded multilevel selection theory. Mechanisms enabling individual organisms to function cohesively can provide insights into social group integration. The distinction between altruism and social control, where the latter evolves to promote group-beneficial behaviors without high individual costs, is critical. This reconsideration of group-level selection applies to human groups, which, as seen in egalitarian hunter-gatherer societies, operate as moral communities enforcing social norms for group cohesion and welfare. This new understanding positions human groups and their moral structures as influential units of selection, echoing the group integration seen in social insects and challenging previous beliefs focused solely on genetic uniformity and reciprocal altruism.

In the Chewong society, food sharing is critical, and desires frequently concern food. If someone isn’t immediately offered food observed being consumed or brought back from the jungle, they enter a state of punen due to the belief that unshared food fosters unfulfilled desires. Eating alone is considered the worst behavior, rooted in the myth of Yinlugen Bud, who taught that proper human behavior rejects eating alone. The Chewong have developed practices to ensure fair food distribution and avoid punen: food is publicly displayed and shared among households, with a ritual involving touching the food and others while stating "punen" to announce forthcoming sharing. Guests arriving during meals are also included. The punen system extends beyond food to scarce non-food items like bamboo or water, which must be equally shared when in short supply. However, this system does not lead to freeloading, as desires must be fulfilled once voiced, and the fear of punen discourages overt asking. Desiring for oneself is seen negatively as it is a personal emotion that undermines social harmony, illustrated when an old woman, Mag, asked for a whetstone and faced disapproval from others.

The calamity faced by someone in a state of punen among the Chewong can manifest as attacks from tigers, snakes, or poisonous millipedes, whose spirit forms can also bring disease or injury. These misfortunes serve as "evidence" of a prior transgression, demonstrating a system immune to disproof. This should not be seen as a weakness but as a strength in regulating behavior within their society. The practices highlighted show altruistic behaviors emerge without a narrow focus on genealogical ties or return gains, instead driven by a moral system that defines right and wrong conduct. This system discourages self-serving behaviors and invites punishment from both animals and community members for wrongdoings. Though it doesn’t work perfectly, it functions well enough to encourage food sharing and social unity. Despite appearing irrational, this belief system has practical functionality, suggesting that dismissing its possible functions would be as foolish as attributing function to every detail. We must strive for a balanced understanding, acknowledging that human social evolution requires viewing moral systems both from an innate psychological perspective and as products of rapid cultural evolution. This exploration offers a dynamic view of scientific inquiry, full of inconsistencies and ongoing discoveries, which makes the process more intriguing than merely knowing the final outcomes.

Evolutionary psychologists Cosmides and Tooby argue that the mind consists of numerous specialized mechanisms tailored to specific survival challenges, as opposed to a single general-purpose organ guided by universal laws like operant conditioning or rational choice. Examples from nature, such as migratory birds using the center of night sky rotation for navigation and desert ants employing solar-based dead reckoning, demonstrate evolved specialized circuits. These cognitive adaptations solve distinct problems of survival and reproduction, specific to each species. Similarly, humans possess specialized mental circuits for group formation and moral system development, as evidenced by key studies like the robber’s cave experiment and social psychology's social identity theory. These mechanisms, evolved through natural selection, automatically facilitate cooperation and norm enforcement, reflecting sophisticated cognitive machinery akin to vision. Understanding these innate systems, essential for small-scale human societies, requires a synthesis of social sciences and evolutionary biology. Consequently, religious behaviors should be viewed as emerging from these complex psychological structures rather than merely cultural inventions.

From an evolutionary perspective, moral systems combine both an innate psychological dimension and an open-ended cultural dimension. While our genetically evolved minds enable the existence of moral systems, the specific contents of these systems can change within and vary widely among groups, impacting survival and reproduction. This insight contradicts the notion of genetic determinism, suggesting instead that our biology fosters cultural evolution. Despite the recognition of culture as an evolutionary process, there remains little consensus on its nature or its relationship with genetic evolution. Critics of sociobiology view culture as independent of biology, while some biologists see it as a quicker, adaptive evolution parallel to genetic evolution. Others, like Dawkins and Blackmore, propose culture impacts individuals like disease organisms. Evolutionary psychologists often present the human mind as a collection of specialized cognitive modules triggered by the environment. This perspective, though insightful, tends to underplay the role of learning, development, and cultural changes as dynamic, open-ended processes. To illustrate this point, the author likens the immune system—a sophisticated, evolved set of mechanisms that relies on an open-ended process of blind variation and selective retention—to cognitive processes, advocating for a broader understanding of human mentality beyond specialized modules.

This comparison between the mind and the immune system reveals that genetic evolution does not always lead to modularity but can produce open-ended, evolutionary processes capable of addressing new problems—termed "Darwin machines" by Plotkin. These processes, tightly managed yet evolutionary, adapt to recent environments and reflect historical contingencies. Viewing the mind as an evolution-driven system akin to the immune system highlights its specialized features and potential for cultural evolution in diverse and changing environments. Unlike deterministic gene selection, cultural evolution operates through mechanisms like trial and error, imitation, and distributed cognition across groups, often beneath conscious awareness. The concept of group cognition, supported by studies of social insects like honeybees, suggests groups can function similarly to a brain, with individuals acting as neurons. Modern human societies, though different from ancient ones, continue to evolve culturally, with multilevel selection promoting group-beneficial traits. This broader perspective on evolution, including cultural dynamics, offers insights into the adaptability and transformative potential of practices such as religion, emphasizing that evolution encompasses more than just slow genetic changes. Cultural evolution thus redefines how we understand historical developments and human adaptability.

Large-scale human societies appear less egalitarian than hunter-gatherer groups, but this inequity can be viewed in two distinct ways. Small groups, where individuals rely on one another, tend to have stronger social control mechanisms, making inequities in larger societies seem like individual-level adaptations that are often detrimental at a societal level. However, from a group-level functional standpoint, societies must diversify as they grow; while thirty people can make consensual decisions easily, thirty million cannot. This raises the question: are extreme status differences simply domination, or necessary design features for functioning at a large scale, particularly in competition with other societies? Although larger societies tend to replace smaller ones unless hampered by coordination issues, cultural evolution may see smaller groups merging into larger ones, akin to long-term biological evolution. Importantly, organismic groups do not evolve automatically but through group selection, which has been a powerful evolutionary force, leading to today's highly integrated social organisms. Human societal organisms depend significantly on moral systems to govern behavior and prevent internal subversion, with these systems having both innate psychological and open-ended dimensions. This framework views human history as a rapid evolutionary process driven by cultural mechanisms. To further explore evolutionary concepts relevant to religion, we must examine fitness and why morality often manifests in the form of religion.

Studying religion and other subjects through an evolutionary lens necessitates a clear definition of fitness, which can be relatively straightforward for physical traits like aerodynamic shapes in birds. However, when it comes to behaviors such as a traveling salesman’s route or a hummingbird’s flower visits, efficiency can be precisely measured too. Historical explanations in Darwin's time focused on the apparent design in nature, striving to explain the evident functionality. At a basic level, fitness seems intuitive, but complications arise due to its relative nature—an organism is only considered fit if it reproduces better than others, sometimes leading to morally questionable behaviors that benefit the individual over the group. For instance, some males kill infants to expedite mating, behaviors that are not beneficial in a broader context, yet increase individual reproductive success. Group selection offers partial solutions, but can escalate between-group conflicts. This relative and local concept of fitness can analogously be seen in cultural systems, like the persistence of the English measurement system over the metric system due to majority effects. Fitness can also be affected by genetic inheritance complexities, as seen in the sickle cell gene’s varying benefits and detriments. Additionally, genes in differing transmission modes, like cytoplasmic versus autosomal inheritance, lead to conflicts that challenge the coherence of an organism. These principles complicate and enrich our understanding of cultural evolution, paralleling the intricate dynamics in religious and social behaviors.

A fifth complication in understanding natural selection involves distinguishing the process from its product. While an adaptation is expected to be well-designed for its environment as a result of natural selection, the actual process involves numerous failures for each success, much like the unappealing creation of laws or sausages. Failed religious experiments, therefore, should not be considered arguments against evolution if we’re observing both process and product. The key question is whether successful religious practices succeed due to their inherent properties and whether these properties are passed on, with modifications, to future religions. Despite these and other complications, it’s crucial not to lose sight of the progress that can be made. Religions often address basic survival and reproductive needs—food, shelter, health, safety, marriage, child development, and social relationships—so fundamentally connected to survival that we need not delve into the nitty-gritty details any more than Darwin needed to question the utility of a thick beak for cracking seeds. It’s often clear whether individuals secure life’s necessities at others' expense or through cooperation. This fundamental problem of social life and religion’s role in addressing it is essential, and I will attempt to show how it stands despite the complexities tied to fitness.

I've discussed evolution, human behavior, morality, and culture but have touched lightly on religion and its role in morality. Why do humans embed moral systems within religious frameworks, invoking supernatural beliefs that seem detached from reality? Religion captures scientists' attention and the scorn of nonbelievers because it appears to defy scientific principles. It’s often suggested that religion is merely an outdated attempt to understand the world. However, this overlooks the fact that all cultures exhibit sophisticated scientific understanding. More importantly, scientific advancements haven't eradicated religious belief, as seen in the continued religiosity and participation in organized religion among scientists. Religion and scientific thought coexist, rather than one being an inferior version of the other. From an evolutionary perspective, knowing how to interpret reality is an adaptive trait, but sometimes distorting reality can also be adaptive. Emotions, far older than logical reasoning, motivate behavior, suggesting that moral systems are designed to trigger emotional responses rather than rely solely on factual evidence. Elements like stories, music, and rituals effectively guide group behavior, and supernatural beliefs provide clear, motivating blueprints for action. These religious elements and scientific thought both play crucial roles in human societies. For illustration, the Mbuti tribe’s decision-making process, led by skilled hunters but decided by consensus, shows how moral judgments are shaped by a combination of factual knowledge and communal values, pleasing the forest as a moral compass.

This passage offers a compelling example of hunter-gatherer egalitarianism, where the collective will supersedes that of the strongest individuals, some of whom might otherwise dominate if not for social controls. The group's decision on where to hunt likely stemmed from practical reasoning based on detailed factual knowledge akin to scientific thought. Interestingly, this rational thought coexisted with a belief in a sentient forest, aligning with the group's welfare. The question arises as to why Mbuti thought veered into this "irrational" territory when discussions could have remained purely pragmatic and rational. The answer lies in viewing these alternative modes of thought as potentially adaptive. Once scientific reasoning is no longer seen as the sole adaptive way of thinking, religious forms of thought can also be considered legitimate adaptations, worthy of study and understanding.

The primary objective of this book is to seriously consider the organismic concept of religious groups as a scientific hypothesis, particularly through the lens of evolutionary biology. This chapter explores the multilevel nature of natural selection, which operates among groups and individuals alike, suggesting that moral systems and supernatural beliefs play pivotal roles in helping human groups function as adaptive units. Despite evolution's complexity and resistance to monolithic explanations, the group selection hypothesis sheds significant light on the adaptive value of religion, advocating for its consideration amidst various competing hypotheses cataloged in table 1.1. These hypotheses vary from seeing religion as a group-level or individual-level adaptation to viewing it as a cultural parasite or byproduct of evolution. Although the group selection hypothesis has historically been overlooked and criticized, it offers valuable insights, likening religious communities to organisms that aim for the ideal of true love and unity. This framework will continuously inform our examination of religion, even as we also incorporate perspectives from the social sciences, acknowledging the diverse and multifaceted nature of religious practices and ideals.
`,
		quarter: `Chapter 1, "The View from Evolutionary Biology," explores how Charles Darwin's theory of natural selection applies to social groups and religious contexts. Darwin argued that tribes demonstrating traits such as patriotism, fidelity, and cooperation could outcompete others, illustrating group-level natural selection. The chapter examines the history of group thinking in evolutionary biology, noting a shift in the 1960s towards individualism, but recognizes that under certain conditions, groups can evolve as adaptive units, often facilitated by religion. This aligns with functionalist thinking, which interprets objects or organisms as having a purpose. Darwin's theory posits that adaptation involves phenotypic variation, heritability, and fitness consequences, transforming biology by explaining adaptive design. Social groups, however, present a complex case for adaptation, balancing individual and collective needs to ensure both personal freedom and social cohesion. Ultimately, Darwin’s insights underscore the importance of cooperative traits in human evolution and societal development, challenging simplistic views of society as a singular organism.

The evolutionary concept of adaptation often contradicts intuitive group-level expectations, where one might assume bird flocks act cohesively for collective good. Darwin's theory complicates this due to individual survival and reproductive benefits. He proposed natural selection operates at multiple levels, including groups—a concept known as group selection. Groups with altruistic members could outperform less cooperative ones, but among-group selection must outweigh within-group selection. This complexity extends to religious groups, interplaying with genetic and cultural evolution, within-group selection, and nonadaptive aspects. Evolutionary theory doesn’t guarantee universal altruism, often resulting in in-group cohesion and out-group hostility, necessitating extensive scholarly exploration to understand religious groups' evolutionary dynamics. W. D. Hamilton and Robert Trivers proposed theories of kin selection and reciprocal altruism, respectively, challenging the metaphor of society as an organism. This led to a significant shift, with evolutionists focusing on individual fitness, seemingly overlooking group selection's potential benefits. Although initial group selection arguments were naïve, its outright dismissal was a misstep. I've argued, including work with Elliott Sober, for revisiting group-level adaptation. Critics highlight behaviors like bird warning calls as examples of individual benefit masked as altruism, emphasizing the need for careful definitions of groups relevant to traits. Misinterpretations often stem from the "averaging fallacy," confusing individual fitness across groups with within-group selection. Hence, group selection should be evaluated case-by-case, avoiding outdated assumptions that reject or universalize its impact.

In the 1960s, group selection in evolution was deemed irrelevant, favoring mutational changes. Yet, evidence supports that evolution also occurs via social group integration, forming higher-level organisms. Lynn Margulis pioneered this, proposing eukaryotic cells as bacterial symbiotic communities. Such transitions affirm Darwin's group selection idea, viewing organisms as gene collectives facing "selfish gene" exploits. This advances multilevel selection theory, highlighting genetic social behavior's role in evolutionary dynamics. For instance, human societies, like egalitarian hunter-gatherers, enforce norms for cohesion, echoing social insects' group integration. In the Chewong society, food sharing prevents "punen" (misfortune from unmet desires), reinforcing fair distribution and social harmony. Rituals and fears of animal attacks uphold this behavior despite seeming irrational, showing practical functionality. This view suggests that moral systems drive altruistic behavior beyond kinship or reciprocity. Understanding human social evolution thus necessitates a balanced view of innate psychology and cultural evolution, acknowledging moral systems' roles. The scientific inquiry into these evolving dynamics is an ongoing, fascinating journey.

Evolutionary psychologists Cosmides and Tooby contend that the human mind comprises numerous specialized mechanisms designed for distinct survival challenges rather than a single general-purpose organ. Highlighting examples like migratory birds and desert ants, they illustrate how specialized cognitive circuits have evolved to address survival and reproduction issues. Human adaptations also include mental circuits aiding group formation and moral development, visible in experiments like the robber’s cave and social identity theory. These evolved mechanisms support cooperation and norm enforcement essential for small-scale societies, suggesting that religious behaviors stem from complex psychological structures rather than mere cultural constructs. They propose a blend of innate psychological and cultural systems influencing moral behavior. Despite debates on culture’s nature and relationship to genetic evolution, some see it as an independent process or akin to disease organisms altering individuals. Evolutionary psychologists view the mind as cognitive modules triggered by the environment, sometimes overlooking the role of learning and cultural changes. The author compares cognitive processes to the immune system, advocating a broader understanding beyond specialized modules. This insight emphasizes cultural evolution as adaptive and dynamic, contrasting with genetic determinism. Culture evolves through mechanisms like imitation and group cognition, seen in social insects like honeybees. Larger societies, though less egalitarian, may require status differences for functional operation. Evolution, including cultural dynamics, illuminates adaptability in practices like religion, underlining evolution’s role beyond slow genetic changes. Recognizing group cognition and cohesion influenced by moral systems, the text argues that understanding evolution’s impact needs examining practices like religion through evolutionary biology, considering fitness and morality’s intertwining with religious belief. Such a perspective challenges the view of religion as a misguided scientific endeavor, instead proposing it as an adaptive thought mode. The primary goal is to explore religious groups as adaptive units influenced by multilevel natural selection, offering insights into moral systems and supernatural beliefs' roles in group functionality, with table 1.1 summarizing various hypotheses on religion’s adaptive value. This framework, integrating insights from social sciences, underscores the multifaceted nature of religious practices.
`,
	},
	"demo/darwins_cathederal/chapter_2": {
		index: `CHAPTER 2

THE VIEW FROM THE SOCIAL SCIENCES

A religion is a unified system of beliefs and practices relative to sacred things . . . which unite into one single moral community called a Church, all those who adhere to them.

—Durkheim \[1912\] 1995, 44

What do human beings get from religion? According to Rodney Stark and William Bainbridge, they get what they cannot have.

—Buckser 1995, 1

The scientific study of religion has traditionally been the province of anthropologists, sociologists, and psychologists. Interest in religion began with the framers of these disciplines (e.g., Tylor 1871; Frazer 1890; Durkheim 1912; James 1902) and continues with today’s most sophisticated practitioners. Theories of religion in the social sciences have relied upon evolution to varying degrees, although the historical trend has been in the direction of less, not more. An impressive body of information has accumulated that can be used to test hypotheses, including evolutionary hypotheses that were not in mind when the data was being gathered.

As a newcomer, any modern evolutionary approach to religion must prove itself against these older traditions. One extreme possibility is that evolutionary theory triumphs over the social sciences, which totally missed the boat. Another extreme possibility is that evolutionary theory merely rediscovers what social scientists have long known. To continue the nautical metaphor, an evolutionary theory of religion might be like a rowboat joining a fleet of battleships, with nothing new to offer. A third extreme possibility is that evolutionary theory fails to explain the nature of religion; the battleships sink the rowboat.

The real situation is more complex and interesting than any of these extremes. The hypothesis that I developed in [chapter 1]() is close to a position in the social sciences known as functionalism, which was far more popular during the first half of the twentieth century than today. In fact, the demise of functionalism in the social sciences bears an eerie resemblance to the demise of multilevel selection theory in biology. Taking the organismic concept of groups seriously therefore amounts to a revival of functionalism in the social sciences—not in its original form, which in part deserved its fate, but in a form that can be justified theoretically and verified empirically.

NOW AND THEN

To survey the social science literature on religion, it will help to begin with the present state of the art. Arguably the most dynamic current research program is that of Rodney Stark, William S. Bainbridge, and their colleagues, which is an admirable blend of sociology, anthropology, history, psychology, and economics (Stark and Bainbridge 1985, 1987, 1997; Stark 1996, 1999; Finke and Stark 1992; Stark and Finke 2000). Their work is also impressive for its interplay between theory and empirical research and for the diversity of its research methods, which range from ethnographies of modern-day cults, to nationwide and worldwide survey data, to the ingenious construction of quantitative data bases from historical material. When I first approached this literature, I felt very much like a person in a rowboat pulling alongside a fleet of battleships!

Stark and his colleagues study religion from the perspective of economics and rational choice theory. Religion is envisioned as an economic exchange between people and imagined supernatural agents for goods that are scarce (e.g., rain during a drought) or impossible (e.g., immortal life) to obtain in the real world. Religious belief is therefore rational in the sense of employing cost-benefit reasoning. In addition, many details of religious belief and practice can be predicted from an economic perspective. Stark’s (1999) theory of religion is ambitious: “all aspects of religion—belief, emotion, ritual, prayer, sacrifice, mysticism, and miracle—can be understood on the basis of exchange relations between humans and supernatural beings” (264). I will hereafter refer to this as the rational choice theory of religion.

The paper from which this quotation was obtained is an update of a book-length theory of religion (Stark and Bainbridge 1987). Both versions have the virtue of presenting major propositions in the form of crisp statements accompanied by equally concise definitions of terms. This format allows me to summarize Stark’s latest version of the rational choice theory of religion in his own words, as shown in [table 2.1]().

To facilitate comparison, the hypothesis that religious groups function as adaptive units is summarized as a list of propositions in [table 2.2]().[1]() Groups consist of people who actually interact with each other with respect to the activity at hand, as discussed in [chapter 1](). Remarkably, Stark’s list fails to address the issues at the heart of my list. The essence of Stark’s theory is that goods can either be procured by human action, in which case religious belief is unnecessary (proposition 7), or goods cannot be procured by human action, in which case supernatural agents are invented to provide the unprovidable. We pray to God for everlasting life, not to convey us to work in the morning. As Buckser (1995) puts it in one of the quotations that begin this chapter, according to Stark and Bainbridge religion gives us what we cannot have. Missing entirely from this conception is the category of goods that can be procured by human action, but only by coordinated human action, and the role of religion in achieving the required coordination. In short, Stark’s theory ignores the fundamental problem of social life and the role of religion in its solution.

In evolutionary terms, Stark’s list of propositions would be classified as a byproduct, or “spandrel” explanation. Propositions 1, 2, and 3 describe psychological attributes that are highly adaptive in general and can easily be explained as a product of natural selection. However, their manifestation in the case of religion is not adaptive. If religion does not actually deliver the scarce resources that supernatural agents are invented to provide, the entire enterprise is a waste of time as far as survival and reproduction are concerned. A mutant human race with the ability to employ its psychological attributes only when they deliver worldly benefits, turning them off otherwise, would quickly replace *Homo religiosis.* Religion persists only because people cannot fine-tune their psychological attributes to this degree. Religion is on the cost side of a cost-benefit equation as far as the evolution of human psychology is concerned.

Throughout their writings, rational choice theorists tend to be highly critical of functionalism, portraying it as a dead tradition that by all means should remain buried. At times, Stark is so bitingly satirical that he seems to deny functionalists the capacity for rational thought that he grants to religious zealots. Thus, we seem to have a clear case of a byproduct theory of religion that has triumphed over a theory based on group-level adaptation. However, this impression is superficial. Before I attempt a closer analysis, we need to acquaint ourselves with the tradition of functionalism that appears to have failed so miserably.

DURKHEIM REVISITED

My main exemplar of functionalism will be Emile Durkheim’s *Elementary Forms of Religious Life* (\[1912\] 1995). Prior to Durkheim, the two most influential theories of religion were known as “animism” and “naturism.” According to animism, spiritual belief originated from the experience of dreaming, in which a phantom version of oneself appears capable of leaving the body and traveling long distances. Sleep, fainting, madness, and death all lead to the notion of a world of spirits who enter and leave human bodies at will. Once this world is imagined, it can explain anything:

In this way they constitute a veritable arsenal of causes, always at hand, never leaving the mind that is in search of explanations unequipped. Does a man seem inspired; does he speak with eloquence; does he seem lifted above both himself and the ordinary level of men? It is because a benevolent spirit is in him, animating him. Is another man taken by a seizure or by madness? An evil spirit has entered his body, agitating him. There is no sickness that cannot be put down to some such influence. In this way, the power of souls increases from all that is attributed to them, so much so that, in the end, man finds himself a captive in this imaginary world, even though he is its creator and model. He becomes the vassal of those spiritual forces that he has made with his own hands and in his own image. For if these souls are so much in control of health and illness and of good and evil things, it is wise to seek their benevolence or to appease them when they are annoyed. From thence come offering, sacrifices, prayers—in short, the whole apparatus of religious observances. (Durkheim \[1912\] 1995, 49)

Naturism also portrays the religious believer as a captive in an imaginary world of his own making, but by a different pathway: awe of the forces of nature rather than the experience of dreaming. In modern evolutionary terms, both animism and naturism would be called byproduct theories, similar in spirit, if not in detail, to Stark’s list of propositions. The human capacity for thought is broadly adaptive, but its particular manifestation in the case of religion has no function and can be costly to the extent that it misrepresents the world and leads to inappropriate behaviors. The passage quoted above even anticipates the modern concept of “selfish memes” (Dawkins 1976; Boyer 1994, 2001; Blackmore 1999), which envisions culture as a parasitic organism in its own right that exploits its human host.

Durkheim doubted that something as pervasive and influential as religion could be so dysfunctional. Early humankind lived too close to the edge of survival for such idle theorizing. Beliefs that failed to deliver practical benefits would soon be discarded in favor of more adaptive beliefs.

That man has an interest in knowing the world around him and that, consequently, his reflection was quickly applied to it, everyone will readily accept. The help of the things with which he was in immediate contact was so necessary that he inevitably tried to investigate their nature. But if, as Naturism contends, religious thought was born from these particular reflections, then it becomes inexplicable that religious thought should have survived the first tests made, and unintelligible that religious thought has been maintained. If, in fact, we have a need to know things, it is in order to act in a manner appropriate to them. But the representation of the universe that religion gives us, especially at the beginning, is too grossly incomplete to have been able to bring about practices that had secular utility. According to that representation of the universe, things are nothing less than living, thinking beings—consciousnesses and personalities like those the religious imagination has made into the agents of cosmic phenomena. So it is not by conceiving them in that form and treating them according to that notion that man could have made them helpful to him. It is not by praying to them, celebrating them in feasts and sacrifices, and imposing fasts and privations on himself that he could have prevented them from harming him or obliged them to serve his purposes. Such procedures could have succeeded only on very rare occasions—miraculously, so to speak. If the point of religion was to give us a representation of the world that would guide us in our dealings with it, then religion was in no position to carry out its function, and humanity would not have been slow to notice that fact: Failures, infinitely more common than successes, would have notified them very quickly that they were on the wrong path; and religion, constantly shaken by these constant disappointments, would have been unable to last. (Durkheim \[1912\] 1995, 76–77)

Since religious belief is such a poor representation of the natural world, its “secular utility” must reside elsewhere. Durkheim proposed that religion functions as an organizer of social life, both by defining groups and by prescribing the behaviors of its members. For Durkheim, the essence of religion was a distinction between the sacred and the profane: “A religion is a unified system of beliefs and practices relative to sacred things, that is to say, things set apart and forbidden—beliefs and practices which unite into one single moral community called a Church, all those who adhere to them” (44). The similarity between this passage and the biological concept of human groups unified by moral systems that we arrived at in [chapter 1]() is unmistakable. In modern evolutionary terms, Durkheim interpreted religion as an adaptation that enables human groups to function as harmonious and coordinated units. I take this to be the central thesis of functionalism in the social sciences as it relates to religion.

In addition to framing the central thesis, Durkheim also had a complex and sophisticated vision of exactly how religion performs its functions. He thought that a social group is such an abstract entity that it needs to be represented by a set of symbols to be comprehended by the human mind: “In all its aspects and at every moment of history, social life is only possible thanks to a vast symbolism” (233). Religion is therefore a symbolic representation of society. For example, human tribes are often divided into a number of clans whose membership is based on a complex mix of affinal and genetic relationships. Each clan is represented by a totem (usually an animal or a plant) that identifies clan membership, and associated with each totem are a variety of sacred objects and practices that guide the behavior of clan members. Durkheim felt that the symbolic badge of group membership and the aura of sacredness surrounding prescribed behaviors were required for clans to exist as functioning groups. He also felt that periodic gatherings were required to maintain the integrity of groups. The religious rituals and other festivities held during these gatherings were so emotionally intense that they gave force to group identity when its members were dispersed.

Some of Durkheim’s specific proposals still sound plausible today. For example, Deacon (1998) has recently argued that symbolic thought sets humans apart from all other animals and evolved to enable enforced social contracts such as marriage. If he is correct, it will be an impressive confirmation of Durkheim’s claim that human social life is only possible thanks to a vast symbolism. However, some of Durkheim’s other proposals sound antiquated today; this is hardly surprising, since much has happened in the social sciences since 1912! For our purposes we need to distinguish Durkheim’s general thesis that religion is a group-level adaptation from his many specific proposals about how religion performs its various functions. Was Durkheim right about the central thesis but wrong about some of the details, or was he wrong about the central thesis?

THE NEXT GENERATION

Stark and other rational choice theorists discuss Durkheim in a number of contexts. Stark thinks that Durkheim defined religion too broadly (it should be restricted to belief in supernatural agents) but credits him for correctly distinguishing between religion and magic. In general, however, Stark regards Durkheim’s work in particular and functionalism in general as a paradigm that was rejected long ago and that does not need revisiting, citing the great British anthropologist E. E. Evans-Pritchard (1956, 313), who wrote: “It was Durkheim, not the savage, who made society into a god.”

Unlike Durkheim, Evans-Pritchard lived among the people he studied. Not only are his ethnographies of the Nuer and other African tribes still regarded as classics, but he also wrote a general book on theories of primitive religion (Evans-Pritchard 1965), which makes him a good exemplar of the generation of anthropologists that followed Durkheim.

Evans-Pritchard (1965, 56–64) provides a concise and accurate summary of Durkheim’s theory of religion that culminates in the following assessment:

Durkheim’s thesis is more than just neat; it is brilliant and imaginative, almost poetical; and he had an insight into a psychological fundamental of religion: the elimination of the self, the denial of individuality, its having no meaning, or even existence, save as part of something greater, and other, than the self. But I am afraid that we must once more say that it is a just-so story. (64)

Evans-Pritchard then weighed in on the details of Durkheim’s thesis. As a hardened field anthropologist, he was more interested in the empirical details than in the logic and theory. He did not see a rigid dichotomy between the sacred and profane. When Zande shrines were not in ritual use they served as convenient props for spears. Among the Australian aboriginals whom Durkheim analyzed, it was the co-residential groups and tribes, not the clans identified by separate totems, that functioned as corporate units. Furthermore, Australian totemism provided a poor foundation for a general theory of religion. One can almost hear Evans-Pritchard heaving a sigh of exasperation as he ends his litany with the following statement: “if only Tylor, Marett, Durkheim, and all the rest of them could have spent a few weeks among the peoples about whom they so freely wrote” (67).

Although some of Durkheim’s specific proposals were dismantled by Evans-Pritchard and others of his generation, it would be wrong to conclude that the general thesis of functionalism was similarly dismantled. The passage quoted above singles out the elimination of the self, save as part of something greater, as a psychological fundamental of religion. Evans-Pritchard’s own books are peppered with references to groups as “corporate units.” He might have disagreed with Durkheim on the status of clans as corporate units, but not on the basic existence of groups as corporate units or the role of religion in structuring such groups. Indeed, he is perhaps best known for his concept of segmentation: the organization of leaderless tribes into a nested hierarchy of groups that can become functionally organized at any level, depending on the scale of the environmental challenge (usually warfare).

Evans-Pritchard’s (1956) analysis of Nuer religion is fully consistent with the general thesis of functionalism and the biological concept of human groups that we arrived at in [chapter 1](). In fact, one of his most arresting observations is that Nuer religion is similar to the Judaism of the Old Testament—not because of any historical connection but because both were derived from herding cultures whose lives were dominated by their livestock and their own social affairs. If true, this would be an example of convergent cultural evolution that would be difficult to explain without invoking the concepts of adaptation and natural selection.

[Table 2.3]() lists a number of passages from Evans-Pritchard (1956) that interpret Nuer religion as integral to the functional organization of Nuer society. I hope I will be forgiven for overkill, but it is important to establish that when someone as authoritative as Evans-Pritchard criticized Durkheim, he was not rejecting the interpretation of human groups as adaptive units, the role of religion in structuring society, or even the importance of ritual and symbolism provided by religion. What is true for Evans-Pritchard is also true for the entire generation of anthropologists who followed Durkheim and who account for most of the empirical knowledge of so-called primitive people in something close to their pristine state. To choose another example, Victor Turner (\[1969\] 1995) analyzed religious ritual in terms of two key concepts: communitas and structure. Structure is the system of roles related to age, sex, and status that people in a community occupy. Communitas is a conception of the community as an egalitarian unit in which all members, from highest to lowest, have a moral claim. The purpose of structure is to implement the spirit of communitas. As far as social norms are concerned, prescribed roles are intended to serve the interests of the community and should not be exploited for personal gain.

An incumbent of high status is peculiarly tempted to use the authority vested in him by society to satisfy these private and privative wishes. But he should regard his privileges as gifts of the whole community, which in the final issue has an overright over all his actions. Structure and the high offices provided by structure are thus seen as instrumentalities of the commonweal, not as means of personal aggrandizement. (Turner \[1965\] 1995, 104)

Of course individuals often do abuse the power invested in them by their communities. As we saw in [chapter 1](), human groups achieve their functional organization not entirely by self-restraint (although this can be an important factor) but by mutual vigilance and social control. According to Turner, ritual is one important mechanism that keeps structure and communitas bound to each other. A common feature of ritual in both traditional and modern societies involves the stripping away of status, especially during the transition from one social role to another. One memorable example from Gabon involves the election of a new king, who is chosen secretly by the village elders and is kept ignorant of his fate until the following event occurs:

It happened that Njogoni, a good friend of my own, was elected. The choice fell on him, in part because he came of a good family, but chiefly because he was a favourite of the people and could get the most votes. I do not think that Njogoni had the slightest suspicion of his elevation. As he was walking on the shore on the morning of the seventh day \[after the death of the former king\] he was suddenly set upon by the entire populace, who proceeded to a ceremony which is preliminary to the crowning and must deter any but the most ambitious man from aspiring to the crown. They surrounded him in a dense crowd, and then began to heap upon him every manner of abuse that the worst of mobs could imagine. Some spat in his face; some beat him with their fists; some kicked him; others threw disgusting objects at him; while those unlucky ones who stood on the outside, and could reach the poor fellow only with their voices, assiduously cursed him, his father, his mother, his sisters and brothers, and all his ancestors to the remotest generation. A stranger would not have given a cent for the life of him who was presently to be crowned.

Amid all the noise and struggle, I caught the words which explained all this to me; for every few minutes some fellow, administering a specially severe blow or kick, would shout out, “You are not our king yet; for a little while we will do what we please with you. By-and-by we will have to do your will.”

Njogoni bore himself like a man and prospective King. He kept his temper, and took all the abuse with a smiling face. When it had lasted about half an hour they took him to the house of the old king. Here he was seated, and became again for a little while the victim of his people’s curses.

Then all became silent; and the elders of the people rose and said, solemnly (the people repeating after them), “now we choose you for our king; we engage to listen to you and to obey you.” He was then dressed in a red gown, and received the greatest marks of respect from all who had just now abused him. (from Du Chaillu 1868; quoted in Turner \[1965\] 1995, 171)

This passage wonderfully illustrates the spirit of egalitarianism that pervades human communities long after they have become structurally hierarchical. Turner does not comment or provide evidence for the effectiveness of such humbling rituals in curtailing selfish behavior, which should be an important objective for future research. However, the meaning and intention of such rituals, as interpreted by Turner, is highly consistent with the conception of human groups unified by moral systems that we arrived at in [chapter 1]().

Until recently, the only way to learn about the customs of so-called primitive people was through the writing of Western anthropologists. Increasingly, however, members of these cultures are speaking for themselves. An interesting example is Malidoma Patrice Somé, a member of the West African Dagara culture, who has attempted to interpret the nature of ritual for an American audience (Somé 1997). According to Some, rituals and social responsibilities are “inseparable” (11). [Table 2.4]() lists representative passages that gratifyingly support the central thesis of Durkheim, Evans-Pritchard, Turner, and many other anthropologists of their generations. The connection between religion and functionally organized society is not just a figment of Durkheim’s or of the Western imagination.

FUNCTIONALISM TODAY

So far I have shown that functionalism was not rejected by the anthropologists who followed Durkheim, including those who lived among the people they studied. When and why, then, was functionalism rejected? There is no single answer to this question, since the social sciences are a vast archipelago of disciplines that only partially communicate with each other. The prevailing wisdom about functionalism varies among disciplines, even for the study of religion (see Allen et al. 1998 for a recently published volume celebrating Durkheim’s *Elementary Forms of Religious Life,* in contrast to the disparaging views of most rational choice theorists). This kind of fragmentation within the social sciences is regrettable, especially for those, such as myself, who are attempting to forge an even larger synthesis between the social sciences and biology.

The most comprehensive modern assessment of functionalism can be obtained from philosophers, who are better than most practicing scientists at synthesizing across disciplines. A useful selection of philosophical articles on functionalism and the closely related subject of holism has been compiled by Martin and McIntyre (1994). These articles raise a number of issues that need to be examined from a modern evolutionary perspective. The following discussion will help to revive functionalism throughout the social sciences and will pave the way to our study of religion.

**Holism**

The idea that the whole is somehow more than the sum of its parts is one of the most common and also one of the most vaguely articulated themes associated with functionalism. Durkheim was eager to create a science of sociology and was not prone to mysticism. He was happy to concede that the social organism could exist only within individual minds, but he nevertheless insisted that a sociological level of explanation existed that could not be reduced to individual behavior. The alternative to Durkheim’s view became known as methodological individualism, described by Watkins (\[1957\] 1994, 442) as follows:

According to this principle, the ultimate constituents of the social world are individual people who act more or less appropriately in the light of their dispositions and understanding of their situation. Every complex social situation, institution, or event is the result of a particular configuration of individuals, their dispositions, situations, beliefs, and physical resources and environment. There may be unfinished or halfway explanations of large-scale phenomena (say, inflation) in terms of other large-scale phenomena (say, full employment); but we shall not have arrived at rock-bottom explanations of such large-scale phenomena until we have deduced an account of them from statements about the dispositions, belief, resources and interrelations of individuals. . . . And just as mechanism is contrasted with the organicist idea of physical fields, so methodological individualism is contrasted with sociological holism or organicism.

Methodological individualism swept through the social sciences and eclipsed “organicism” at about the same time that the theory of individual selection swept through evolutionary biology, eclipsing multilevel selection theory. Nevertheless, these two forms of individualism are very different from each other, as I will show. In addition, it might surprise some readers to learn that the extreme reductionism expressed by Watkins has not withstood critical scrutiny, enabling philosopher Elliott Sober (1999) to state: “If there is now a received view among philosophers of mind and philosophers of biology about reductionism, it is that reductionism is mistaken.”

The most relevant form of holism for our purposes is based on the concept of adaptation. Consider all the artificial selection experiments that have been conducted on fruit flies (*Drosophila*): they have been given short wings, long wings, no wings, many bristles, few bristles—the list goes on and on. The question “Why do these particular fruit flies have this particular phenotype?” has two answers. First, every phenotype is caused mechanistically by genes that interact with each other and their environment during development. Second, the phenotype exists because of a history of selection for that phenotype, coupled with heritable variation. These two explanations are usually labeled “proximate” and “ultimate” respectively, and there is a sense in which the latter is more fundamental than the former. As one classic example, Cohan (1984) divided a single population of fruit flies into a number of isolated smaller populations. He then selected the same trait (wing vein length) in each isolated population, examining the response to selection and the underlying genetic mechanisms in each case. It turned out that the same phenotypic trait of long wing veins evolved by different genetic mechanisms. A single ultimate-level explanation sufficed for all the populations, but different proximate-level explanations were required. More generally, the natural world is full of species that have evolved similar solutions to life’s problems (e.g., hard exteriors as protection from predators), even though they are composed of different genes and physical materials (e.g., chitin for beetles, cellulose for plant seeds, and calcium carbonate for snails).

In short, heritable variation and selection provide a solid foundation for the holistic claim that the parts permit the properties of the whole but do not cause the properties of the whole.[2]() A lump of clay permits but does not cause the form provided by the sculptor. To the extent that the physical make-up of organisms provides heritable variation, it becomes a malleable clay that can be sculpted by selection. Evolutionary biologists rely upon this kind of holism all the time. They confidently predict that desert animals should be sandy colored, a bird’s wing should be aerodynamically efficient, and small fish should be timid in the presence of predators without any reference whatsoever to the genes or physical material that make up these organisms. Proximate explanation (“the sandy color in this species is caused by chromatin granules, which are coded by genes on the fourth chromosome”) complements ultimate explanation (“the sandy color is caused by a history of selection favoring cryptic coloration”) but never substitutes for it.

The distinction between proximate and ultimate explanation, which lies at the heart of evolutionary analysis and which will figure importantly in our study of religion, stands in contrast to Watkins’s use of the word “ultimate” in the passage quoted above. For Watkins, the whole can only be truly understood in terms of the interactions among its parts, which are its “ultimate” constituents. This might be true for objects that have not been molded by natural selection. If you are handed a mineral and asked to explain its properties, what else can you do but look at its parts and their interactions? However, the molding action of natural selection endows the word “ultimate” with a new meaning that gives the whole priority over its clay-like parts. That is why the theory of individual selection, which relies heavily on the concept of adaptation, is different from methodological individualism, which relies heavily on the concept of mechanistic reductionism (Wilson 1988).

So far I have used individual organisms as the wholes in my discussion of holism. I have shown that Watkins’s negative comments about “organicism” are mistaken when applied to creatures such as an insect, a fish, or a person. Multilevel selection theory allows us to frame-shift the entire discussion upward, in which the wholes are social groups and the parts are their individual members. To the degree that groups are units of selection, they possess properties that are permitted but not caused by their individual members. This is exactly what Durkheim and other functionalists were reaching for, which the tradition of methodological individualism erroneously seemed to deny. A position in the social sciences that in the past appeared wooly-minded and mystical can be placed on a rock-solid evolutionary foundation.

**Complexity**

Adaptationism is the most relevant form of holism/functionalism for the purposes of this book. Another form of holism/functionalism, based on complex interactions, needs to be distinguished and set aside even though it is interesting and important in its own right.[3]() Consider the famous examples of water and salt, whose properties are difficult to predict from their parts (hydrogen and oxygen in the case of water and sodium and chloride in the case of salt). This concept of holism is based on complex interactions rather than functional organization. Salt and water have no purpose; their properties simply reside mostly in the interactions among their parts rather than in the properties of the parts as isolated units. In the same way, functionalism in the social sciences often seems to stress complexity and interconnectedness rather than functional organization per se (e.g., Malinowski 1944, 158–59). One example is a book called *Dynamic Functionalism* (Faia 1986), which stresses complex feedback processes and multiple stable equilibria (“absorbing Markov chains”). Along with Kincaid (in Martin and McIntyre 1994, 417), I think that this rendering of functionalism “casts the net too widely.” I take it as a given that human cultures and social interactions are tremendously complex and interconnected, like water and salt only more so. Unfortunately, dysfunction can be as complex and locally stable as function, so the term “functionalism” should be avoided for concepts of holism based on complexity and restricted to the direct or indirect products of natural selection.

**Functionalism and multilevel selection**

Virtually everyone who has written on functionalism agrees that it is a legitimate form of explanation for individual-level adaptations that evolved by natural selection. There is nothing wrong with saying that the heart functions to circulate blood, that the turtle’s shell functions to protect it from predators, etc., as long as these traits really did evolve by natural selection for the reasons that are ascribed to them. The problem with functionalism begins when we attempt to explain the properties of groups in general and especially human groups, for which the influence of natural selection is not so obvious. The rejection of group selection by evolutionary biologists and hostility toward evolutionary approaches to human behavior by many social scientists combined over the years to restrict functional explanation to the individual properties of nonhuman species.

I fully agree that functional explanations must be judged by the same criteria in evolutionary biology and in the social sciences. What has changed is the likelihood that the criteria are satisfied for the properties of groups in general and human groups in particular. Since philosophers and social scientists already acknowledge the legitimacy of functionalism at the individual level in nonhuman species when warranted by natural selection, the developments in evolutionary biology that I outlined in [chapter 1]() automatically set the stage for the return of group-level functionalism in the social sciences.

**Just-so stories**

A common criticism of adaptationist hypotheses in biology and functionalist hypotheses in the social sciences is that they are difficult to test. The derogatory term “just-so story,” an allusion to the fanciful tales of Rudyard Kipling, was used by Evans-Pritchard against Durkheim (see the passage quoted above) long before Gould and Lewontin (1979) used it against what they regarded as adaptationist excesses in biology.

Of course, no one would dream of saying outright “this hypothesis is false because it is difficult to test.” Science is a labor-intensive process, and some of the most important nuts are also the most difficult to crack. The “just-so story” criticism of functionalism implicitly assumes that nonfunctionalist hypotheses are easier to test and can substitute for functionalist hypotheses. Neither of these assumptions is likely to be true. I have already discussed the fact that proximate and ultimate explanations do not substitute for each other. In addition, adaptationism enjoys its status in evolutionary biology in part because it is *simpler* to employ than nonfunctionalist approaches. Often only a little knowledge suffices to make an initial prediction about the properties of organisms that enhance fitness in their environments (e.g., fish in streams with predators should be more timid than fish in streams without predators). In contrast, predictions based on phylogeny, genetics, development, and physiology require far more effort. As with predictions, so also with testing. Why should the hypothesis that fish are timid in the presence of predators be more difficult to test than, say, the hypothesis that fish development constrains heritable variation? Mature research programs in biology pay equal attention to ultimate and proximate explanation, but they often begin with an adaptationist hypothesis that provides the best and most economical “first guess” about the properties of the organism (see Hempel 1959, reprinted in Martin and McIntyre 1994, 371, for a similar view of functionalism in the social sciences). Indeed, discrepancies between adaptationist predictions and the properties of real organisms often lead to the discovery of nonadaptive factors that would have been missed otherwise. If we discover that fish are not timid in the presence of predators, despite the fact that it would increase their fitness, we might be tempted to look for factors that constrain adaptation and natural selection.

I do not mean to underestimate the challenge of testing functionalist hypotheses in evolutionary biology or in the social sciences. However, it is equally excessive to regard functionalism in general as a giant compendium of just-so stories that are somehow immune to scientific inquiry. The fact is that with enough hard work, evolutionary biologists are able to demonstrate the presence or absence of adaptations beyond all reasonable doubt. The quality of the science and the reliability of its conclusions are as good as for any other field of inquiry.

Because I intend to use standard evolutionary methods to study religion, it will help to show how they are successfully used to study adaptations in nonhuman species. When they aren’t in pet stores and household aquaria, guppies (*Peocilia reticulata*) live in tropical streams that typically include dangerous fish predators in their downstream but not in their upstream portions. Since predators are a major source of mortality for guppies, we can predict that downstream and upstream populations become locally adapted to the presence and absence of predators, respectively. This hypothesis can be tested with at least three different sources of evidence, most usefully in combination with each other (reviewed by Endler 1986, 1995).

The first source of evidence is based on the argument from design. An object designed for a given purpose must have certain properties to achieve its purpose, which are unlikely to have arisen by chance. The more numerous, complex, and interlocking the design features, the more compelling the evidence for their designed nature. William Paley (1805) popularized the argument from design as evidence for God, but in fact it only provides evidence for a designing agent—the hand of God, a human engineer, alien visitors from another planet, or the process of natural selection. Thus, if we are studying organisms and if we exclude special creation and alien designers from other planets from consideration, we are left with design as a source of evidence of evolutionary adaptation. In the case of guppies, predator avoidance involves a suite of morphological, behavioral, and life history traits that would be difficult to explain in other ways. Endler (1995) provides a list of forty-seven traits that have been examined so far. One of these is age at first reproduction. In a downstream environment where every day might be a guppy’s last, it is adaptive to have babies as soon as possible. In an upstream environment where the predators are so ineffective that only small guppies are in danger, it is adaptive to grow to a large size before starting to have babies. Upstream guppies are therefore predicted to have a later age of first reproduction than downstream guppies. When predictions such as this one are confirmed for a large suite of traits, it provides compelling evidence for adaptation and natural selection.

The argument from design can be based on the properties of a single organism or structure (e.g., the eye, or Paley’s example of a watch, which is so elaborately constructed for a purpose that it couldn’t exist by chance). The second source of evidence expands the view to include a comparison of organisms that occupy different environments. If natural selection adapts organisms to their environment, then the organisms should change as the environment changes (in more technical language, there should be a phenotype-environment correlation). Not only should downstream guppies have a suite of traits adapting them to the presence of predators, but upstream guppies should have another suite of traits adapting them to the absence of predators. Moreover, the geographical range of guppies includes dozens of river systems that have been separated from each other for millions of years. The river systems differ in their particular predator species, geochemistry, and other features, but all have the same downstream-upstream gradient of predator risk, providing a natural replicated experiment. In some cases the transition between upstream and downstream is amazingly abrupt, as when a waterfall acts as a barrier for the predator species but not for the guppies. In these cases, guppies that live only a few meters apart from each other (on each side of the waterfall) should differ in their phenotypic traits. If the upstream-downstream differences are found again and again in separate river systems, the adaptationist hypothesis receives powerful support. Subtle differences between river systems can also provide additional evidence. For example, in some streams the major predator is a crustacean rather than a fish. Crustaceans have a different visual system than vertebrates and are blind to the color orange, which gives their guppy prey a private wavelength for displaying to each other while remaining cryptic to their predators. It turns out that male guppies in the presence of fish predators are cryptic to the vertebrate eye, while male guppies in the presence of crustacean predators are ablaze with orange spots.

The third source of evidence involves tracking the evolutionary process. The ultimate proof of an adaptation is to actually watch it evolve. Natural selection was once assumed to be such a slow process that only the products, and not the process, could be directly observed. This view has been shattered by dozens of empirical studies, as eloquently described by Weiner (1994) in his Pulitzer prize-winning book *The beak of the finch.* In the case of guppies, downstream fish transplanted to upstream tributaries have evolved the upstream suite of traits within ten generations. To determine that predators were the causative agent, the same experiment was performed in the laboratory with identical physical environments that differed only in the presence and absence of predators. Other selection experiments altered the size and color of the gravel that forms the physical background against which guppies are seen by their predators. Since avoiding predators requires matching one’s background, changing the spots in the environment actually changed the spots on the guppies in only a few generations (Endler 1986). Could there be a more convincing demonstration of organisms as a reflection of their environment?

When all three sources of evidence are taken together, any reasonable person must conclude that guppies are locally adapted to the presence and absence of predators in their environments. Even creationists have accepted this conclusion for evolutionary research on microevolution, which in part has caused them to shift their definition of “natural kind” to a higher taxonomic scale. This does not mean that guppies are perfectly adapted in every way or that constraints on the process of natural selection can be ignored. As one example, Houde and Hankes (1997) studied two populations in which females preferred orange-colored spots in males, but in only one of these populations had the males responded to sexual selection by evolving orange spots. More work is required to determine the factors that seem to have constrained natural selection in this case.

It is gratifying that empirical research can achieve the middle ground between functionalism and its alternatives that so often is lost in polemical debates. In addition, evolutionary methods for studying adaptations in nonhuman species can be applied to the study of religion, as I will attempt to show in subsequent chapters. While certain kinds of research on humans are off-limits for obvious and well-justified ethical reasons, other kinds of research can be performed more easily on humans than on other species. In addition, solid progress can be made on the basis of descriptive information and “natural experiments” that exist in abundance for religions around the world and throughout history. Rather than complaining about the difficulty of testing functionalist hypotheses, we need to roll up our sleeves and start using our proven tools on the material at hand.

**Intentional behavior**

Human behavior is often goal oriented, and the implements people employ to achieve goals are correspondingly functional. If I lock myself out of my house and fetch a ladder to enter the upstairs window, the function of the ladder is to enable me to reach the window. The function of the lock and key is to enable me to gain access to my house while keeping others out, even if I occasionally lock myself out as well. Human life is awash with this kind of functionality, which exists at the level of groups in addition to individuals. A business corporation might be intricately designed by its executives to maximize profits. The very word corporation, which is derived from the Latin word for “body,” implies functional organization above the level of the individual.

In an influential analysis of modes of scientific explanation, Elster (1983) properly distinguishes causal (proximate) explanation from functional (ultimate) explanation. However, he then tries to make another distinction between functional explanation and intentional explanation. My efforts to discuss functionalism with social scientists frequently run aground on this distinction, which therefore requires our attention.

Let’s begin with biology, which Elster agrees provides the foundation for functionalism. Consider a species of zooplankton with a peculiar spike on its head. Suppose we conduct sufficient research to establish that the spike is an antipredator adaptation. Elster presumably would agree that the function of the spike is to protect the individual from predators. Now consider another species of zooplankton that is developmentally flexible. No spike develops when predators are absent but the presence of predators is sensed chemically and triggers the development of the spike. Suppose we conduct sufficient research to establish that the developmental mechanism is also an adaptation. In fact, the second species is historically derived from the first species. Its developmental flexibility allows it to “have its cake and eat it too,” by dispensing with the spike when it is not needed.

Many examples of adaptive flexibility (also called “phenotypic plasticity”) have accumulated in the biological literature. Mentality is not required; bacteria and plants can be adaptively flexible. It is easy to show theoretically that flexibility is favored in some kinds of environments but not others (Wilson and Yoshimura 1994). Some species (including humans) might even consist of a mix of developmentally flexible and inflexible genotypes (Wilson et al. 1994). I want to claim that adaptive flexibility does not change the functional interpretation of phenotypes. The function of the spike in both zooplankton species is to protect the individual from predators. The species differ in the proximate mechanisms that evolved to produce the spike, but that difference does not alter the functional interpretation of the spike. Similarly, guppies cannot change their spots as individuals and therefore require the passage of generations to match their background. Flounders, octopi, and many other species can change their color as individuals and can match their background in a few moments. In both cases the function of matching one’s background is to avoid predators.

My claim should be uncontroversial, but what is human intentionality but an elaborate mechanism of environmental assessment, built by natural selection, that culminates on balance in adaptive phenotypes? Allman’s (1999) panoramic review of brain evolution illustrates my point by starting with the brain-like functions of bacteria:

Some of the most basic features of brains can be found in bacteria because even the simplest motile organisms must solve the problem of locating resources and avoiding toxins in a variable environment. Strictly speaking, these unicellular organisms do not have nervous systems, but nevertheless they exhibit remarkably complex behavior: They sense their environment through a large number of receptors and store this elaborate sensory input in the form of brief memory traces. Moreover, they integrate the inputs from these multiple memory sensory channels to produce adaptive movements. The revolution in our understanding of genetic mechanisms has made it possible to determine how these brainlike processes work at a molecular level in bacteria. (Allman 1999, 3)

Real brains have the same function of transforming environmental information into adaptive phenotypes. Human brains may be unique in their ability to process symbolic information (as argued by Deacon 1998), but that does not alter their basic function or the functionality of the activities that are motivated by human thought. If a person knowingly fashions a spear to ward off predators, why on earth should we avoid the conclusion that the function of the spear is to ward off predators, just because intentional thought was involved?

Elster’s distinction between functional and intentional explanation seems so strange that the reader may wonder if I am misrepresenting his position. Therefore, consider his own example of how to explain the profit-maximizing behavior of business firms (Elster 1983, 57–58). Evidently, the Chicago school of economists determined that firms were maximizing their profits but that the members of the firms were largely unaware of the specific practices responsible for their success. This finding led the economists to speculate that the successful practices had evolved by a process of selection; firms vary in ways unknown to their members, and the best outcompete the worst. Another possibility is that members of firms recognize and imitate success, even if they don’t understand how the specific practices that they imitate lead to success. In this case, the best practices spread by imitation rather than by the actual survival and reproduction of firms. According to Elster, only the raw evolutionary process of differential survival and reproduction qualifies as a functional explanation. Even spread by imitation qualifies as an intentional explanation. This is like saying that a spear cannot be explained by its function if the spear-maker knows what he is making, or even if he blindly imitates another person who owns a spear and brings home more game.

The evolutionary distinction between ultimate and proximate explanation can help us avoid this nonsensical conclusion while retaining the distinction that I suspect Elster is trying to make. The first and foremost question we must ask is whether an object of study counts as functional: are its properties designed to accomplish a given effect? A spear is a spear is a spear, regardless of whether it is made by intentional thought, blind imitation, or an even blinder process of differential survival and reproduction. The next question is to determine the designing agent or process. Is it the hand of God, a selection process, or an organism that itself is a product of a selection process? It is remarkable how well the first question can be answered without knowledge about the answer to the second question. William Harvey discovered the function of the heart and circulatory system centuries before Darwin. He was wrong about the designing agent but right about the function of the heart. The Chicago school of economists discovered the profit-maximizing behavior of firms without needing to settle the issue of imitation vs. takeover. This is one reason to regard intentional thought as one of several possible proximate mechanisms that create function rather than as an alternative to functional explanation.

If the designing agent is an organism, a new set of questions comes to the fore. In the case of humans, we might especially want to know if function can be attributed to the mental processes that Elster classifies as intentional. Thus, Elster’s distinction remains important but can be appreciated while avoiding the bizarre consequences of treating intentional and functional explanations as fundamentally different from each other.

**Latent and manifest functions**

Despite my disagreement with Elster, there is a sense in which he correctly interprets the functionalist debate. Functionalists were not simply pointing out the functions of intentional behaviors that were already manifestly obvious. They were claiming latent functions for practices and institutions at a grand scale that were not products of conscious intentional thought. Stated in evolutionary terms, Elster thinks that conscious intentional thought is the only proximate mechanism that makes human life functional. There are no latent functions beyond our awareness, only those of which we are already conscious. If this position is correct, then functionalism as an intellectual tradition would be dead.

However, this position is completely untenable, based on the evolutionary principles outlined in [chapter 1](). Functionality in human life can be attributed to at least three proximate mechanisms beyond the conscious intentional mechanisms emphasized by Elster: (1) psychological processes at the individual level that lie beneath conscious awareness; (2) group-level processes that individuals partake in without conscious knowledge of their roles; and (3) ongoing processes of cultural evolution.

With respect to individual psychology, Elster evidently regards all animal mentality and unconscious human mentality as simple forms of associative learning, which makes the possibility of unconscious intentions inconceivable to him:

It follows from this argument that the notion of unconscious intentions is no more coherent than that of a squared circle. It does not follow, however, that it is impossible to make sense of the notion of the unconscious, if we conceive of it strictly as a mechanism for climbing along a pleasure-gradient. It would be absurd to impute to the unconscious the capacity for waiting, for making sacrifices, for acting according to rules, etc., for these modes of behaviour all presuppose consciousness. (Elster 1983, 71–72)

Unfortunately for Elster, the trend in cognitive, evolutionary, and social psychology has been steadily away from this view toward ever more sophisticated, special purpose, unconscious information processing systems in both humans and other animals—so much that the concept of consciousness has become precarious and speculative (Allman 1999; Damasio 1994; Deacon 1998; Rolls 1998). Individual behavior is replete with latent functions, before we even proceed to the level of groups.

With respect to group psychology, fuzzy concepts of “social organisms” and “group minds” were easy prey for the seemingly hard-headed individualism and reductionism of the last few decades. However, I have already shown how the circuitry that we associate with “mind” can exist among a network of individuals as easily as among a network of neurons when groups are the units of selection. Examples are already known for the social insects, and finding comparable examples for humans might be primarily a matter of deciding that they are possible before we can see them clearly.[4]() In any case, the more individuals act as participants in a group mental process, the less likely they are to be consciously aware of the process.

With respect to ongoing evolutionary processes, I have already shown in [chapter 1]() that what we loosely define as “culture” is in part a Darwin machine that produces phenotypic variation and heritability at the group level. If cultural phenotypic variation has functional consequences, it is hard to avoid the conclusion that at least some properties of present-day cultures owe their existence directly to the winnowing process of natural selection. In addition, it would be naive to expect people always to be aware of this source of function in their lives.

Since cultural adaptation as a direct product of cultural evolution has always been acceptable evidence for functionalism, it may surprise some readers that compelling examples can be found in the social sciences literature. Perhaps the best example is the Nuer, the African pastoralist tribe whose religion was described earlier in this chapter (summarized by Kelly 1985).[5]() Linguistic evidence shows that the Nuer were historically derived from the Dinka, a neighboring tribe that shared the same environment and subsistence economy. Nevertheless, the Nuer and Dinka differed culturally in ways that gave the Nuer both a stronger incentive to raid cattle and the ability to field a larger fighting force in intertribal conflict. As a result, the Nuer were in the process of replacing the Dinka when they were contacted by anthropologists in the 1800s. If the “Nuer conquest” (actually the cumulative result of many independent raids and not an active campaign) had not been halted by the British and Egyptian administration, there would probably be no Dinka tribe for anthropologists to study.

The features of Nuer culture that accounted for their need to expand and their competitive superiority are complex and multifaceted, including brideprice customs that influenced herd management practices and a kinship system that enabled settlements to join together in war even after they had stopped interacting with respect to subsistence. Not all cultural differences between the two tribes are functional; there is plenty of room for what in evolutionary terms would be called byproduct explanations. Nevertheless, decades of anthropological research have established a convincing example of cultural replacement that can be causally attributed to cultural differences in which even the phylogenetic relationship of the two cultures is well understood. This example is generally thought by anthropologists to represent a common process of cultural replacement, even if other examples have not been documented to the same extent. As Darwin said, at all times throughout the world, tribes have supplanted other tribes. In addition, there is not the slightest hint that either the Nuer or the Dinka were aware of their differences or tried to consciously manage their cultures to succeed in inter-tribe competition. The cultural differences simply emerged and were stable enough to persist, with important functional consequences.

Closer to home are the cultural differences among regions of the United States that are derived from differences among the original colonists, and which remain discernible after centuries (Fischer 1989; Nisbett and Cohen 1996; Phillips 2000). It is likely that the outcome of the American Civil War was based as much on the long-term consequences of cultural variation as on environmental differences between the North and South. A third example is Putnam’s (1993) exquisitely documented study of the patterns of cultural variation in Italy—patterns that have remained stable for a millennium, with profound functional consequences in the context of today’s socioeconomic environment. Putnam’s study illustrates the halting and inefficient nature of cultural evolution in addition to some of its basic ingredients. Cultural evolution may be fast in comparison to genetic evolution, but it can still require many human lifetimes. In addition, cultural variation does not always result in cultural evolution. Majority effects, spatial effects, and other factors complicate the concept of fitness for cultural and biological evolution alike, as I discussed in [chapter 1]() (see also Michod 1999a).

In none of these examples is there the slightest hint that people are aware of the functionally important features of their cultures, nor is there any compelling theoretical reason to expect them to. Indeed, Putnam (1993) pessimistically concludes that the deep structure of many contemporary human societies might prevent them from achieving the social goals for which they are intentionally striving. Similarly, Tocqueville (1835) observed that although the Mexican constitution was patterned after the American constitution, Mexico remained very different from the United States. Something mysterious that we don’t understand, which in our ignorance we refer to as “custom” or “culture,” is so important that it accounts for the fate of whole peoples and nations. It is a delusion that everything functional in human affairs is consciously intended. Evolutionary biologists and human social scientists should work together to understand the evolutionary processes that create latent functions in our species.

RATIONAL CHOICE THEORY REVISITED

Our progress so far can be summarized as follows: I began by describing rational choice theory as one of the most vigorous approaches to religion in the social sciences. It seems to reject functionalism in favor of a byproduct theory of religion, based on the general human tendency to seek explanations and employ cost-benefit reasoning. Then I examined the rejected tradition of functionalism, arguing that rumors of its death have been greatly exaggerated. The anthropologists who followed Durkheim did not reject functionalism on the basis of their greater field experience, and the most important objections raised by philosophers and social scientists must be revised on the basis of the evolutionary principles outlined in [chapter 1]().

Now I will show that the byproduct theory of religion is not nearly as robust as it is often taken to be. Before I criticize the rational choice literature, however, I must acknowledge some of its strengths. In may ways, it has been a productive research program and a model of scientific inquiry. It is a great achievement to develop a theory of religion based on the same principles that govern secular behavior. A good theory generates many testable hypotheses. A really good theory passes at least some of the tests. The rational choice theory of religion qualifies as a good theory by both of these criteria.

What, then, is left to criticize? There are a number of ways to bring religion under the umbrella of rational choice theory. One is to explain religion as the economic mind spinning its wheels to get what it can’t have (a byproduct). Another is to explain religion as more genuinely utilitarian, producing resources that can be had but only through the beliefs and social organization provided by religion or a comparable system (an adaptation). Stark’s formal theory of religion is strongly committed to the first approach, as his own list of propositions attests. However, the larger rational choice literature on religion, including some of Stark’s own work, is not so committed and slips easily between these two forms of explanation.

Just as evolutionary theory can explain religion in many different ways, which I classified in [table 1.1](), many economic theories of religion exist that must be distinguished from each other. The individual who maximizes his own self-interest lies at the core of economic theory, which bears a superficial resemblance to individual selection theory in evolution. However, economics also offers a theory of the firm, in which groups are envisioned as the adaptive units. Mother Teresa poses no problem for economic theory because she employs cost-benefit reasoning to maximize her own peculiar utility of helping others (Kwilecki and Wilson 1998). If I sacrifice my time and hard-earned money praying to imaginary gods for resources that are not forthcoming, I fall within economic theory because I am employing cost-benefit reasoning, based on my beliefs (Stark 1999).

Clearly, economic theory shares with evolutionary theory the capacity to explain vastly different concepts of religion—but that is a weakness as much as a strength. If a theory can’t distinguish among such different concepts and pit them against each other with empirical tests, what good is it? To make progress we must take a stand on a specific concept. I am taking a stand on the concept of religious groups as adaptive units, which allows me to aim a highly specific criticism at the rational choice literature: It *seems* to reject the concept I am evaluating, when in fact it does nothing of the sort. The situation is strikingly similar to the rejection of group selection in evolutionary biology in favor of theories that in fact included group selection within their own structure.

This problem pervades the rational choice literature but can be illustrated with a single example. In an article entitled “Voodoo Economics? Reviewing the Rational Choice Approach to Religion,” Iannaccone (1995) compares the rational choice approach with alternative approaches as follows:

The basic issue, after all, is whether people attend to costs and benefits and act so as to maximize their net benefits. The principal alternative is unreflective action based on habit, norms, emotion, neurosis, socialization, cultural constraints, or the like—action that is largely unresponsive to changes in perceived costs, benefits, or probabilities of success. (81–82)

For decades, scholars have scrutinized religion from every angle except that of rational choice. Explanations of religious phenomena have stressed socialization, indoctrination, neurosis, cognitive dissonance, tradition, deviance, deprivation, functionalism, the role of emotions, the impact of culture and more. But rarely has anyone viewed religion as the product of cost-benefit decisions, and formal models of the religious behavior (rational or otherwise) scarcely exist. (86)

The appearance of functionalism so far down the list of alternatives shows how low its fortunes have sunk. In another passage Iannaccone includes “boundary maintenance” (82) as a specific function of religion that can be discarded along with everything else in this giant house-cleaning of the social sciences. Against this background, consider Iannaccone’s own work. In two influential articles, he shows how seemingly inefficient and bizarre features of religion such as distinctive dress, dietary restrictions, and costly sacrifice can be adaptive (he uses the word “rational”) by turning the religion into an exclusive club that excludes free-riders (Iannaccone 1992, 1994). Those who seek to selfishly exploit the church will be deterred by the costs and lost opportunities of membership. Those who do become members will work hard for the common good because their other options have been so circumscribed by their religion. They will benefit from their efforts because free-riders have been weeded out of the group. Iannaccone’s theory accounts for the paradoxical fact, first noted by Kelly (1972), that churches are strong and vigorous in direct proportion to their strictness.

Iannaccone’s theory is elegant, and I will discuss it in more detail in [chapter 5](). But is it a rational choice theory of religion that stands in contrast to an earlier, functionalist theory? For Iannaccone, the answer is obviously “yes” because cost-benefit reasoning is required for the free-riders and club members to respond to the religion as predicted by the theory. Fair enough. But how did the religion acquire its structure that adaptively constrains the choices of utility-maximizers in just the right way? We must explain the structure of the religion in addition to the behavior of individuals once the structure is in place. Were the bizarre customs consciously invented by rational actors attempting to maximize their utilities? If so, why did they have the utility of maximizing the common good of their church? Must we really attribute all adaptive features of a religion to a psychological process of cost-benefit reasoning? Isn’t a process of blind variation and selective retention possible? After all, thousands of religions are born and die without notice because they never attract more than a few members (Stark and Bainbridge 1985). Perhaps the adaptive features of the few that survive are like random mutations rather than the product of rational choice.

Were it not for the vagaries of history and the shifting fashions of intellectual thought, Iannaccone’s theory would qualify as a fine example of functionalism. Durkheim never denied cost-benefit religious reasoning. Recall the passage quoted earlier, which begins: “That man has an interest in knowing the world around him and that, consequently, his reflection was quickly applied to it, everyone will readily accept.” He went further to say that religious belief is abandoned when it fails to have secular utility. It was Durkheim’s insistence on secular utility that led him to reject the byproduct theories of his day and to explain religion as fundamentally functional for its members. The challenge for Durkheim was to interpret the many features of religion that appear to lack function as having latent functions. Iannaccone could accurately be described as a modern Durkheim who has revealed the latent functions of religion, including the all-important function of boundary marking, that serve to increase the collective utility of its members. Instead, he regards himself as a rational choice theorist and lumps boundary marking in particular and functionalism in general along with a meaningless jumble of other concepts as outside rational choice theory. The fact that Iannaccone’s theory explains how religion provides real benefits for its members (an adaptation) rather than the illusion of getting what they can’t have (a byproduct) is not perceived as a problem. Who needs byproduct theories or functionalism when economics offers the theory of the firm?

THE FUTURE OF FUNCTIONALISM

I began this book by saying that many subjects have a long, hard road to travel before they can advance by way of the textbook portrayal of the scientific method. Functionalism is such a subject. Over a century of effort hasn’t even come close to resolving some of the most fundamental questions that can be asked about human behavior and social organization. The worst that can be said about functionalism is that it failed to fulfill itself as a research program during its heyday. Functionalism wasn’t falsified; it merely went out of fashion.

Two major developments in intellectual thought may allow functionalism to succeed as a research program in the future, despite its past failures. The first is progress in evolutionary biology, which provides the foundation for functional explanations of all kinds. When Evans-Pritchard (1965) reviewed theories of primitive religion, he described Durkheim’s theory as “sociological” in contrast to a different and rejected class of “evolutionary” theories. What Evans-Pritchard meant by evolution would be unrecognizable today. Advances include not only multilevel selection theory (a very recent development) but also the integration of ecology, evolution, and behavior, the mature empirical study of adaptations, and modern evolutionary approaches to human behavior. If evolution is the foundation of functionalism, then there is a new foundation upon which to build.

The second major development is the unification of the human social sciences, which I described earlier as a vast archipelago of disciplines that only partially communicate with each other. My status as an outsider makes it easy for me to island-hop the social sciences, and I am struck by the lack of consistency. To pick an example, anthropologists interested in cultural change, even those who regard themselves as anti-Darwinian, tend to emphasize non-intentional processes while neglecting the possibility of rational choice. Cultures don’t choose their destiny; it simply happens to them through processes of which they are largely unaware. To question this largely unstated assumption, Boehm (1996) searched the ethnographic literature for case studies of how cultures respond to emergency events, such as warfare or natural disasters. In each case, the people responded by meeting as a group to discuss their options in a highly practical and rational fashion. Boehm’s demonstration of a rational component to cultural change was new and important against the background of his particular discipline, although he would never claim that rational planning accounts for all cultural change. Contrast this configuration of ideas with Elster’s extraordinary statement that “intentional explanation is the feature that distinguishes the social sciences from the natural sciences” (1983, 69). Then contrast Elster’s reliance on conscious thought with the brain and behavioral sciences literature in which discussions of consciousness are reserved for the final chapters of books, with profuse apologies for their tentative nature (e.g., Rolls 1998)!

You know there is a problem when one man’s heresy is another man’s commonplace. It signals the need to step back and rebuild the social sciences from first principles, making the various subdisciplines consistent with each other and with evolutionary biology. One contribution that evolutionary biology can make to this enterprise is the classification outlined in [table 1.1](), which makes a fundamental distinction between functional vs. nonfunctional explanation and a secondary distinction between individual vs. group-level functional explanation. When functional explanations are warranted, the distinction between ultimate and proximate causation becomes critical. These are among the most basic distinctions that can be made from an evolutionary perspective, and they need to be preserved within the social sciences. As we have seen, rational choice theory slides so easily among these categories that they are scarcely recognized as categories. All subdisciplines of the social sciences need to appreciate that functional explanations must be handled with care, and that group-level functional explanations require the greatest care of all. Human groups cannot lightly be described as adaptive units, but if they can be rigorously shown to function as adaptive units, that will be a major scientific accomplishment.

A second contribution that evolutionary biology can make to rebuilding the social sciences is to provide a more sophisticated theory of psychology. As we have seen, rational choice theory is often presented as a psychological theory that attempts to explain the length and breadth of human nature with a few axioms about how people think. Alas, physics might be reducible to a few fundamental laws but not psychology. The human mind is a melange of adaptations and spandrels that have accumulated over millions of years, during which both culture and life in groups have been integral parts of the evolutionary process. Cost-benefit reasoning is an important part of human (and animal) psychology but not the only part. Tooby and Cosmides (1992) criticized learning theory in psychology for achieving the illusion of physics-like generality only by losing the ability to predict the specific content of what animals learn. The same criticism applies with equal force to rational choice theorists, who generally do not even attempt to predict the specific content of the utility that is supposedly maximized. This weakness, and evolutionary biology’s strength in comparison, will become evident in subsequent chapters.

There was a time when individualism reigned supreme both in evolutionary biology and in the human social sciences, creating an image of the individual as the only adaptive unit (or rational actor) in nature and of the group as merely a byproduct of what individuals do to each other. Those days are over. I stated at the beginning of [chapter 1]() that science is not a frictionless pendulum destined to swing forever between extreme positions. Evolutionary biology is settling into a middle position that acknowledges the potential for adaptation and natural selection at all levels of the biological hierarchy, especially in the case of human evolution. Group-level adaptation is here to stay in evolutionary biology, and the human social sciences must follow suit to remain true to first principles. Now that the organismic concept of groups has emerged from its intellectual wilderness, let us see how well it describes the nature of religion
`,
		half: `### The View From The Social Sciences

A religion is essentially a cohesive system of beliefs and rituals concerning sacred entities, which forms a moral community known as a Church amongst its followers, as posited by Durkheim \[1912\] 1995, 44. But what do people truly gain from religion? Rodney Stark and William Bainbridge argue that individuals acquire something unattainable through other means.

In his 1995 work, Buckser delves into the complexities of identity and cultural expressions within the context of Greenlandic Inuit societies. He meticulously examines how modernization interacts with tradition, highlighting the constant negotiation individuals undergo to balance multiple identities. Buckser's insightful analysis underscores the resilience of cultural practices amidst external influences, providing a nuanced understanding of how tradition and modernity coexist and shape each other. Through his detailed exploration, Buckser offers a profound narrative that reveals the dynamic and adaptive nature of cultural identity.

The scientific study of religion has often been led by anthropologists, sociologists, and psychologists, dating back to the foundational work of Tylor in 1871, Frazer in 1890, Durkheim in 1912, and James in 1902. Though historically these fields favored evolutionary explanations to varying extents, current trends show a movement away from such perspectives. Nevertheless, substantial data collected over the years offers a rich body of evidence for testing various hypotheses, including those grounded in evolutionary theory. Any modern evolutionary approach to religion must compete with these established traditions, which range from potentially overshadowing the social sciences to merely rediscovering known knowledge or failing completely. The reality is more nuanced, resembling the historical trajectory of functionalism in social sciences, which lost favor mid-twentieth century similarly to the decline of multilevel selection theory in biology. Reviving the organismic view of groups suggests a return to functionalism, albeit in a modern, theoretically robust, and empirically verifiable form.

To survey the social science literature on religion, it's beneficial to start with the current state of the art, notably the dynamic research program led by Rodney Stark, William S. Bainbridge, and their colleagues. Their work admirably combines sociology, anthropology, history, psychology, and economics (Stark and Bainbridge 1985, 1987, 1997; Stark 1996, 1999; Finke and Stark 1992; Stark and Finke 2000). This body of work impresses with its integration of theory and empirical research, employing diverse methods from ethnographies of modern-day cults to extensive survey data and constructing quantitative databases from historical materials. Approaching this comprehensive literature felt much like a person in a rowboat pulling alongside a fleet of battleships!

Stark and his colleagues approach religion through the lens of economics and rational choice theory, suggesting it as an economic exchange between humans and imagined supernatural agents for unattainable goods like rain during a drought or immortality. Stark posits that religious belief is rational as it involves cost-benefit reasoning and asserts that various elements of religious belief and practice, such as prayer and sacrifice, can be understood through these economic exchanges (Stark, 1999). Stark and Bainbridge's 1987 and 1999 works distill their rational choice theory into clear propositions, summarized effectively in the paper's tables. However, Stark's theory misses the crucial role of religion in coordinating human actions to procure goods that require cooperation, reflecting a byproduct or "spandrel" explanation rather than an adaptive one. While rational choice theorists critique functionalism sharply, often with satirical disdain, dismissing it as outdated, this stance may overlook the adaptive functions of religion in social life. To better understand this, we must revisit the functionalist tradition, as suggested by Durkheim.

My principal example of functionalism is Emile Durkheim’s *Elementary Forms of Religious Life* (\[1912\] 1995). Before Durkheim, the main theories of religion were “animism” and “naturism.” Animism posited that spiritual belief stems from dreams where a phantom self ventures out, leading to a belief in spirits that can explain anything, thereby creating a religious framework involving offerings, sacrifices, and prayers. Naturism, on the other hand, attributed religious belief to awe of nature’s forces. Both theories are seen as byproducts of human cognition, potentially costly by misrepresenting the world. Durkheim countered that religion, being so pervasive, had practical benefits; early humans, needing functional beliefs for survival, would discard ineffective ideas. He argued that if religion were purely about understanding the world, it would have failed due to its incomplete representation of the universe, leading humanity to recognize its inefficacy. Thus, religious practices would have rapidly vanished if they didn’t prove helpful, which they evidently did, according to Durkheim.

Since religious belief poorly represents the natural world, its utility, according to Durkheim, lies in organizing social life by defining groups and prescribing member behaviors. Durkheim argued that religion hinges on the distinction between the sacred and the profane, forming unified moral communities, or Churches, through beliefs and practices related to sacred things. This parallels the biological concept of human groups unified by moral systems. Durkheim viewed religion as an evolutionary adaptation enhancing group harmony and coordination, a core thesis of functionalism in social sciences. He posited that social life, reliant on vast symbolism, requires symbols for abstract entities like social groups. Religion acts as this symbolic representation, exemplified by clans identified through totems and sacred practices. These symbolic badges and the sacredness surrounding behaviors help clans function, maintained through emotionally intense religious rituals and gatherings. Some of Durkheim's ideas, such as the necessity of symbolic thought for social contracts like marriage, still resonate today, though others appear outdated. Stark and rational choice theorists critique Durkheim's broad definition of religion, favoring a focus on supernatural agents, and regard his work and functionalism as largely obsolete, quoting E.E. Evans-Pritchard's dismissive view of Durkheim's deification of society. For our purposes, it's crucial to separate Durkheim's general thesis of religion as a group-level adaptation from his specific, sometimes outdated proposals.

Evans-Pritchard, unlike Durkheim, immersed himself among the people he studied, making significant ethnographic contributions on African tribes like the Nuer. While he admired Durkheim’s imaginative and poetic insights into the psychological fundamentals of religion, such as the elimination of self and denial of individuality in favor of a greater community, Evans-Pritchard critiqued the empirical basis of Durkheim’s theories. He argued that the rigid division between the sacred and profane, and the use of Australian totemism to generalize about religion, were flawed. Evans-Pritchard emphasized the importance of studying societies firsthand, suggesting that this would have given theorists like Tylor and Marett a more nuanced understanding. Despite his criticisms, Evans-Pritchard’s work aligned with functionalist views, recognizing the role of religion in organizing social groups, exemplified by his analysis of Nuer religion and societal segmentation. Victor Turner’s work resonated similarly, describing religious rituals as mechanisms to balance communitas and social structure, highlighting how high status should serve community interests rather than personal gain. Rituals play a crucial role in maintaining this balance, as illustrated by scenes of communal abuse and deferment of status in Gabonese king elections, reinforcing internal social controls over individual power.

Njogoni's endurance during his initiation as King, where he endured abuse with a calm demeanor, illustrates the resilience expected of a leader. The passage also reflects the deep-rooted egalitarian spirit in human communities, despite their hierarchical structures. This ritual, as interpreted by Turner, aligns with the notion of human groups unified by moral systems. Meanwhile, functionalism's persistence, despite being sidelined in some social science disciplines, demonstrates its enduring relevance. Its modern reassessment, particularly through philosophers' synthetic views, reveals the necessity of examining functionalism through evolutionary perspectives. Durkheim's holistic approach, emphasizing society's emergent properties beyond individual behaviors, contrasts sharply with methodological individualism. Reductionism, though critiqued, fails to address the holistic nature molded by natural selection—highlighting that parts permit but do not cause the properties of the whole. This concept is applicable to social groups where, according to multilevel selection theory, group dynamics and properties are emergent from yet not reducible to individual actions. Thus, Durkheim's "organicism," seemingly mystical before, rests on robust evolutionary theories today.



Adaptationism is the most pertinent form of holism/functionalism for this book, necessitating a distinction from another form based on complex interactions, exemplified by the properties of water and salt arising from their part interactions rather than functional organization. This complex interaction-based holism ties in with social sciences' emphasis on interconnectedness, as seen in works like Dynamic Functionalism (Faia 1986), focusing on feedback processes and stable equilibria. However, concepts labeled as functionalism that merely reflect complexity should be avoided, restricting functionalism to traits shaped by natural selection. While individual-level adaptations, like the heart's role in circulating blood, are widely accepted as functionalism, complications arise when explaining group properties, especially in human groups, due to the less obvious influence of natural selection and the historical resistance by evolutionary biologists and social scientists to group selection and evolutionary approaches to human behavior.

I strongly believe that functional explanations should be evaluated using the same criteria in both evolutionary biology and the social sciences. The key difference now is the increased likelihood of these criteria being satisfied for the properties of groups, especially human groups. Philosophers and social scientists already accept individual-level functionalism in nonhuman species, so advancements in evolutionary biology naturally pave the way for the return of group-level functionalism in social sciences. A frequent critique of adaptationist and functionalist hypotheses is their perceived difficulty in testing, often labeled as "just-so stories." However, such criticisms often overlook that nonfunctionalist hypotheses are not necessarily easier to test nor can they replace functionalist ones. Adaptationism remains popular in evolutionary biology due to its simplicity in forming initial hypotheses, requiring less effort compared to alternatives like phylogeny or genetics. Testing functionalist hypotheses is challenging but not immune to scientific inquiry. Evolutionary biologists have demonstrated the existence of adaptations in various organisms, including guppies, through multiple robust methods. For example, guppies display different traits based on predator presence in their environments, a phenomenon supported by various forms of evidence such as the argument from design, phenotype-environment correlations, and direct evolutionary observations. As I aim to apply these evolutionary methods to study religion, it's clear that despite the inherent challenges, substantial progress can be made by leveraging descriptive information and natural experiments. Rather than dismissing the difficulty, we should embrace it and utilize proven tools to further our understanding.

Human behavior is typically goal-oriented, with the tools people use being highly functional. For instance, if I lock myself out of my house and use a ladder to enter through an upstairs window, the ladder's function is to help me reach the window. Similarly, locks and keys function to secure my house while allowing me access, even if I sometimes lock myself out. This kind of functionality pervades human life, extending beyond individuals to groups. For example, a business corporation, intricately designed by its executives, aims to maximize profits. The term "corporation," from the Latin word for "body," suggests a functional organization at a level higher than the individual.

Elster (1983) distinguishes between causal and functional explanations in the context of scientific understanding but also differentiates functional explanation from intentional explanation, which complicates discussions with social scientists about functionalism. To clarify, let's consider biology as the foundation of functionalism: a zooplankton species develops a spike as an antipredator adaptation, and another species shows adaptive flexibility by developing the spike only when predators are present. Both scenarios highlight that the function of the spike is predator protection, regardless of the different developmental mechanisms. This concept extends to other species and adaptations, such as guppies and flounders, and their predator-avoidance strategies. The overarching claim is that adaptive flexibility does not alter the functional interpretation of phenotypes. Human intentionality, seen as an elaborate mechanism of environmental assessment, has evolved through natural selection, leading to adaptive phenotypes. Allman (1999) further supports this by showing how even bacteria exhibit brain-like functions, integrating sensory inputs to produce adaptive behaviors, illustrating the evolutionary roots of complex brain functions.

Human brains, much like other brains, transform environmental information into adaptive phenotypes and are unique in processing symbolic information. Elster’s distinction between functional and intentional explanations, such as profit-maximizing business behaviors, oversimplifies this transformation. The Chicago school found that firms optimized profits without conscious forethought, implying an evolutionary selection process, contrary to Elster's stance that only differential survival qualifies as functional. Intentional thought or imitation is one of many proximate mechanisms, making this distinction unnecessary. Elster's view dismisses latent functions, unseen processes underpinning human adaptation, but these exist at individual, group, and cultural levels. Contrary to Elster's focus on conscious intent, evolving understanding shows sophisticated unconscious processes in humans and animals. Group dynamics function similarly, with evident examples in social insects and evolving human parallels. Cultural evolution, as seen with tribes like the Nuer and Dinka or regions in Italy and the US, also demonstrates latent functions driving societal changes without conscious management. Functional differences, often unperceived, can shape entire cultures and their historical trajectories, suggesting a profound, unconscious evolutionary influence in human life.

Our progress so far can be summarized as follows: I began by describing rational choice theory as one of the most vigorous approaches to religion in the social sciences, which appears to reject functionalism in favor of a byproduct theory of religion based on the general human tendency to seek explanations and employ cost-benefit reasoning. Subsequently, I examined the rejected tradition of functionalism, contending that rumors of its death have been greatly exaggerated. Contrary to popular belief, the anthropologists who followed Durkheim did not reject functionalism due to their greater field experience, and the most important objections raised by philosophers and social scientists must be revised based on the evolutionary principles outlined in chapter 1.

The byproduct theory of religion is often viewed as robust, but my critique aims to demonstrate its limitations. However, before delving into criticisms, it’s essential to recognize the rational choice literature's strengths. This theory has facilitated productive research and embodies scientific inquiry by generating many testable hypotheses and passing some of these tests. Rational choice theory can encompass various explanations of religion: one views it as an economic mind's futile effort (a byproduct), and another as providing unique resources through its beliefs and social organization (an adaptation). Although Stark's formal theory adheres to the byproduct approach, broader rational choice literature oscillates between these explanations. Much like how evolutionary theory offers multiple explanations for religion, so does economic theory, which mirrors individual selection theory but also includes theories of groups or 'firms' as adaptive units. The theory's ability to explain diverse concepts of religion is both its strength and its weakness. For real progress, a specific concept must be chosen and examined. I adopt the stance that religious groups act as adaptive units, criticizing the rational choice literature for seeming to reject this notion while implicitly accepting it—similar to the misunderstanding of group selection in evolutionary biology. This issue pervades the rational choice literature, as exemplified by Iannaccone’s article, which contrasts rational choice with alternatives like unreflective action driven by habit, emotions, or cultural constraints.

For decades, scholars have analyzed religion through various lenses, such as socialization, indoctrination, neurosis, and functionalism, but rarely through rational choice. Iannaccone’s work, in contrast, uses rational choice theory to explain how seemingly inefficient religious practices, like distinctive dress and dietary restrictions, serve to create exclusive communities by deterring free-riders. His theory posits that high membership costs ensure that those who join work for the collective good, thus strengthening the church—a view that aligns with Kelly's observation that stricter churches are more vigorous. This perspective challenges traditional functionalism by suggesting that religious structures evolve to maximize utility, much like a firm in economics. Despite Iannaccone’s association with rational choice theory, his work can be seen as modern functionalism, revealing the latent, community-enhancing functions of religious practices. This shifts the burden from explaining individual behaviors to understanding how religious structures adaptively evolve. Durkheim's ideas resonate here, as he saw religious belief as functional and abandoned when it lacks secular utility. Thus, Iannaccone can be viewed as updating Durkheim for the rational choice framework by demonstrating how religion provides tangible benefits rather than merely byproducts of other processes, indicating a need to reconsider the merits of functionalism in light of rational theories.

Functionalism may yet succeed as a research program, thanks to two significant developments in intellectual thought: advancements in evolutionary biology and the unification of the human social sciences. Recent progress in evolutionary biology, such as multilevel selection theory and the integration of ecology, evolution, and behavior, provides a robust foundation for functional explanations. This contrasts with past views on evolution and its dismissal in the study of primitive religion. Simultaneously, the human social sciences, fragmented and inconsistent across disciplines, need to be rebuilt from first principles, aligning with evolutionary biology. Rational choice theory, often overemphasized, must acknowledge the multifaceted nature of human psychology, which is shaped by a myriad of adaptations over millions of years. The once dominant view of the individual as the sole adaptive unit is giving way to a recognition of group-level adaptations. Evolutionary biology's acceptance of adaptation and natural selection at various levels, particularly regarding humans, challenges the social sciences to follow suit. The organismic concept of groups, now gaining acceptance, will be explored further in explaining the nature of religion.
`,
		quarter: `A religion, according to Durkheim \[1912\] 1995, 44, is a coherent system of beliefs and rituals regarding sacred entities, which forms a moral community or Church among its adherents. Rodney Stark and William Bainbridge contend that religion provides individuals with something unattainable by other means. Buckser (1995) explores the intricate dynamics of identity and cultural expressions within Greenlandic Inuit societies, emphasizing how modernization and tradition coexist and shape each other. His work highlights the resilience of cultural practices amid external influences, presenting a nuanced narrative of cultural identity's adaptive nature. The scientific study of religion, historically led by anthropologists, sociologists, and psychologists, dates back to pioneers like Tylor, Frazer, Durkheim, and James. Although these fields initially favored evolutionary explanations, contemporary trends are moving away from such perspectives. A modern evolutionary approach to religion must contend with these established traditions and extensive data. Like the historical decline of functionalism in social sciences and multilevel selection theory in biology, reviving the organismic view of groups suggests a return to a modern, theoretically robust, and empirically verifiable functionalism.

To survey the social science literature on religion, it's crucial to start with the dynamic research program by Rodney Stark, William S. Bainbridge, and their colleagues, which integrates sociology, anthropology, history, psychology, and economics (Stark and Bainbridge 1985, 1987, 1997; Stark 1996, 1999; Finke and Stark 1992; Stark and Finke 2000). Their approach uses diverse methods, combining theory and empirical research, to explore religion through the lens of economics and rational choice theory. Stark posits that religious belief involves rational cost-benefit reasoning and interprets elements like prayer and sacrifice as economic exchanges with imagined supernatural agents for unattainable goods. However, Stark's theory could overlook religion's role in coordinating human cooperation, a view championed by functionalist theories such as those of Emile Durkheim. Durkheim's "Elementary Forms of Religious Life" ([1912] 1995) critiques prior theories of animism and naturism, emphasizing that religion offers practical survival benefits by organizing social life and defining group behaviors. He argues that religion's distinction between the sacred and the profane unites moral communities and enhances group harmony through symbolic representation and emotionally intense rituals. While some of Durkheim's ideas appear outdated today, his view of religion as an evolutionary adaptation remains influential, contrary to Stark and other rational choice theorists who criticize functionalism and regard Durkheim's work as obsolete. It’s essential to distinguish Durkheim's general thesis of religion as a group-level adaptation from his specific, historical proposals.

Evans-Pritchard's immersive ethnographic studies of African tribes, such as the Nuer, presented him as a critic of Durkheim's theories, particularly the rigid sacred-profane division and the generalization from totemism. Despite this, he respected Durkheim’s insights into religion's psychological roles and aligned with functionalist views recognizing religion's societal organization role. Victor Turner echoed these sentiments, seeing religious rituals as balancing individual and communal interests. Evans-Pritchard advocated for firsthand social studies for nuanced understanding, a view opposed to methodological individualism. Evolutionary perspectives have revived functionalism, challenging reductionism by emphasizing emergent group's properties. Adaptationism and evolutionary biology underscore the functional dynamics in social sciences. Functionalist hypotheses, albeit complex to test, prove insightful, exemplified by cases like guppies' predator-specific traits. Rational choice theory, productive in its hypothesis generation, can integrate functionalism, suggesting religious groups act as adaptive units, contrary to the byproduct theory. Developments in evolutionary biology and the unified social sciences envisage a robust foundation for functionalism, recognizing group-level adaptations and the intricate nature of human psychology. The concept of organismic groups now gains acceptance, paving a way to reexamine the nature of religion from a functionalist perspective.
`,
	},
	"demo/paul_graham/great_work": {
		index: `How to Do Great Work

July 2023

If you collected lists of techniques for doing great work in a lot of different fields, what would the intersection look like? I decided to find out by making it.

Partly my goal was to create a guide that could be used by someone working in any field. But I was also curious about the shape of the intersection. And one thing this exercise shows is that it does have a definite shape; it's not just a point labelled "work hard."

The following recipe assumes you're very ambitious.

The first step is to decide what to work on. The work you choose needs to have three qualities: it has to be something you have a natural aptitude for, that you have a deep interest in, and that offers scope to do great work.

In practice you don't have to worry much about the third criterion. Ambitious people are if anything already too conservative about it. So all you need to do is find something you have an aptitude for and great interest in. \[1\]

That sounds straightforward, but it's often quite difficult. When you're young you don't know what you're good at or what different kinds of work are like. Some kinds of work you end up doing may not even exist yet. So while some people know what they want to do at 14, most have to figure it out.

The way to figure out what to work on is by working. If you're not sure what to work on, guess. But pick something and get going. You'll probably guess wrong some of the time, but that's fine. It's good to know about multiple things; some of the biggest discoveries come from noticing connections between different fields.

Develop a habit of working on your own projects. Don't let "work" mean something other people tell you to do. If you do manage to do great work one day, it will probably be on a project of your own. It may be within some bigger project, but you'll be driving your part of it.

What should your projects be? Whatever seems to you excitingly ambitious. As you grow older and your taste in projects evolves, exciting and important will converge. At 7 it may seem excitingly ambitious to build huge things out of Lego, then at 14 to teach yourself calculus, till at 21 you're starting to explore unanswered questions in physics. But always preserve excitingness.

There's a kind of excited curiosity that's both the engine and the rudder of great work. It will not only drive you, but if you let it have its way, will also show you what to work on.

What are you excessively curious about — curious to a degree that would bore most other people? That's what you're looking for.

Once you've found something you're excessively interested in, the next step is to learn enough about it to get you to one of the frontiers of knowledge. Knowledge expands fractally, and from a distance its edges look smooth, but once you learn enough to get close to one, they turn out to be full of gaps.

The next step is to notice them. This takes some skill, because your brain wants to ignore such gaps in order to make a simpler model of the world. Many discoveries have come from asking questions about things that everyone else took for granted. \[2\]

If the answers seem strange, so much the better. Great work often has a tincture of strangeness. You see this from painting to math. It would be affected to try to manufacture it, but if it appears, embrace it.

Boldly chase outlier ideas, even if other people aren't interested in them — in fact, especially if they aren't. If you're excited about some possibility that everyone else ignores, and you have enough expertise to say precisely what they're all overlooking, that's as good a bet as you'll find. \[3\]

Four steps: choose a field, learn enough to get to the frontier, notice gaps, explore promising ones. This is how practically everyone who's done great work has done it, from painters to physicists.

Steps two and four will require hard work. It may not be possible to prove that you have to work hard to do great things, but the empirical evidence is on the scale of the evidence for mortality. That's why it's essential to work on something you're deeply interested in. Interest will drive you to work harder than mere diligence ever could.

The three most powerful motives are curiosity, delight, and the desire to do something impressive. Sometimes they converge, and that combination is the most powerful of all.

The big prize is to discover a new fractal bud. You notice a crack in the surface of knowledge, pry it open, and there's a whole world inside.

Let's talk a little more about the complicated business of figuring out what to work on. The main reason it's hard is that you can't tell what most kinds of work are like except by doing them. Which means the four steps overlap: you may have to work at something for years before you know how much you like it or how good you are at it. And in the meantime you're not doing, and thus not learning about, most other kinds of work. So in the worst case you choose late based on very incomplete information. \[4\]

The nature of ambition exacerbates this problem. Ambition comes in two forms, one that precedes interest in the subject and one that grows out of it. Most people who do great work have a mix, and the more you have of the former, the harder it will be to decide what to do.

The educational systems in most countries pretend it's easy. They expect you to commit to a field long before you could know what it's really like. And as a result an ambitious person on an optimal trajectory will often read to the system as an instance of breakage.

It would be better if they at least admitted it — if they admitted that the system not only can't do much to help you figure out what to work on, but is designed on the assumption that you'll somehow magically guess as a teenager. They don't tell you, but I will: when it comes to figuring out what to work on, you're on your own. Some people get lucky and do guess correctly, but the rest will find themselves scrambling diagonally across tracks laid down on the assumption that everyone does.

What should you do if you're young and ambitious but don't know what to work on? What you should not do is drift along passively, assuming the problem will solve itself. You need to take action. But there is no systematic procedure you can follow. When you read biographies of people who've done great work, it's remarkable how much luck is involved. They discover what to work on as a result of a chance meeting, or by reading a book they happen to pick up. So you need to make yourself a big target for luck, and the way to do that is to be curious. Try lots of things, meet lots of people, read lots of books, ask lots of questions. \[5\]

When in doubt, optimize for interestingness. Fields change as you learn more about them. What mathematicians do, for example, is very different from what you do in high school math classes. So you need to give different types of work a chance to show you what they're like. But a field should become increasingly interesting as you learn more about it. If it doesn't, it's probably not for you.

Don't worry if you find you're interested in different things than other people. The stranger your tastes in interestingness, the better. Strange tastes are often strong ones, and a strong taste for work means you'll be productive. And you're more likely to find new things if you're looking where few have looked before.

One sign that you're suited for some kind of work is when you like even the parts that other people find tedious or frightening.

But fields aren't people; you don't owe them any loyalty. If in the course of working on one thing you discover another that's more exciting, don't be afraid to switch.

If you're making something for people, make sure it's something they actually want. The best way to do this is to make something you yourself want. Write the story you want to read; build the tool you want to use. Since your friends probably have similar interests, this will also get you your initial audience.

This should follow from the excitingness rule. Obviously the most exciting story to write will be the one you want to read. The reason I mention this case explicitly is that so many people get it wrong. Instead of making what they want, they try to make what some imaginary, more sophisticated audience wants. And once you go down that route, you're lost. \[6\]

There are a lot of forces that will lead you astray when you're trying to figure out what to work on. Pretentiousness, fashion, fear, money, politics, other people's wishes, eminent frauds. But if you stick to what you find genuinely interesting, you'll be proof against all of them. If you're interested, you're not astray.

Following your interests may sound like a rather passive strategy, but in practice it usually means following them past all sorts of obstacles. You usually have to risk rejection and failure. So it does take a good deal of boldness.

But while you need boldness, you don't usually need much planning. In most cases the recipe for doing great work is simply: work hard on excitingly ambitious projects, and something good will come of it. Instead of making a plan and then executing it, you just try to preserve certain invariants.

The trouble with planning is that it only works for achievements you can describe in advance. You can win a gold medal or get rich by deciding to as a child and then tenaciously pursuing that goal, but you can't discover natural selection that way.

I think for most people who want to do great work, the right strategy is not to plan too much. At each stage do whatever seems most interesting and gives you the best options for the future. I call this approach "staying upwind." This is how most people who've done great work seem to have done it.

Even when you've found something exciting to work on, working on it is not always straightforward. There will be times when some new idea makes you leap out of bed in the morning and get straight to work. But there will also be plenty of times when things aren't like that.

You don't just put out your sail and get blown forward by inspiration. There are headwinds and currents and hidden shoals. So there's a technique to working, just as there is to sailing.

For example, while you must work hard, it's possible to work too hard, and if you do that you'll find you get diminishing returns: fatigue will make you stupid, and eventually even damage your health. The point at which work yields diminishing returns depends on the type. Some of the hardest types you might only be able to do for four or five hours a day.

Ideally those hours will be contiguous. To the extent you can, try to arrange your life so you have big blocks of time to work in. You'll shy away from hard tasks if you know you might be interrupted.

It will probably be harder to start working than to keep working. You'll often have to trick yourself to get over that initial threshold. Don't worry about this; it's the nature of work, not a flaw in your character. Work has a sort of activation energy, both per day and per project. And since this threshold is fake in the sense that it's higher than the energy required to keep going, it's ok to tell yourself a lie of corresponding magnitude to get over it.

It's usually a mistake to lie to yourself if you want to do great work, but this is one of the rare cases where it isn't. When I'm reluctant to start work in the morning, I often trick myself by saying "I'll just read over what I've got so far." Five minutes later I've found something that seems mistaken or incomplete, and I'm off.

Similar techniques work for starting new projects. It's ok to lie to yourself about how much work a project will entail, for example. Lots of great things began with someone saying "How hard could it be?"

This is one case where the young have an advantage. They're more optimistic, and even though one of the sources of their optimism is ignorance, in this case ignorance can sometimes beat knowledge.

Try to finish what you start, though, even if it turns out to be more work than you expected. Finishing things is not just an exercise in tidiness or self-discipline. In many projects a lot of the best work happens in what was meant to be the final stage.

Another permissible lie is to exaggerate the importance of what you're working on, at least in your own mind. If that helps you discover something new, it may turn out not to have been a lie after all. \[7\]

Since there are two senses of starting work — per day and per project — there are also two forms of procrastination. Per-project procrastination is far the more dangerous. You put off starting that ambitious project from year to year because the time isn't quite right. When you're procrastinating in units of years, you can get a lot not done. \[8\]

One reason per-project procrastination is so dangerous is that it usually camouflages itself as work. You're not just sitting around doing nothing; you're working industriously on something else. So per-project procrastination doesn't set off the alarms that per-day procrastination does. You're too busy to notice it.

The way to beat it is to stop occasionally and ask yourself: Am I working on what I most want to work on? When you're young it's ok if the answer is sometimes no, but this gets increasingly dangerous as you get older. \[9\]

Great work usually entails spending what would seem to most people an unreasonable amount of time on a problem. You can't think of this time as a cost, or it will seem too high. You have to find the work sufficiently engaging as it's happening.

There may be some jobs where you have to work diligently for years at things you hate before you get to the good part, but this is not how great work happens. Great work happens by focusing consistently on something you're genuinely interested in. When you pause to take stock, you're surprised how far you've come.

The reason we're surprised is that we underestimate the cumulative effect of work. Writing a page a day doesn't sound like much, but if you do it every day you'll write a book a year. That's the key: consistency. People who do great things don't get a lot done every day. They get something done, rather than nothing.

If you do work that compounds, you'll get exponential growth. Most people who do this do it unconsciously, but it's worth stopping to think about. Learning, for example, is an instance of this phenomenon: the more you learn about something, the easier it is to learn more. Growing an audience is another: the more fans you have, the more new fans they'll bring you.

The trouble with exponential growth is that the curve feels flat in the beginning. It isn't; it's still a wonderful exponential curve. But we can't grasp that intuitively, so we underrate exponential growth in its early stages.

Something that grows exponentially can become so valuable that it's worth making an extraordinary effort to get it started. But since we underrate exponential growth early on, this too is mostly done unconsciously: people push through the initial, unrewarding phase of learning something new because they know from experience that learning new things always takes an initial push, or they grow their audience one fan at a time because they have nothing better to do. If people consciously realized they could invest in exponential growth, many more would do it.

Work doesn't just happen when you're trying to. There's a kind of undirected thinking you do when walking or taking a shower or lying in bed that can be very powerful. By letting your mind wander a little, you'll often solve problems you were unable to solve by frontal attack.

You have to be working hard in the normal way to benefit from this phenomenon, though. You can't just walk around daydreaming. The daydreaming has to be interleaved with deliberate work that feeds it questions. \[10\]

Everyone knows to avoid distractions at work, but it's also important to avoid them in the other half of the cycle. When you let your mind wander, it wanders to whatever you care about most at that moment. So avoid the kind of distraction that pushes your work out of the top spot, or you'll waste this valuable type of thinking on the distraction instead. (Exception: Don't avoid love.)

Consciously cultivate your taste in the work done in your field. Until you know which is the best and what makes it so, you don't know what you're aiming for.

And that is what you're aiming for, because if you don't try to be the best, you won't even be good. This observation has been made by so many people in so many different fields that it might be worth thinking about why it's true. It could be because ambition is a phenomenon where almost all the error is in one direction — where almost all the shells that miss the target miss by falling short. Or it could be because ambition to be the best is a qualitatively different thing from ambition to be good. Or maybe being good is simply too vague a standard. Probably all three are true. \[11\]

Fortunately there's a kind of economy of scale here. Though it might seem like you'd be taking on a heavy burden by trying to be the best, in practice you often end up net ahead. It's exciting, and also strangely liberating. It simplifies things. In some ways it's easier to try to be the best than to try merely to be good.

One way to aim high is to try to make something that people will care about in a hundred years. Not because their opinions matter more than your contemporaries', but because something that still seems good in a hundred years is more likely to be genuinely good.

Don't try to work in a distinctive style. Just try to do the best job you can; you won't be able to help doing it in a distinctive way.

Style is doing things in a distinctive way without trying to. Trying to is affectation.

Affectation is in effect to pretend that someone other than you is doing the work. You adopt an impressive but fake persona, and while you're pleased with the impressiveness, the fakeness is what shows in the work. \[12\]

The temptation to be someone else is greatest for the young. They often feel like nobodies. But you never need to worry about that problem, because it's self-solving if you work on sufficiently ambitious projects. If you succeed at an ambitious project, you're not a nobody; you're the person who did it. So just do the work and your identity will take care of itself.

"Avoid affectation" is a useful rule so far as it goes, but how would you express this idea positively? How would you say what to be, instead of what not to be? The best answer is earnest. If you're earnest you avoid not just affectation but a whole set of similar vices.

The core of being earnest is being intellectually honest. We're taught as children to be honest as an unselfish virtue — as a kind of sacrifice. But in fact it's a source of power too. To see new ideas, you need an exceptionally sharp eye for the truth. You're trying to see more truth than others have seen so far. And how can you have a sharp eye for the truth if you're intellectually dishonest?

One way to avoid intellectual dishonesty is to maintain a slight positive pressure in the opposite direction. Be aggressively willing to admit that you're mistaken. Once you've admitted you were mistaken about something, you're free. Till then you have to carry it. \[13\]

Another more subtle component of earnestness is informality. Informality is much more important than its grammatically negative name implies. It's not merely the absence of something. It means focusing on what matters instead of what doesn't.

What formality and affectation have in common is that as well as doing the work, you're trying to seem a certain way as you're doing it. But any energy that goes into how you seem comes out of being good. That's one reason nerds have an advantage in doing great work: they expend little effort on seeming anything. In fact that's basically the definition of a nerd.

Nerds have a kind of innocent boldness that's exactly what you need in doing great work. It's not learned; it's preserved from childhood. So hold onto it. Be the one who puts things out there rather than the one who sits back and offers sophisticated-sounding criticisms of them. "It's easy to criticize" is true in the most literal sense, and the route to great work is never easy.

There may be some jobs where it's an advantage to be cynical and pessimistic, but if you want to do great work it's an advantage to be optimistic, even though that means you'll risk looking like a fool sometimes. There's an old tradition of doing the opposite. The Old Testament says it's better to keep quiet lest you look like a fool. But that's advice for seeming smart. If you actually want to discover new things, it's better to take the risk of telling people your ideas.

Some people are naturally earnest, and with others it takes a conscious effort. Either kind of earnestness will suffice. But I doubt it would be possible to do great work without being earnest. It's so hard to do even if you are. You don't have enough margin for error to accommodate the distortions introduced by being affected, intellectually dishonest, orthodox, fashionable, or cool. \[14\]

Great work is consistent not only with who did it, but with itself. It's usually all of a piece. So if you face a decision in the middle of working on something, ask which choice is more consistent.

You may have to throw things away and redo them. You won't necessarily have to, but you have to be willing to. And that can take some effort; when there's something you need to redo, status quo bias and laziness will combine to keep you in denial about it. To beat this ask: If I'd already made the change, would I want to revert to what I have now?

Have the confidence to cut. Don't keep something that doesn't fit just because you're proud of it, or because it cost you a lot of effort.

Indeed, in some kinds of work it's good to strip whatever you're doing to its essence. The result will be more concentrated; you'll understand it better; and you won't be able to lie to yourself about whether there's anything real there.

Mathematical elegance may sound like a mere metaphor, drawn from the arts. That's what I thought when I first heard the term "elegant" applied to a proof. But now I suspect it's conceptually prior — that the main ingredient in artistic elegance is mathematical elegance. At any rate it's a useful standard well beyond math.

Elegance can be a long-term bet, though. Laborious solutions will often have more prestige in the short term. They cost a lot of effort and they're hard to understand, both of which impress people, at least temporarily.

Whereas some of the very best work will seem like it took comparatively little effort, because it was in a sense already there. It didn't have to be built, just seen. It's a very good sign when it's hard to say whether you're creating something or discovering it.

When you're doing work that could be seen as either creation or discovery, err on the side of discovery. Try thinking of yourself as a mere conduit through which the ideas take their natural shape.

(Strangely enough, one exception is the problem of choosing a problem to work on. This is usually seen as search, but in the best case it's more like creating something. In the best case you create the field in the process of exploring it.)

Similarly, if you're trying to build a powerful tool, make it gratuitously unrestrictive. A powerful tool almost by definition will be used in ways you didn't expect, so err on the side of eliminating restrictions, even if you don't know what the benefit will be.

Great work will often be tool-like in the sense of being something others build on. So it's a good sign if you're creating ideas that others could use, or exposing questions that others could answer. The best ideas have implications in many different areas.

If you express your ideas in the most general form, they'll be truer than you intended.

True by itself is not enough, of course. Great ideas have to be true and new. And it takes a certain amount of ability to see new ideas even once you've learned enough to get to one of the frontiers of knowledge.

In English we give this ability names like originality, creativity, and imagination. And it seems reasonable to give it a separate name, because it does seem to some extent a separate skill. It's possible to have a great deal of ability in other respects — to have a great deal of what's often called "technical ability" — and yet not have much of this.

I've never liked the term "creative process." It seems misleading. Originality isn't a process, but a habit of mind. Original thinkers throw off new ideas about whatever they focus on, like an angle grinder throwing off sparks. They can't help it.

If the thing they're focused on is something they don't understand very well, these new ideas might not be good. One of the most original thinkers I know decided to focus on dating after he got divorced. He knew roughly as much about dating as the average 15 year old, and the results were spectacularly colorful. But to see originality separated from expertise like that made its nature all the more clear.

I don't know if it's possible to cultivate originality, but there are definitely ways to make the most of however much you have. For example, you're much more likely to have original ideas when you're working on something. Original ideas don't come from trying to have original ideas. They come from trying to build or understand something slightly too difficult. \[15\]

Talking or writing about the things you're interested in is a good way to generate new ideas. When you try to put ideas into words, a missing idea creates a sort of vacuum that draws it out of you. Indeed, there's a kind of thinking that can only be done by writing.

Changing your context can help. If you visit a new place, you'll often find you have new ideas there. The journey itself often dislodges them. But you may not have to go far to get this benefit. Sometimes it's enough just to go for a walk. \[16\]

It also helps to travel in topic space. You'll have more new ideas if you explore lots of different topics, partly because it gives the angle grinder more surface area to work on, and partly because analogies are an especially fruitful source of new ideas.

Don't divide your attention evenly between many topics though, or you'll spread yourself too thin. You want to distribute it according to something more like a power law. \[17\] Be professionally curious about a few topics and idly curious about many more.

Curiosity and originality are closely related. Curiosity feeds originality by giving it new things to work on. But the relationship is closer than that. Curiosity is itself a kind of originality; it's roughly to questions what originality is to answers. And since questions at their best are a big component of answers, curiosity at its best is a creative force.

Having new ideas is a strange game, because it usually consists of seeing things that were right under your nose. Once you've seen a new idea, it tends to seem obvious. Why did no one think of this before?

When an idea seems simultaneously novel and obvious, it's probably a good one.

Seeing something obvious sounds easy. And yet empirically having new ideas is hard. What's the source of this apparent contradiction? It's that seeing the new idea usually requires you to change the way you look at the world. We see the world through models that both help and constrain us. When you fix a broken model, new ideas become obvious. But noticing and fixing a broken model is hard. That's how new ideas can be both obvious and yet hard to discover: they're easy to see after you do something hard.

One way to discover broken models is to be stricter than other people. Broken models of the world leave a trail of clues where they bash against reality. Most people don't want to see these clues. It would be an understatement to say that they're attached to their current model; it's what they think in; so they'll tend to ignore the trail of clues left by its breakage, however conspicuous it may seem in retrospect.

To find new ideas you have to seize on signs of breakage instead of looking away. That's what Einstein did. He was able to see the wild implications of Maxwell's equations not so much because he was looking for new ideas as because he was stricter.

The other thing you need is a willingness to break rules. Paradoxical as it sounds, if you want to fix your model of the world, it helps to be the sort of person who's comfortable breaking rules. From the point of view of the old model, which everyone including you initially shares, the new model usually breaks at least implicit rules.

Few understand the degree of rule-breaking required, because new ideas seem much more conservative once they succeed. They seem perfectly reasonable once you're using the new model of the world they brought with them. But they didn't at the time; it took the greater part of a century for the heliocentric model to be generally accepted, even among astronomers, because it felt so wrong.

Indeed, if you think about it, a good new idea has to seem bad to most people, or someone would have already explored it. So what you're looking for is ideas that seem crazy, but the right kind of crazy. How do you recognize these? You can't with certainty. Often ideas that seem bad are bad. But ideas that are the right kind of crazy tend to be exciting; they're rich in implications; whereas ideas that are merely bad tend to be depressing.

There are two ways to be comfortable breaking rules: to enjoy breaking them, and to be indifferent to them. I call these two cases being aggressively and passively independent-minded.

The aggressively independent-minded are the naughty ones. Rules don't merely fail to stop them; breaking rules gives them additional energy. For this sort of person, delight at the sheer audacity of a project sometimes supplies enough activation energy to get it started.

The other way to break rules is not to care about them, or perhaps even to know they exist. This is why novices and outsiders often make new discoveries; their ignorance of a field's assumptions acts as a source of temporary passive independent-mindedness. Aspies also seem to have a kind of immunity to conventional beliefs. Several I know say that this helps them to have new ideas.

Strictness plus rule-breaking sounds like a strange combination. In popular culture they're opposed. But popular culture has a broken model in this respect. It implicitly assumes that issues are trivial ones, and in trivial matters strictness and rule-breaking are opposed. But in questions that really matter, only rule-breakers can be truly strict.

An overlooked idea often doesn't lose till the semifinals. You do see it, subconsciously, but then another part of your subconscious shoots it down because it would be too weird, too risky, too much work, too controversial. This suggests an exciting possibility: if you could turn off such filters, you could see more new ideas.

One way to do that is to ask what would be good ideas for someone else to explore. Then your subconscious won't shoot them down to protect you.

You could also discover overlooked ideas by working in the other direction: by starting from what's obscuring them. Every cherished but mistaken principle is surrounded by a dead zone of valuable ideas that are unexplored because they contradict it.

Religions are collections of cherished but mistaken principles. So anything that can be described either literally or metaphorically as a religion will have valuable unexplored ideas in its shadow. Copernicus and Darwin both made discoveries of this type. \[18\]

What are people in your field religious about, in the sense of being too attached to some principle that might not be as self-evident as they think? What becomes possible if you discard it?

People show much more originality in solving problems than in deciding which problems to solve. Even the smartest can be surprisingly conservative when deciding what to work on. People who'd never dream of being fashionable in any other way get sucked into working on fashionable problems.

One reason people are more conservative when choosing problems than solutions is that problems are bigger bets. A problem could occupy you for years, while exploring a solution might only take days. But even so I think most people are too conservative. They're not merely responding to risk, but to fashion as well. Unfashionable problems are undervalued.

One of the most interesting kinds of unfashionable problem is the problem that people think has been fully explored, but hasn't. Great work often takes something that already exists and shows its latent potential. Durer and Watt both did this. So if you're interested in a field that others think is tapped out, don't let their skepticism deter you. People are often wrong about this.

Working on an unfashionable problem can be very pleasing. There's no hype or hurry. Opportunists and critics are both occupied elsewhere. The existing work often has an old-school solidity. And there's a satisfying sense of economy in cultivating ideas that would otherwise be wasted.

But the most common type of overlooked problem is not explicitly unfashionable in the sense of being out of fashion. It just doesn't seem to matter as much as it actually does. How do you find these? By being self-indulgent — by letting your curiosity have its way, and tuning out, at least temporarily, the little voice in your head that says you should only be working on "important" problems.

You do need to work on important problems, but almost everyone is too conservative about what counts as one. And if there's an important but overlooked problem in your neighborhood, it's probably already on your subconscious radar screen. So try asking yourself: if you were going to take a break from "serious" work to work on something just because it would be really interesting, what would you do? The answer is probably more important than it seems.

Originality in choosing problems seems to matter even more than originality in solving them. That's what distinguishes the people who discover whole new fields. So what might seem to be merely the initial step — deciding what to work on — is in a sense the key to the whole game.

Few grasp this. One of the biggest misconceptions about new ideas is about the ratio of question to answer in their composition. People think big ideas are answers, but often the real insight was in the question.

Part of the reason we underrate questions is the way they're used in schools. In schools they tend to exist only briefly before being answered, like unstable particles. But a really good question can be much more than that. A really good question is a partial discovery. How do new species arise? Is the force that makes objects fall to earth the same as the one that keeps planets in their orbits? By even asking such questions you were already in excitingly novel territory.

Unanswered questions can be uncomfortable things to carry around with you. But the more you're carrying, the greater the chance of noticing a solution — or perhaps even more excitingly, noticing that two unanswered questions are the same.

Sometimes you carry a question for a long time. Great work often comes from returning to a question you first noticed years before — in your childhood, even — and couldn't stop thinking about. People talk a lot about the importance of keeping your youthful dreams alive, but it's just as important to keep your youthful questions alive. \[19\]

This is one of the places where actual expertise differs most from the popular picture of it. In the popular picture, experts are certain. But actually the more puzzled you are, the better, so long as (a) the things you're puzzled about matter, and (b) no one else understands them either.

Think about what's happening at the moment just before a new idea is discovered. Often someone with sufficient expertise is puzzled about something. Which means that originality consists partly of puzzlement — of confusion! You have to be comfortable enough with the world being full of puzzles that you're willing to see them, but not so comfortable that you don't want to solve them. \[20\]

It's a great thing to be rich in unanswered questions. And this is one of those situations where the rich get richer, because the best way to acquire new questions is to try answering existing ones. Questions don't just lead to answers, but also to more questions.

The best questions grow in the answering. You notice a thread protruding from the current paradigm and try pulling on it, and it just gets longer and longer. So don't require a question to be obviously big before you try answering it. You can rarely predict that. It's hard enough even to notice the thread, let alone to predict how much will unravel if you pull on it.

It's better to be promiscuously curious — to pull a little bit on a lot of threads, and see what happens. Big things start small. The initial versions of big things were often just experiments, or side projects, or talks, which then grew into something bigger. So start lots of small things.

Being prolific is underrated. The more different things you try, the greater the chance of discovering something new. Understand, though, that trying lots of things will mean trying lots of things that don't work. You can't have a lot of good ideas without also having a lot of bad ones. \[21\]

Though it sounds more responsible to begin by studying everything that's been done before, you'll learn faster and have more fun by trying stuff. And you'll understand previous work better when you do look at it. So err on the side of starting. Which is easier when starting means starting small; those two ideas fit together like two puzzle pieces.

How do you get from starting small to doing something great? By making successive versions. Great things are almost always made in successive versions. You start with something small and evolve it, and the final version is both cleverer and more ambitious than anything you could have planned.

It's particularly useful to make successive versions when you're making something for people — to get an initial version in front of them quickly, and then evolve it based on their response.

Begin by trying the simplest thing that could possibly work. Surprisingly often, it does. If it doesn't, this will at least get you started.

Don't try to cram too much new stuff into any one version. There are names for doing this with the first version (taking too long to ship) and the second (the second system effect), but these are both merely instances of a more general principle.

An early version of a new project will sometimes be dismissed as a toy. It's a good sign when people do this. That means it has everything a new idea needs except scale, and that tends to follow. \[22\]

The alternative to starting with something small and evolving it is to plan in advance what you're going to do. And planning does usually seem the more responsible choice. It sounds more organized to say "we're going to do x and then y and then z" than "we're going to try x and see what happens." And it is more organized; it just doesn't work as well.

Planning per se isn't good. It's sometimes necessary, but it's a necessary evil — a response to unforgiving conditions. It's something you have to do because you're working with inflexible media, or because you need to coordinate the efforts of a lot of people. If you keep projects small and use flexible media, you don't have to plan as much, and your designs can evolve instead.

Take as much risk as you can afford. In an efficient market, risk is proportionate to reward, so don't look for certainty, but for a bet with high expected value. If you're not failing occasionally, you're probably being too conservative.

Though conservatism is usually associated with the old, it's the young who tend to make this mistake. Inexperience makes them fear risk, but it's when you're young that you can afford the most.

Even a project that fails can be valuable. In the process of working on it, you'll have crossed territory few others have seen, and encountered questions few others have asked. And there's probably no better source of questions than the ones you encounter in trying to do something slightly too hard.

Use the advantages of youth when you have them, and the advantages of age once you have those. The advantages of youth are energy, time, optimism, and freedom. The advantages of age are knowledge, efficiency, money, and power. With effort you can acquire some of the latter when young and keep some of the former when old.

The old also have the advantage of knowing which advantages they have. The young often have them without realizing it. The biggest is probably time. The young have no idea how rich they are in time. The best way to turn this time to advantage is to use it in slightly frivolous ways: to learn about something you don't need to know about, just out of curiosity, or to try building something just because it would be cool, or to become freakishly good at something.

That "slightly" is an important qualification. Spend time lavishly when you're young, but don't simply waste it. There's a big difference between doing something you worry might be a waste of time and doing something you know for sure will be. The former is at least a bet, and possibly a better one than you think. \[23\]

The most subtle advantage of youth, or more precisely of inexperience, is that you're seeing everything with fresh eyes. When your brain embraces an idea for the first time, sometimes the two don't fit together perfectly. Usually the problem is with your brain, but occasionally it's with the idea. A piece of it sticks out awkwardly and jabs you when you think about it. People who are used to the idea have learned to ignore it, but you have the opportunity not to. \[24\]

So when you're learning about something for the first time, pay attention to things that seem wrong or missing. You'll be tempted to ignore them, since there's a 99% chance the problem is with you. And you may have to set aside your misgivings temporarily to keep progressing. But don't forget about them. When you've gotten further into the subject, come back and check if they're still there. If they're still viable in the light of your present knowledge, they probably represent an undiscovered idea.

One of the most valuable kinds of knowledge you get from experience is to know what you don't have to worry about. The young know all the things that could matter, but not their relative importance. So they worry equally about everything, when they should worry much more about a few things and hardly at all about the rest.

But what you don't know is only half the problem with inexperience. The other half is what you do know that ain't so. You arrive at adulthood with your head full of nonsense — bad habits you've acquired and false things you've been taught — and you won't be able to do great work till you clear away at least the nonsense in the way of whatever type of work you want to do.

Much of the nonsense left in your head is left there by schools. We're so used to schools that we unconsciously treat going to school as identical with learning, but in fact schools have all sorts of strange qualities that warp our ideas about learning and thinking.

For example, schools induce passivity. Since you were a small child, there was an authority at the front of the class telling all of you what you had to learn and then measuring whether you did. But neither classes nor tests are intrinsic to learning; they're just artifacts of the way schools are usually designed.

The sooner you overcome this passivity, the better. If you're still in school, try thinking of your education as your project, and your teachers as working for you rather than vice versa. That may seem a stretch, but it's not merely some weird thought experiment. It's the truth, economically, and in the best case it's the truth intellectually as well. The best teachers don't want to be your bosses. They'd prefer it if you pushed ahead, using them as a source of advice, rather than being pulled by them through the material.

Schools also give you a misleading impression of what work is like. In school they tell you what the problems are, and they're almost always soluble using no more than you've been taught so far. In real life you have to figure out what the problems are, and you often don't know if they're soluble at all.

But perhaps the worst thing schools do to you is train you to win by hacking the test. You can't do great work by doing that. You can't trick God. So stop looking for that kind of shortcut. The way to beat the system is to focus on problems and solutions that others have overlooked, not to skimp on the work itself.

Don't think of yourself as dependent on some gatekeeper giving you a "big break." Even if this were true, the best way to get it would be to focus on doing good work rather than chasing influential people.

And don't take rejection by committees to heart. The qualities that impress admissions officers and prize committees are quite different from those required to do great work. The decisions of selection committees are only meaningful to the extent that they're part of a feedback loop, and very few are.

People new to a field will often copy existing work. There's nothing inherently bad about that. There's no better way to learn how something works than by trying to reproduce it. Nor does copying necessarily make your work unoriginal. Originality is the presence of new ideas, not the absence of old ones.

There's a good way to copy and a bad way. If you're going to copy something, do it openly instead of furtively, or worse still, unconsciously. This is what's meant by the famously misattributed phrase "Great artists steal." The really dangerous kind of copying, the kind that gives copying a bad name, is the kind that's done without realizing it, because you're nothing more than a train running on tracks laid down by someone else. But at the other extreme, copying can be a sign of superiority rather than subordination. \[25\]

In many fields it's almost inevitable that your early work will be in some sense based on other people's. Projects rarely arise in a vacuum. They're usually a reaction to previous work. When you're first starting out, you don't have any previous work; if you're going to react to something, it has to be someone else's. Once you're established, you can react to your own. But while the former gets called derivative and the latter doesn't, structurally the two cases are more similar than they seem.

Oddly enough, the very novelty of the most novel ideas sometimes makes them seem at first to be more derivative than they are. New discoveries often have to be conceived initially as variations of existing things, even by their discoverers, because there isn't yet the conceptual vocabulary to express them.

There are definitely some dangers to copying, though. One is that you'll tend to copy old things — things that were in their day at the frontier of knowledge, but no longer are.

And when you do copy something, don't copy every feature of it. Some will make you ridiculous if you do. Don't copy the manner of an eminent 50 year old professor if you're 18, for example, or the idiom of a Renaissance poem hundreds of years later.

Some of the features of things you admire are flaws they succeeded despite. Indeed, the features that are easiest to imitate are the most likely to be the flaws.

This is particularly true for behavior. Some talented people are jerks, and this sometimes makes it seem to the inexperienced that being a jerk is part of being talented. It isn't; being talented is merely how they get away with it.

One of the most powerful kinds of copying is to copy something from one field into another. History is so full of chance discoveries of this type that it's probably worth giving chance a hand by deliberately learning about other kinds of work. You can take ideas from quite distant fields if you let them be metaphors.

Negative examples can be as inspiring as positive ones. In fact you can sometimes learn more from things done badly than from things done well; sometimes it only becomes clear what's needed when it's missing.

If a lot of the best people in your field are collected in one place, it's usually a good idea to visit for a while. It will increase your ambition, and also, by showing you that these people are human, increase your self-confidence. \[26\]

If you're earnest you'll probably get a warmer welcome than you might expect. Most people who are very good at something are happy to talk about it with anyone who's genuinely interested. If they're really good at their work, then they probably have a hobbyist's interest in it, and hobbyists always want to talk about their hobbies.

It may take some effort to find the people who are really good, though. Doing great work has such prestige that in some places, particularly universities, there's a polite fiction that everyone is engaged in it. And that is far from true. People within universities can't say so openly, but the quality of the work being done in different departments varies immensely. Some departments have people doing great work; others have in the past; others never have.

Seek out the best colleagues. There are a lot of projects that can't be done alone, and even if you're working on one that can be, it's good to have other people to encourage you and to bounce ideas off.

Colleagues don't just affect your work, though; they also affect you. So work with people you want to become like, because you will.

Quality is more important than quantity in colleagues. It's better to have one or two great ones than a building full of pretty good ones. In fact it's not merely better, but necessary, judging from history: the degree to which great work happens in clusters suggests that one's colleagues often make the difference between doing great work and not.

How do you know when you have sufficiently good colleagues? In my experience, when you do, you know. Which means if you're unsure, you probably don't. But it may be possible to give a more concrete answer than that. Here's an attempt: sufficiently good colleagues offer surprising insights. They can see and do things that you can't. So if you have a handful of colleagues good enough to keep you on your toes in this sense, you're probably over the threshold.

Most of us can benefit from collaborating with colleagues, but some projects require people on a larger scale, and starting one of those is not for everyone. If you want to run a project like that, you'll have to become a manager, and managing well takes aptitude and interest like any other kind of work. If you don't have them, there is no middle path: you must either force yourself to learn management as a second language, or avoid such projects. \[27\]

Husband your morale. It's the basis of everything when you're working on ambitious projects. You have to nurture and protect it like a living organism.

Morale starts with your view of life. You're more likely to do great work if you're an optimist, and more likely to if you think of yourself as lucky than if you think of yourself as a victim.

Indeed, work can to some extent protect you from your problems. If you choose work that's pure, its very difficulties will serve as a refuge from the difficulties of everyday life. If this is escapism, it's a very productive form of it, and one that has been used by some of the greatest minds in history.

Morale compounds via work: high morale helps you do good work, which increases your morale and helps you do even better work. But this cycle also operates in the other direction: if you're not doing good work, that can demoralize you and make it even harder to. Since it matters so much for this cycle to be running in the right direction, it can be a good idea to switch to easier work when you're stuck, just so you start to get something done.

One of the biggest mistakes ambitious people make is to allow setbacks to destroy their morale all at once, like a balloon bursting. You can inoculate yourself against this by explicitly considering setbacks a part of your process. Solving hard problems always involves some backtracking.

Doing great work is a depth-first search whose root node is the desire to. So "If at first you don't succeed, try, try again" isn't quite right. It should be: If at first you don't succeed, either try again, or backtrack and then try again.

"Never give up" is also not quite right. Obviously there are times when it's the right choice to eject. A more precise version would be: Never let setbacks panic you into backtracking more than you need to. Corollary: Never abandon the root node.

It's not necessarily a bad sign if work is a struggle, any more than it's a bad sign to be out of breath while running. It depends how fast you're running. So learn to distinguish good pain from bad. Good pain is a sign of effort; bad pain is a sign of damage.

An audience is a critical component of morale. If you're a scholar, your audience may be your peers; in the arts, it may be an audience in the traditional sense. Either way it doesn't need to be big. The value of an audience doesn't grow anything like linearly with its size. Which is bad news if you're famous, but good news if you're just starting out, because it means a small but dedicated audience can be enough to sustain you. If a handful of people genuinely love what you're doing, that's enough.

To the extent you can, avoid letting intermediaries come between you and your audience. In some types of work this is inevitable, but it's so liberating to escape it that you might be better off switching to an adjacent type if that will let you go direct. \[28\]

The people you spend time with will also have a big effect on your morale. You'll find there are some who increase your energy and others who decrease it, and the effect someone has is not always what you'd expect. Seek out the people who increase your energy and avoid those who decrease it. Though of course if there's someone you need to take care of, that takes precedence.

Don't marry someone who doesn't understand that you need to work, or sees your work as competition for your attention. If you're ambitious, you need to work; it's almost like a medical condition; so someone who won't let you work either doesn't understand you, or does and doesn't care.

Ultimately morale is physical. You think with your body, so it's important to take care of it. That means exercising regularly, eating and sleeping well, and avoiding the more dangerous kinds of drugs. Running and walking are particularly good forms of exercise because they're good for thinking. \[29\]

People who do great work are not necessarily happier than everyone else, but they're happier than they'd be if they didn't. In fact, if you're smart and ambitious, it's dangerous not to be productive. People who are smart and ambitious but don't achieve much tend to become bitter.

It's ok to want to impress other people, but choose the right people. The opinion of people you respect is signal. Fame, which is the opinion of a much larger group you might or might not respect, just adds noise.

The prestige of a type of work is at best a trailing indicator and sometimes completely mistaken. If you do anything well enough, you'll make it prestigious. So the question to ask about a type of work is not how much prestige it has, but how well it could be done.

Competition can be an effective motivator, but don't let it choose the problem for you; don't let yourself get drawn into chasing something just because others are. In fact, don't let competitors make you do anything much more specific than work harder.

Curiosity is the best guide. Your curiosity never lies, and it knows more than you do about what's worth paying attention to.

Notice how often that word has come up. If you asked an oracle the secret to doing great work and the oracle replied with a single word, my bet would be on "curiosity."

That doesn't translate directly to advice. It's not enough just to be curious, and you can't command curiosity anyway. But you can nurture it and let it drive you.

Curiosity is the key to all four steps in doing great work: it will choose the field for you, get you to the frontier, cause you to notice the gaps in it, and drive you to explore them. The whole process is a kind of dance with curiosity.

Believe it or not, I tried to make this essay as short as I could. But its length at least means it acts as a filter. If you made it this far, you must be interested in doing great work. And if so you're already further along than you might realize, because the set of people willing to want to is small.

The factors in doing great work are factors in the literal, mathematical sense, and they are: ability, interest, effort, and luck. Luck by definition you can't do anything about, so we can ignore that. And we can assume effort, if you do in fact want to do great work. So the problem boils down to ability and interest. Can you find a kind of work where your ability and interest will combine to yield an explosion of new ideas?

Here there are grounds for optimism. There are so many different ways to do great work, and even more that are still undiscovered. Out of all those different types of work, the one you're most suited for is probably a pretty close match. Probably a comically close match. It's just a question of finding it, and how far into it your ability and interest can take you. And you can only answer that by trying.

Many more people could try to do great work than do. What holds them back is a combination of modesty and fear. It seems presumptuous to try to be Newton or Shakespeare. It also seems hard; surely if you tried something like that, you'd fail. Presumably the calculation is rarely explicit. Few people consciously decide not to try to do great work. But that's what's going on subconsciously; they shy away from the question.

So I'm going to pull a sneaky trick on you. Do you want to do great work, or not? Now you have to decide consciously. Sorry about that. I wouldn't have done it to a general audience. But we already know you're interested.

Don't worry about being presumptuous. You don't have to tell anyone. And if it's too hard and you fail, so what? Lots of people have worse problems than that. In fact you'll be lucky if it's the worst problem you have.

Yes, you'll have to work hard. But again, lots of people have to work hard. And if you're working on something you find very interesting, which you necessarily will if you're on the right path, the work will probably feel less burdensome than a lot of your peers'.

The discoveries are out there, waiting to be made. Why not by you?`,
		half: `If you gathered techniques for doing great work across various fields, what would their commonalities look like? Driven by this curiosity, I decided to create such a guide, usable by anyone, regardless of their field. Through this exercise, I discovered that these common strategies indeed form a definite structure rather than just a vague notion like "work hard." This recipe for great work starts with the assumption that you're highly ambitious. The first step is choosing what to work on. Your chosen work must have three essential traits: it should align with your natural talents, deeply interest you, and provide ample opportunity to produce outstanding work.

You don't need to stress much about determining the third criterion of work. Ambitious individuals are often already quite cautious about this. Instead, focus on finding something you have both an aptitude for and a great interest in, which can be challenging. When you're young, you're unaware of your true strengths or the nature of various careers, particularly those that don't yet exist. While some people have clear ambitions early on, most need to figure it out through experience. If undecided, simply guess and start working on something; trial and error is fine and will help you understand various fields. Cultivate a habit of pursuing your own projects, as the most significant work you'll do will likely be driven by your own ambitions. Your projects should be whatever excites you most. Over time, what's exciting and what’s important will converge, evolving from simple interests to more complex inquiries. Preserve your enthusiasm and curiosity, as these will guide you toward the right projects. Your excessive curiosity — even if it bores others — is the key to discovering your path.

When you’re intensely interested in something, dive deep enough to reach the frontiers of knowledge where gaps and opportunities for discovery lie. Spotting these gaps takes skill, as our brains often overlook them for simplicity. Embrace unconventional ideas and boldly pursue outlier concepts that excite you, even if others ignore them. This process involves four steps: choose a field, learn extensively, notice gaps, and explore promising ones. Hard work is essential and driven by deep interest. The system assumes you'll magically guess your field early, but often, finding your path involves luck and curiosity-driven experimentation. By trying various things, meeting different people, and reading widely, you increase your chances of finding your passion. Optimize for what’s interesting to you, even if your interests seem unusual. Enjoying the tedious parts of a field is a good sign of suitability, but remain flexible and switch paths if you discover something more exciting along the way.

If you're creating something for people, make sure it's something they actually want by making something you, yourself, want. This aligns with the excitingness rule; the most thrilling story to write is the one you want to read. Many falter by aiming to please an imaginary, sophisticated audience instead of themselves. Several distractions—like pretentiousness, fashion, and money—can lead you astray, but genuine interest will keep you on track. This strategy requires boldness and a willingness to face rejection and failure, but not exhaustive planning. Great work often arises from hard work on ambitious projects rather than meticulous planning. Known as "staying upwind," this approach involves doing whatever seems most interesting and offers the best future options at each stage. However, working on something exciting isn't always straightforward; it requires technique and perseverance, much like sailing through headwinds and hidden shoals.

Working too hard can lead to diminishing returns due to fatigue, reducing productivity and potentially harming your health. The optimal work period varies by task, with some requiring only four or five hours of concentrated effort, ideally uninterrupted. Arrange your schedule to allow large blocks of work time to avoid interruptions, which can deter starting hard tasks. Overcoming the initial resistance to begin work often requires psychologically tricking oneself, acknowledging that the mental threshold to start is higher than that to continue. Telling small lies to yourself, such as taking advantage of the "How hard could it be?" mindset, can catalyze project initiation, especially for younger, more optimistic individuals. Finish what you start, as significant progress often materializes in the final stages of a project. Additionally, considering your work exceedingly important can drive motivation and possibly lead to genuine significant discoveries.

There are two types of procrastination: per-day and per-project, with the latter being much more dangerous. Per-project procrastination involves delaying the start of ambitious projects because the timing never feels right, leading to years of inaction. This type of procrastination is particularly insidious because it camouflages itself as productivity; you're not idle, but diligently working on other tasks, and therefore, it doesn’t raise the same alarms as daily procrastination. To combat this, periodically ask yourself if you are working on what you truly want to work on. While it's acceptable for young people to occasionally say no, this becomes increasingly perilous with age. Achieving great work often requires dedicating an exceptional amount of time to a problem, which shouldn't be viewed as a cost but rather enjoyed as a compelling endeavor.

Great work isn't about slogging away at something you hate for years; it's about consistently dedicating yourself to something you're genuinely passionate about. The cumulative effect of consistent work can be astonishing—writing a mere page a day can result in a book a year. The key is consistency. Great achievements are often made by completing small tasks regularly, leading to exponential growth. This growth, though seemingly flat at first, soon accelerates, creating significant value over time. Whether it's learning or building an audience, the more you invest, the more you gain. Often, we underestimate this process and push through early stages unconsciously, realizing later the importance of initial efforts. Additionally, undirected thinking, such as when walking or showering, can spur innovative solutions, but it requires the foundation of deliberate work. Hence, a blend of persistent effort and occasional mind-wandering can lead to remarkable successes.

Avoiding distractions at work is crucial, but it's equally important to avoid distractions during downtime that push your work out of focus. Letting your mind wander should center on what you care about most, except for love. Consciously develop your taste in work within your field; understanding the best and why it's the best will help you aim higher. Many agree that aiming to be the best rather than just good is essential, possibly because ambition often falls short of the target, or because striving for the best is a different, more motivating endeavor. Trying to be the best can be more liberating and simpler than just aiming to be good. Aim to create work that will be valued in a century, as this is a good proxy for genuine quality.

Don't focus on crafting a distinctive style. Simply do your best; your unique style will emerge naturally. When you strive too hard for distinctiveness, it becomes artificial. True style flows effortlessly from your genuine efforts.

Affectation involves adopting a fake persona, often showing in one's work, with the temptation being greater among the young due to feelings of insignificance. However, undertaking ambitious projects inherently solves this by establishing one's identity through achievement. While avoiding affectation is advisable, a more positive approach is to be earnest, which encompasses being intellectually honest and willing to admit mistakes, thereby avoiding similar vices. Earnestness also includes informality, focusing on substance over appearance, a trait often seen in nerds who conserve their energy for real work rather than pretense. Although cynicism and pessimism may be advantageous in some fields, optimism is essential for groundbreaking work, even at the risk of looking foolish. Great work necessitates earnestness, as it aligns consistently with both the creator and itself, often requiring a willingness to redo parts to maintain this consistency. To combat laziness and status quo bias, one should consider if, having made a change, reverting to the previous state would be desirable.

Have the confidence to cut. Don't hold onto something that doesn't fit just because it makes you proud or because you put a ton of effort into it. In fact, in certain types of work, it's beneficial to strip down your project to its core. This will yield a more focused result, enhance your understanding, and prevent self-deception about the authenticity of your work.

Mathematical elegance might initially seem like a metaphor borrowed from the arts, as I once believed when I first encountered the term "elegant" for a proof. However, I've come to think it might actually be foundational — that artistic elegance derives from mathematical elegance. This notion of elegance extends beyond math, serving as a valuable standard in various fields. Elegance can be a long-term investment; while laborious solutions garner short-term prestige due to their complexity and the effort they demand, the finest work often appears effortless because it feels pre-existing, merely needing to be observed rather than constructed. The truest sign of brilliance in any creative endeavor is when it's unclear whether you're inventing something new or simply uncovering it.

When you're involved in work that straddles the line between creation and discovery, lean towards discovery. Adopt the mindset of being a mere conduit through which ideas naturally take shape.

Choosing a problem to work on is often viewed as a search but ideally resembles creating a new field during exploration. When building powerful tools, ensure they are unrestrictively designed, as they are likely to be used in unforeseen ways. Aim to create tools and ideas that others can build upon or answer questions with. The best ideas have wide-ranging implications and should be expressed in the most general form to reveal deeper truths. However, ideas must be both true and new, which requires a certain degree of skill to identify them once you reach the frontiers of knowledge.

In English, we attribute terms like originality, creativity, and imagination to a certain unique ability, which seems reasonable to label separately as it appears to be a distinct skill. One can possess substantial technical ability yet lack this creative flair. Personally, I dislike the term "creative process," as originality seems more of a habitual mindset than a process. Original thinkers continuously generate new ideas on whatever they concentrate on, similar to an angle grinder producing sparks. However, if their focus is on something unfamiliar, the ideas may not be particularly good. For instance, an original thinker I know, post-divorce, shifted his focus to dating, an area he was inexperienced in, resulting in notably colorful outcomes. Observing originality dissociated from expertise highlights its true nature. While it's unclear if originality can be cultivated, there are definite ways to maximize it. You're more likely to have original ideas when engaged in challenging work, as these ideas arise from the efforts to build or understand something complex, not from trying to be original. Discussing or writing about interesting subjects can also spur new thoughts, as attempting to articulate ideas can draw out the missing pieces. Changing your context, such as traveling or even just taking a walk, can help dislodge new ideas. Exploring various topics expands the "angle grinder's" surface area and often yields fruitful analogies, but rather than spreading your attention thinly across many areas, focus deeply on a few and remain idly curious about others. Curiosity nurtures originality by providing new material to work with and is akin to what questions are to originality's answers. Often, generating new ideas means seeing what was always in plain sight, leading to the paradox that once an idea is found, it often seems obvious.

When an idea strikes you as both novel and obvious at the same time, you can bet it's a good one.

Having new ideas is difficult because they often require a shift in perspective, which involves fixing broken models of the world. While our models help us, they also constrain us, making it hard to notice and correct their flaws. Once a broken model is fixed, new ideas become obvious, illustrating why they seem easy yet hard to discover. Being stricter than others can help identify broken models, as they leave clues against reality that most people ignore. Einstein's success in recognizing the implications of Maxwell's equations stemmed from his stricter view. Moreover, a willingness to break rules is essential for creating new models, as truly innovative ideas break implicit rules of old models and appear conservative only after they succeed. The heliocentric model took a century to be accepted because it initially felt wrong. Thus, good new ideas often seem bad initially; what you seek are ideas that are crazy in a way that is exciting and rich in implications. Recognizing them is uncertain since bad ideas can also seem crazy. Comfort with rule-breaking, whether enjoyed or disregarded, is crucial. Aggressively independent-minded people, who derive energy from breaking rules, find delight in the audacity of their projects, which helps them get started.

The other way to break rules is simply not to care about them or even know they exist, which is why novices and outsiders often make new discoveries; their ignorance of a field's assumptions brings a form of passive independent-mindedness. Similarly, people on the autism spectrum (Aspies) seem to possess an immunity to conventional beliefs, aiding them in generating new ideas. While popular culture pits strictness against rule-breaking, this is a flawed perspective, especially in significant matters where only rule-breakers can truly be stringent. Often, overlooked ideas are subconsciously dismissed because they seem too weird, risky, labor-intensive, or controversial. This opens up an intriguing possibility: if you could disable these filters, you'd see more innovative ideas. One way to achieve this is by considering what ideas might be valuable for others to explore, thereby circumventing your subconscious self-censorship.

You can uncover hidden ideas by examining what's obscuring them, particularly by challenging cherished but mistaken principles, which often create a dead zone of unexplored, valuable ideas. Religions exemplify such collections of flawed principles, meaning that anything metaphorically or literally resembling a religion will have untapped potential hidden in its shadow. Notable figures like Copernicus and Darwin made significant discoveries by confronting such prevailing beliefs. Reflect on what your field might be religious about—principles taken as self-evident but which may not be—and consider the possibilities that arise if you discard these assumptions. Interestingly, people show more originality in solving problems than in choosing which problems to tackle, with even the brightest minds often conservatively sticking to fashionable problems rather than exploring uncharted territory.

People tend to be more conservative when choosing problems to tackle rather than solutions because problems can be long-term commitments, occupying years, while solutions might only take days to explore. Yet this conservatism often goes too far, influenced by both risk aversion and fashion trends, undervaluing unfashionable problems. Some of the most rewarding work comes from revisiting problems deemed fully explored but rich with latent potential, as Durer and Watt demonstrated. Working on unfashionable problems can be gratifying, free from hype and scrutiny, and involves developing ideas that would otherwise be wasted. The most overlooked problems, however, aren't necessarily unfashionable but are underrated in importance. Finding such problems requires indulging your curiosity and setting aside the urge to only pursue "important" problems. The key to groundbreaking work lies in the originality of the problems you choose, as this often leads to discovering new fields. The ratio of question to answer in big ideas is misunderstood; the real insight frequently lies in the question itself.

Part of the reason we undervalue questions is their fleeting nature in schools, where they are answered quickly, much like unstable particles. However, truly great questions can be more than this—they are partial discoveries. They propel us into uncharted territory: How do new species arise? Is the force that pulls objects to the Earth the same as the one that keeps planets in orbit? Unanswered questions can be uncomfortable, but carrying them increases the likelihood of finding solutions or recognizing connections between them. Sometimes, these questions linger with us for years, even from childhood, driving significant discoveries. While people often emphasize the importance of maintaining youthful dreams, it's equally crucial to keep our youthful questions alive.

Experts aren't always certain; in fact, being puzzled about important, unexplored questions often leads to originality. Embrace puzzlement and be rich in unanswered questions, as exploring them generates even more inquiries. Rather than demanding grand questions, pull on the threads of curiosity and see what unravels. Small, prolific efforts often lead to big discoveries, though they come with failures. Favor starting small and evolving projects through successive versions, especially when creating for others, rather than over-planning. Take risks, as high rewards come from them, and avoid the conservatism that often accompanies inexperience.

Even a project that fails can hold immense value. Through the process, you get to explore uncharted territory and confront unique questions that others may not have even considered. There's no richer source of questions than those you come across by attempting something that’s just beyond your reach.

Use the advantages of youth—energy, time, optimism, and freedom—and those of age—knowledge, efficiency, money, and power—appropriately as you encounter them in life. While young, take advantage of your abundant time by engaging in slightly frivolous activities, experimenting, and exploring new interests. This approach allows learning through experience and fresh perspectives, sometimes discovering flaws in ideas that others ignore. As you grow older, discern what truly matters and eliminate insignificant concerns, focusing on impactful activities. Schools often foster passivity and limited views of learning, so dynamically engage with education. Rather than copying uncritically, leverage others' ideas openly and adapt them to create meaningful, original work. Recognize that even successful people have flaws and learn vicariously through both positive and negative examples. Embrace cross-field ideas and visit hubs of excellence for inspiration and self-belief. This balanced approach, from youth to age, can enrich your growth and achievements.

If you're genuinely interested, you'll likely receive a warmer welcome than anticipated from experts in any field, as they often enjoy discussing their work with earnest individuals. Outstanding professionals typically have a passionate, hobbyist-like dedication to their work, and finding such colleagues, though sometimes difficult due to the prestige associated with great work, is crucial. Universities, for instance, maintain a polite fiction that everyone produces high-quality work, though the reality varies greatly across departments. Seek out the best colleagues as their influence is crucial; they can offer fresh insights and support that can elevate your own work. Working with excellent colleagues is better than having many decent ones, as seen in historical clusters of greatness. You'll know you have good colleagues when they continuously surprise and challenge you. While everyone can benefit from collaboration, some projects require large-scale teamwork and effective management, which demands specific skills and dedication. If managing isn't your forte, you must either learn it or avoid such projects. Lastly, maintaining your morale is vital when working on ambitious endeavors, so nurture and protect it diligently.

Morale begins with your perspective on life. An optimistic outlook helps you produce great work, and considering yourself fortunate rather than a victim boosts your likelihood of success.

Indeed, work can offer a refuge from your problems. Engaging in pure work's intrinsic difficulties can be a productive form of escapism, as evidenced by some of the greatest minds in history. High morale fosters good work, which in turn boosts morale, creating a positive cycle. Conversely, poor work can demoralize, making the cycle spiral downward. Therefore, when stuck, switching to easier tasks can help maintain productivity and morale. A critical mistake ambitious individuals make is allowing setbacks to shatter their morale. To avoid this, consider setbacks as integral to the process. Tackling hard problems often requires backtracking. Hence, "If at first you don't succeed, try, try again" should be refined to: If at first you don't succeed, either try again or backtrack and then try again.

"Never give up" misses the mark slightly. Sometimes, ejecting is the right move. A more accurate motto would be: Never let setbacks make you backtrack more than necessary. And importantly: Never abandon the root node. Struggling doesn't inherently mean you're off course—think of it like being out of breath while running; it all depends on your speed. So, learn to tell the difference between good pain and bad pain. Good pain signifies effort, while bad pain indicates damage.

An audience is crucial for maintaining morale. Whether you're a scholar sharing your work with peers or an artist performing for an audience in the traditional sense, the size of your audience isn't as important as its quality. This is particularly uplifting for those just starting out since a small, dedicated audience can be immensely sustaining. Even if only a handful of people genuinely love what you do, that's sufficient. Whenever possible, try to bypass intermediaries between you and your audience. While this may not always be achievable in some fields, the liberation of directly connecting with your audience may be worth considering a switch to a related field where direct engagement is feasible. 

\[28\]

The people you spend time with will significantly impact your morale. Some individuals will increase your energy, while others will decrease it, and these effects can often be surprising. Make it a point to seek out those who boost your energy and steer clear of those who sap it. However, if caring for someone is necessary, that responsibility should take precedence.

Don't marry someone who sees your work as competition for your attention. If you're ambitious, working is essential—almost like a medical necessity. If your partner prevents you from working, they either don't understand you or don't care. Remember, morale is physical; you think with your body. Therefore, maintain a healthy lifestyle by exercising regularly, eating and sleeping well, and avoiding dangerous drugs. Running and walking are great forms of exercise because they're good for thinking. Achievers aren't necessarily happier, but they're happier than they'd be if unproductive. Ambitious, intelligent folks who don't achieve can become bitter. It's okay to want to impress others, but focus on those you genuinely respect. Fame, or the approval of a larger, less significant group, is just noise.

The prestige of a type of work is often an afterthought and can sometimes be entirely wrong. If you excel at something, you'll make it prestigious. The essential question is not how prestigious a type of work is, but how well it can be done. While competition can motivate, don't let it dictate your choices; avoid pursuing something merely because others are. Let your curiosity be your guide—it never misleads and inherently knows what's worth your focus. Pursue what genuinely intrigues you, and you'll find your own path to success.

If you asked an oracle the secret to doing great work, my bet would be on "curiosity." Curiosity alone isn’t enough and you can't force it, but you can nurture it. It's essential across all four steps of doing great work: it guides you to a field, drives you to its frontier, highlights gaps, and compels you to explore them. This essay is long, partly to act as a filter; if you're still reading, you’re inherently interested in doing great work. This boils down to ability and interest, with effort assumed and luck disregarded as uncontrollable. Can you find work where your ability and interest spark new ideas? Likely, yes. The key challenge is finding that work and letting curiosity guide you. Many shy away from pursuing greatness, fearing failure and seeming presumptuous. Yet, are you willing to strive for great work? Now you're consciously deciding. Don’t worry about failing or seeming presumptuous; many face worse problems. Aim for greatness, and let curiosity drive you.

Yes, you'll have to work hard. But remember, lots of people have to work hard. If you're pursuing something fascinating, which you naturally will be if you're on the right path, the work will likely feel less burdensome than it does for many of your peers. The discoveries are out there, just waiting to be made. So, why not by you?`,
		quarter: `Driven by curiosity about common strategies for achieving great work across fields, I created a guide applicable to anyone. Central to it is the notion that highly ambitious individuals should choose work aligned with their natural talents, deep interests, and has the potential for outstanding output. Often, discovering your path involves trial and error, propelled by curiosity and self-driven projects. This process involves selecting a field, extensive learning, identifying knowledge gaps, and exploring them. Consistent deep interest fuels hard work, and success often stems from the cumulative effect of consistent small tasks. It's crucial to focus without distractions, allowing occasional mind-wandering for innovation. Cultivate a refined taste in your work, aiming to be the best. Authenticity is vital; true style emerges from genuine efforts rather than affectation. Optimism is essential for groundbreaking work, which requires earnestness, intellectual honesty, and a focus on substance. Great work also demands confidence to discard inauthentic parts and a drive towards elegance, where the finest, most brilliant work feels pre-existing rather than constructed.

When engaging in work that blends creation and discovery, prioritize discovery by viewing yourself as a conduit for ideas to naturally emerge. Rather than merely searching for a problem to solve, consider it an exploration to create entirely new fields. Design powerful tools with flexibility in mind, anticipating unforeseen uses. Strive to generate tools and ideas that others can expand upon or use to answer questions. The most impactful ideas have broad implications and should be articulated in general terms to uncover deeper truths. Importantly, these ideas must be both true and novel, a skill that becomes critical as you approach the boundaries of knowledge.

In English, terms like originality, creativity, and imagination denote a unique ability that seems distinct from technical skills alone. I personally find the term "creative process" inadequate because originality feels more like a habitual mindset. Original thinkers habitually generate fresh ideas in their focus areas, much like sparks from an angle grinder. However, their unfamiliarity with a topic can result in less effective ideas, highlighting originality as separate from expertise. Originality thrives in challenging work environments and often emerges from efforts to build or understand complex subjects, rather than from attempting to be original. Engaging in stimulating discussions, changing your context, and exploring varied topics can also foster originality. Notably, originality often involves recognizing obvious yet overlooked solutions that require challenging existing models. Rule-breaking and independent thinking, seen in historic figures like Einstein, are crucial for creating innovative models. People tend to be more conservative in choosing problems rather than solutions, often missing out on underrated yet significant issues. Groundbreaking work stems from the originality of chosen problems, often leading to new fields of inquiry. Embrace puzzlement and unanswered questions, as they drive discovery. Start small, take risks, and evolve projects through successive versions. Use the advantages of youth, such as energy and optimism, and the advantages of age, like knowledge and efficiency, as they come. Engage dynamically with education and leverage others' ideas to create original work. Successful collaboration and excellent colleagues are invaluable, as seen in historical clusters of greatness. Maintaining morale and an optimistic outlook is vital for ambitious endeavors.uccess.

Work can serve as a productive escape from life's problems, with its intrinsic challenges providing a constructive form of diversion. High morale leads to good work, creating a cyclical boost, whereas poor work can spiral morale downward. To stay productive, switching to easier tasks when stuck can help. Ambitious individuals often make the mistake of letting setbacks demoralize them, but setbacks are part of the process. The adage "If at first you don't succeed, try, try again" should be nuanced to include backtracking when necessary. Rather than stubbornly pushing forward, it's often wise to reassess and adjust. Persist, but don’t overdo backtracking; never abandon your core mission. Distinguishing between good pain (indicative of effort) and bad pain (indicative of damage) is crucial in assessing progress. A quality audience is vital for morale, whether you’re a scholar or an artist. The size of the audience is less important than its quality; even a small, devoted audience can be highly sustaining. Direct engagement with your audience is invaluable, and where possible, circumventing intermediaries can enhance this connection, potentially warranting a shift to a field where direct engagement is feasible.

The individuals you surround yourself with can drastically affect your morale. Some people will uplift and energize you, while others may drain your spirit, often in surprising ways. Make a conscious effort to seek out those who enhance your energy and avoid those who deplete it. Yet, if you have a responsibility to care for someone, that duty should always come first.

Don't marry someone who views your work as a rival for your attention. Your ambition and work are vital, almost like a medical necessity. If your partner obstructs your work, they either don't understand or don't care. Morale is physical; you think with your body, so maintain a healthy lifestyle by exercising, eating, and sleeping well. Running and walking are excellent for thinking. Achievers might not be the happiest, but they're happier than if they were unproductive. Ambitious, intelligent people who don't achieve can become bitter. Wanting to impress others is fine, but focus on those you genuinely respect. Fame is just noise; the true value lies in how well you can do the work. Let curiosity guide you—it knows what's truly worth your focus. Curiosity isn't everything, but you can nurture it, and it's essential in all steps of doing great work. If you're still reading, you're interested in great work. The question is whether you find work where your ability and interest spark new ideas. Don't fear failure or appearing presumptuous; aim for greatness and let curiosity drive you. Yes, it'll be hard work, but if you're on the right path, it will feel less burdensome. The discoveries are out there, waiting to be made—why not by you?`,
	},
	"demo/reid_hoffman": {
		index: `I’m stealing a chapter from this guy’s book for the demo. The book is called Blitzscaling.

**Reid Garrett Hoffman** (born August 5, 1967) is an American [internet entrepreneur](https://en.wikipedia.org/wiki/Internet_entrepreneur "Internet entrepreneur"), [venture capitalist](https://en.wikipedia.org/wiki/Venture_capitalist "Venture capitalist"), podcaster, and author. Hoffman is the co-founder and executive chairman of [LinkedIn](https://en.wikipedia.org/wiki/LinkedIn "LinkedIn"), a business-oriented [social network](https://en.wikipedia.org/wiki/Social_network "Social network") used primarily for professional networking. He is also Chairman of venture capital firm Village Global and a co-founder of [Inflection AI](https://en.wikipedia.org/wiki/Inflection_AI "Inflection AI").[\[1\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-Shead-1)[\[2\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-2)[\[3\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-3)

## Early life and education

Hoffman was an avid [tabletop roleplaying gamer](https://en.wikipedia.org/wiki/Tabletop_role-playing_game "Tabletop role-playing game") as a child[\[4\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-4) and worked as an editor at the game company [Chaosium](https://en.wikipedia.org/wiki/Chaosium "Chaosium"), then based in [Oakland, California](https://en.wikipedia.org/wiki/Oakland,_California "Oakland, California") near his home.[\[5\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-5)

Hoffman attended high school at the [progressive](https://en.wikipedia.org/wiki/Progressive_Education "Progressive Education") [Putney School](https://en.wikipedia.org/wiki/The_Putney_School "The Putney School") in [Vermont](https://en.wikipedia.org/wiki/Vermont "Vermont"),[\[6\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-6) where he engaged in farming activities.[\[7\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-Crown_Business-7) He graduated from [Stanford University](https://en.wikipedia.org/wiki/Stanford_University "Stanford University") in 1990 with a [Bachelor of Science](https://en.wikipedia.org/wiki/Bachelor_of_Science "Bachelor of Science") in [Symbolic Systems](https://en.wikipedia.org/wiki/Symbolic_system "Symbolic system") and [Cognitive Science](https://en.wikipedia.org/wiki/Cognitive_Science "Cognitive Science").[\[8\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-8) He was awarded a [Marshall Scholarship](https://en.wikipedia.org/wiki/Marshall_Scholarship "Marshall Scholarship") for graduate study abroad,[\[9\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-9) and he earned a [Master of Studies](https://en.wikipedia.org/wiki/Master_of_Studies "Master of Studies") (MSt) in philosophy from [Wolfson College, Oxford](https://en.wikipedia.org/wiki/Wolfson_College,_Oxford "Wolfson College, Oxford"), in 1993.[\[10\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-10)

His paternal great-great-great-grandfather was [Theophilus Adam Wylie](https://en.wikipedia.org/wiki/Theophilus_Adam_Wylie "Theophilus Adam Wylie"), a [Christian Presbyterian](https://en.wikipedia.org/wiki/Presbyterian_Church_\(U.S.A.\) "Presbyterian Church (U.S.A.)") minister and [Indiana University](https://en.wikipedia.org/wiki/Indiana_University "Indiana University") president pro tempore.[\[11\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-ltsosg1-11)[\[12\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-12)[\[13\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-13) Hoffman's uncle, Eric Hoffman, is a writer.[\[14\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-14)[\[15\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-15)

### **Early years**

Hoffman joined [Apple Computer](https://en.wikipedia.org/wiki/Apple_Computer "Apple Computer") in 1994, where he worked on [eWorld](https://en.wikipedia.org/wiki/EWorld "EWorld"), an early attempt at building an online service. [AOL](https://en.wikipedia.org/wiki/AOL "AOL") acquired eWorld in 1996.[\[16\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-Bloomberg_Television-16) He later worked at [Fujitsu](https://en.wikipedia.org/wiki/Fujitsu "Fujitsu") before co-founding his first company, SocialNet.com, in 1997. It focused "on online dating and matching up people with similar interests, like golfers who were looking for partners in their neighborhood."[\[17\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-Rusli-17)

### **PayPal**

While at SocialNet, Hoffman was a member of the board of directors during the founding of [PayPal](https://en.wikipedia.org/wiki/PayPal "PayPal").[\[18\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-18) In January 2000, he left SocialNet and joined PayPal full-time as the company's COO.[\[17\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-Rusli-17)[\[19\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-19)

### **LinkedIn**

Hoffman speaks at an event in 2008.

Hoffman co-founded [LinkedIn](https://en.wikipedia.org/wiki/LinkedIn "LinkedIn") in December 2002 with two former colleagues from SocialNet (including Allen Blue) from his time at Fujitsu.[\[7\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-Crown_Business-7)[\[20\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-20) LinkedIn launched on May 5, 2003 as one of the first business-oriented online social networks.[\[21\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-LinkedIn:_About-21) [Peter Thiel](https://en.wikipedia.org/wiki/Peter_Thiel "Peter Thiel"), a colleague of Hoffman's at PayPal, invested in LinkedIn. At the time of LinkedIn's [IPO](https://en.wikipedia.org/wiki/IPO "IPO") on May 19, 2011, Hoffman owned a stake worth an estimated $2.34 billion, not including any potential benefits from [Greylock Partners](https://en.wikipedia.org/wiki/Greylock_Partners "Greylock Partners"), where he was named a partner in 2009.[\[22\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-22)

[Microsoft](https://en.wikipedia.org/wiki/Microsoft "Microsoft") proposed to acquire LinkedIn on June 13, 2016 for $26.2 billion in cash.[\[23\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-23) Hoffman became a Microsoft board member on March 14, 2017.[\[24\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-24)

### **Artificial Intelligence ventures\[[edit](https://en.wikipedia.org/w/index.php?title=Reid_Hoffman&action=edit&section=6 "Edit section: Artificial Intelligence ventures")\]**

Hoffman was a founding investor in the [artificial intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence "Artificial intelligence") research company [OpenAI](https://en.wikipedia.org/wiki/OpenAI "OpenAI")[\[25\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-25) and joined its board in 2018.[\[26\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-26)

In March 2022, it was announced that Hoffman was co-founding a new startup, [Inflection AI](https://en.wikipedia.org/wiki/Inflection_AI "Inflection AI"), with his long-time friend and Greylock colleague [Mustafa Suleyman](https://en.wikipedia.org/wiki/Mustafa_Suleyman "Mustafa Suleyman"), the co-founder of [DeepMind](https://en.wikipedia.org/wiki/DeepMind "DeepMind"). [CNBC](https://en.wikipedia.org/wiki/CNBC "CNBC") reported that "Headquartered in Silicon Valley, Inflection will aim to develop AI software products that make it easier for humans to communicate with computers."[\[1\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-Shead-1)

In late 2022, Hoffman and others invested a total of $2.2 million in JusticeText. “\[G\]eared towards public defenders,” the platform “stores, catalogs, analyzes and then shares video evidence, hoping to increase transparency around criminal matters.”[\[27\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-27)

On March 3, 2023, Hoffman resigned from his board seat at OpenAI, citing a desire to avoid conflicts of interest between his board seat at OpenAI, investments in AI technology companies via Greylock Partners, and role as founder of Inflection AI.[\[28\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-28)

As of May 2023, Hoffman and Greylock Partners have invested in at least 37 AI companies.[\[29\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-29) For example, they were an early investor in Tome, makers of productivity software driven by AI. The company claims it is the fastest productivity software maker to reach 1 million users.[\[30\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-30)

Hoffman has dismissed calls to “pause” the development of advanced AI systems, calling such ideas “foolish” and “anti-humanist.” Instead, he has called for the pace of development to be accelerated to help humans solve societal problems.[\[31\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-31) For example, he’s pointed to “its potential to transform areas like health care — “giving everyone a medical assistant”; and education — “giving everyone a tutor….I’m a tech optimist, not a tech utopian.”[\[32\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-32)

[Inc.](https://en.wikipedia.org/wiki/Inc._\(magazine\) "Inc. (magazine)") dubbed Hoffman the “evangelist in chief” for Inflection AI and AI in general, citing his meetings with the likes of President Biden and the Pope to discuss his vision and concerns around AI.[\[33\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-33)[\[34\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-34)

In April of 2024, Hoffman “sat down” for an interview with an AI deepfake of himself. “In their conversation, the two Reids discussed AI regulation, its capabilities, and ways Hoffman can improve his LinkedIn profile.” According to Hoffman, the bot was “built on [OpenAI](https://en.wikipedia.org/wiki/OpenAI "OpenAI")'s GPT-4 and trained on over 20 years' worth of material provided by Hoffman's public speaking engagements and the books he's published.”[\[35\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-35)

### **Investing\[[edit](https://en.wikipedia.org/w/index.php?title=Reid_Hoffman&action=edit&section=7 "Edit section: Investing")\]**

After the PayPal sale to [eBay](https://en.wikipedia.org/wiki/EBay "EBay"), Hoffman became one of Silicon Valley's most prolific [angel investors](https://en.wikipedia.org/wiki/Angel_investor "Angel investor").[\[36\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-36) [Dave Goldberg](https://en.wikipedia.org/wiki/Dave_Goldberg "Dave Goldberg"), former CEO of [SurveyMonkey](https://en.wikipedia.org/wiki/SurveyMonkey "SurveyMonkey"), said that Hoffman "is the person you want to talk to when you are starting a company."[\[16\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-Bloomberg_Television-16) In 2009, Hoffman joined [Greylock Partners](https://en.wikipedia.org/wiki/Greylock_Partners "Greylock Partners").[\[37\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-37)

According to David Kirkpatrick's book *[The Facebook Effect](https://en.wikipedia.org/wiki/The_Facebook_Effect "The Facebook Effect")*, Hoffman arranged the first meeting between [Mark Zuckerberg](https://en.wikipedia.org/wiki/Mark_Zuckerberg "Mark Zuckerberg") and [Peter Thiel](https://en.wikipedia.org/wiki/Peter_Thiel "Peter Thiel"), which led to Thiel's initial $500,000 angel investment in [Facebook](https://en.wikipedia.org/wiki/Facebook "Facebook"). Hoffman invested alongside Thiel in Facebook's first financing round.[\[38\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-38)[\[39\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-39)

Since 2009, Hoffman has provided [venture capital](https://en.wikipedia.org/wiki/Venture_capital "Venture capital") to dozens of businesses across industries, including consumer and transportation technology, finance, and artificial intelligence. Examples include [Airbnb](https://en.wikipedia.org/wiki/Airbnb "Airbnb"), [Aurora Innovation](https://en.wikipedia.org/wiki/Aurora_Innovation "Aurora Innovation"), Taptap Send, and [Helion Energy](https://en.wikipedia.org/wiki/Helion_Energy "Helion Energy").[\[40\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-40)[\[41\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-41)[\[42\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-42)

He served on [Zynga](https://en.wikipedia.org/wiki/Zynga "Zynga")'s board of directors from March 2008 to June 2014[\[43\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-43) and currently serves on several public boards, including Aurora, [Joby Aviation](https://en.wikipedia.org/wiki/Joby_Aviation "Joby Aviation"), and Microsoft.[\[44\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-44)[\[45\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-45)[\[46\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-46)

Hoffman has made multiple investments in transportation technology companies, including Aurora, Convoy, Nauto, Nuro, and Joby Aviation, among others.[\[47\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-47)[\[48\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-48)

An early advocate for [cryptocurrency](https://en.wikipedia.org/wiki/Cryptocurrency "Cryptocurrency"),[\[49\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-49) Hoffman led Greylock's 2014 Series A financing round in Xapo, a company that developed a [bitcoin wallet](https://en.wikipedia.org/wiki/Bitcoin_wallet "Bitcoin wallet") product.[\[50\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-50)

In August 2023, Hoffman said he will not serve as a general partner for Greylock's upcoming funds.[\[51\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-51)

Hoffman has invested in [California Forever](https://en.wikipedia.org/wiki/California_Forever "California Forever"), a company developing a planned city in [Solano County, California](https://en.wikipedia.org/wiki/Solano_County,_California "Solano County, California").[\[52\]](https://en.wikipedia.org/wiki/Reid_Hoffman#cite_note-52)`,
		half: `Stealing from Reid Hoffman's book *Blitzscaling* for this demo highlights the fascinating background of Hoffman, an American internet entrepreneur, venture capitalist, podcaster, and author, born on August 5, 1967. Hoffman co-founded LinkedIn, the professional networking site, and serves as its executive chairman. Additionally, he is the Chairman of Village Global, a venture capital firm, and a co-founder of Inflection AI. Hoffman's early life was marked by his avid interest in tabletop roleplaying games, leading him to work as an editor at Chaosium, a game company in Oakland, California.

Hoffman attended high school at the progressive Putney School in Vermont, where he engaged in farming activities. He graduated from Stanford University in 1990 with a Bachelor of Science in Symbolic Systems and Cognitive Science and was awarded a Marshall Scholarship for graduate study abroad. Subsequently, he earned a Master of Studies (MSt) in philosophy from Wolfson College, Oxford, in 1993. His paternal great-great-great-grandfather was Theophilus Adam Wylie, a Christian Presbyterian minister and Indiana University president pro tempore. Hoffman's uncle, Eric Hoffman, is a writer, illustrating a family history rich in academic and literary achievements.

Hoffman joined Apple Computer in 1994 and worked on the eWorld project, an early initiative to create an online service, which was later acquired by AOL in 1996. Following his stint at Apple, he moved on to Fujitsu. In 1997, he co-founded his first company, SocialNet.com, which aimed to connect people through online dating and shared interests, such as matching golfers looking for partners in their local area.

\[16\]: Information on eWorld and its acquisition.
\[17\]: Details about SocialNet.com's focus.

Reid Hoffman was a member of the board of directors during the founding of PayPal and joined the company full-time as COO in January 2000, after leaving SocialNet. In December 2002, Hoffman co-founded LinkedIn with former colleagues, including Allen Blue, launching the platform on May 5, 2003, as one of the first business-oriented social networks. Peter Thiel, Hoffman's PayPal colleague, invested in LinkedIn, and at the time of its IPO on May 19, 2011, Hoffman's stake was estimated at $2.34 billion. Microsoft proposed to acquire LinkedIn on June 13, 2016, for $26.2 billion in cash, and Hoffman joined Microsoft's board on March 14, 2017. Additionally, Hoffman was a founding investor in OpenAI and joined its board in 2018.

In March 2022, it was announced that Reid Hoffman co-founded Inflection AI with his friend and Greylock colleague Mustafa Suleyman, aiming to develop AI software to enhance human-computer interaction. By late 2022, Hoffman had invested $2.2 million in JusticeText, a platform to aid public defenders by managing video evidence to boost transparency in criminal justice. On March 3, 2023, Hoffman resigned from his board seat at OpenAI to avoid conflicts of interest with his roles in various AI ventures. As of May 2023, he and Greylock Partners invested in at least 37 AI companies, including Tome, a rapidly growing AI-driven productivity software. Hoffman has criticized calls to pause AI development, advocating instead for accelerated progress to solve societal issues, such as improving healthcare and education. Dubbed the "evangelist in chief" for AI, Hoffman has met with global leaders including President Biden and the Pope. In April 2024, he even conducted an interview with an AI deepfake of himself to discuss AI regulation and other topics. Previously a prolific angel investor post-PayPal sale, Hoffman joined Greylock Partners in 2009, solidifying his influence in Silicon Valley.

In David Kirkpatrick's book, *The Facebook Effect*, it's noted that Reid Hoffman organized the initial meeting between Mark Zuckerberg and Peter Thiel, resulting in Thiel's pivotal $500,000 angel investment in Facebook. Hoffman also participated in Facebook's first financing round. Since 2009, Hoffman has provided venture capital to a range of businesses across multiple industries, such as consumer and transportation technology, finance, and artificial intelligence, with investments in companies like Airbnb, Aurora Innovation, Taptap Send, and Helion Energy. Serving on several public boards including Aurora, Joby Aviation, and Microsoft, he was also a board member of Zynga from March 2008 to June 2014. Hoffman has directed investments into numerous transportation technology companies, including Aurora, Convoy, Nauto, Nuro, and Joby Aviation. A proponent of cryptocurrency, Hoffman led Greylock's 2014 Series A financing round in Xapo, a bitcoin wallet product company. In August 2023, he announced he would not be a general partner for Greylock's forthcoming funds, and he has also invested in California Forever, a venture developing a planned city in Solano County, California.`,
		quarter: `Stealing from Reid Hoffman's book "Blitzscaling" highlights Hoffman's dynamic career as an American internet entrepreneur, venture capitalist, podcaster, and author. Born August 5, 1967, Hoffman co-founded LinkedIn and serves as its executive chairman. He chairs Village Global, co-founded Inflection AI, and was an early investor in OpenAI. Hoffman's early interests included tabletop roleplaying games, leading to a stint at game company Chaosium. He graduated from Stanford University with a Bachelor's in Symbolic Systems and Cognitive Science and earned a Master's in philosophy from Oxford's Wolfson College. Hoffman co-founded his first company, SocialNet.com, and played a crucial role at PayPal as COO, moving on to co-found LinkedIn, which saw a successful IPO in 2011 and was acquired by Microsoft in 2016. Hoffman co-founded Inflection AI in 2022, invested $2.2 million in JusticeText, and has been instrumental in various AI endeavors, advocating continued AI progress. A prolific investor from Greylock Partners, he has influenced key investments in companies like Facebook, Airbnb, Aurora Innovation, and Xapo. Hoffman also supports innovative projects like California Forever, a planned city in Solano County, California.`,
	},
	"demo/reid_hoffman/blitzscaling": {
		index: "yeah this is just a book the guy wrote, I copy and paste some chapters just for demo.",
		half: "yeah this is just a book the guy wrote, I copy and paste some chapters just for demo.",
		quarter:
			"yeah this is just a book the guy wrote, I copy and paste some chapters just for demo.",
	},
	"demo/reid_hoffman/blitzscaling/1.what_is_blitscaling": {
		index: `# **PART I**

# What Is Blitzscaling?

Blitzscaling is what we call both the general framework and the specific techniques that allow companies to achieve massive scale at incredible speed. If you’re growing at a rate that is so much faster than your competitors that it makes you feel uncomfortable, then hold on tight, you might be blitzscaling!

Amazon’s incredible growth in the late 1990s (and up through today) is a prime example of blitzscaling. In 1996, a pre-IPO Amazon Books had 151 employees and generated revenues of $5.1 million. By 1999, the now-public Amazon.com had grown to 7,600 employees and generated revenues of $1.64 billion. That’s a 50 times increase in staff and a 322 times increase in revenue in just three years. In 2017, Amazon had 541,900 employees and was forecast to generate revenues of $177 billion (up from $136 billion in 2016).

Dropbox founder Drew Houston described the feeling produced by this kind of growth when he told me, “It’s like harpooning a whale. The good news is, you’ve harpooned a whale. And the bad news is, you’ve harpooned a whale!”

While blitzscaling may seem desirable, it is also fraught with challenges. Blitzscaling is just about as counterintuitive as it comes. The classic approach to business strategy involves gathering information and making decisions when you can be reasonably confident of the results. Take risks, conventional wisdom says, but take calculated ones that you can both measure and afford. Implicitly, this technique prioritizes correctness and efficiency over speed.

Unfortunately, this cautious and measured approach falls apart when new technologies enable a new market or scramble an existing one.

Chris earned his MBA from Harvard Business School in the late 1990s, during the dawn of the Networked Age. Back then, his MBA training focused on traditional techniques, such as using discounted cash flow analysis to make financial decisions with greater certainty. Chris also learned about traditional manufacturing techniques, such as how to maximize the throughput of an assembly line. These methods focused on achieving efficiency and certainty, and the same emphasis was reflected in the broader business world. The world’s most valuable company during that time, General Electric, was beloved by Wall Street analysts for its ability to deliver consistent and predictable earnings growth. But efficiency and certainty, while innately appealing, and very important in the context of a stable, established market, offer little guidance to the disrupters, inventors, and innovators of the world.

When a market is up for grabs, the risk isn’t inefficiency—the risk is playing it too safe. If you win, efficiency isn’t that important; if you lose, efficiency is completely irrelevant. Over the years, many have criticized Amazon for its risky strategy of consuming capital without delivering consistent profits, but Amazon is probably glad that its “inefficiency” helped it win several key markets—online retail, ebooks, and cloud computing, to name just a few.

When you blitzscale, you deliberately make decisions and commit to them even though your confidence level is substantially lower than 100 percent. You accept the risk of making the wrong decision and willingly pay the cost of significant operating inefficiencies in exchange for the ability to move faster. These risks and costs are acceptable because the risk and cost of being too slow is even greater. But blitzscaling is more than just plunging ahead blindly in an effort to “get big fast” to win the market. To mitigate the downside of the risks you take, you should try to focus them—line them up with a small number of hypotheses about how your business will develop so that you can more easily understand and monitor what drives your success or failure. You also have to be prepared to execute with more than 100 percent effort to compensate for the bets that don’t go your way.

For example, anyone who knows Jeff Bezos knows that he didn’t simply mash his foot down on the gas pedal; Amazon has intentionally invested aggressively in the future, and, despite its accounting losses, generates a ton of cash. Amazon’s operating cash flow was over $16 billion in 2016, but it spent $10 billion in investments and $4 billion paying down debt. Its seemingly meager profits are a feature of its aggressive strategy, not a bug.

Blitzscaling requires more than just courage and skill on the part of the entrepreneur. It also requires an environment that is willing to finance intelligent risks with both financial capital and human capital, which are the essential ingredients for blitzscaling. Think of them as fuel and oxygen; you need both to propel the rocket skyward. Meanwhile, the infrastructure of your organization is the actual structure of your rocket, which you’re rebuilding on the fly as you rise. Your job as a leader and an entrepreneur is to make sure that you have sufficient fuel to propel your growth while making the necessary mechanical adjustments to the actual rocket ship to keep it from flying apart as it accelerates.

Fortunately, this is more possible today than it has ever been in the past.

# SOFTWARE IS EATING (AND SAVING) THE WORLD

Historically, stories of breakneck growth involved either computer software, which offers nearly unlimited scalability in terms of distribution, or software-enabled hardware, such as the Fitbit fitness tracker or Tesla electric car, whose software component allows the company to innovate on software timescales (days or weeks) rather than hardware timescales (years). Moreover, the speed and flexibility of software development allow companies to iterate and recover from the inevitable missteps of haste.

What’s especially exciting these days is that software and software-enabled companies are starting to dominate industries outside of traditional high tech. My friend Marc Andreessen has argued that “software is eating the world.” What he means is that even industries that focus on physical products (atoms) are integrating with software (bits). Tesla makes cars (atoms), but a software update (bits) can upgrade the acceleration of those cars and add an autopilot overnight.

The spread of software and computing into every industry, along with the dense networks that connect us all, means that the lessons of blitzscaling are becoming more relevant and easier to implement, even in mature or low-tech industries. To use a computing metaphor, technology is accelerating the world’s “clock speed” (the rate at which Central Processing Units \[CPUs\] operate), making change occur faster than previously thought possible. Not only is the world moving faster, but the speed at which major new technology platforms are being created is reducing the downtime between the arrivals of each wave of innovation. Before, individual waves would sweep through the economy one at a time—technologies like personal computers, disk drives, and CD-ROMs. Today, multiple major waves seem to be arriving simultaneously—technologies like the cloud, AI, AR/VR, not to mention more esoteric projects like supersonic planes and hyperloops. What’s more, rather than being concentrated narrowly in a personal computer industry that was essentially a niche market, today’s new technologies impact nearly every part of the economy, creating many new opportunities.

This trend holds tremendous promise. Precision medicine will use computing power to revolutionize health care. Smart grids use software to dramatically improve power efficiency and enable the spread of renewable energy sources like solar roofs. And computational biology might allow us to improve life itself. Blitzscaling can help these advances spread and magnify their sorely needed impact.

# THE TYPES OF SCALING

Blitzscaling isn’t simply a matter of rapid growth. *Every* company is obsessed with growth. In any industry, you live and die by the numbers—user acquisition, margins, growth rate, and so on. Yet growth alone is not blitzscaling. Rather, blitzscaling is *prioritizing speed over efficiency in the face of uncertainty*. We can better understand blitzscaling by comparing it to other forms of rapid growth.

*Efficiency*

*Speed*

*Uncertainty*

*Classic Start-up Growth*

*Blitzscaling*

*Certainty*

*Classic Scale-up Growth*

*Fastscaling*

**Classic start-up growth** prioritizes efficiency in the face of uncertainty. Starting a company is like jumping off a cliff and assembling an airplane on the way down; being resource-efficient lets you “glide” to minimize the rate of descent, giving you the time to learn things about your market, technology, and team before you hit the ground. This kind of controlled, efficient growth reduces uncertainty and is a good strategy to follow while you’re trying to establish certainty around what the authors Eric Ries and Steve Blank call product/market fit: your product satisfies a strong market demand for the solution to a specific problem or need.

**Classic scale-up growth** focuses on growing efficiently once the company has achieved certainty about the environment. This approach reflects classic corporate management techniques, such as applying “hurdle rates” so that the return on investment (ROI) of corporate projects consistently exceeds the cost of capital. This kind of optimization is a good strategy to follow when you’re trying to maximize returns in an established, stable market.

**Fastscaling** means that you’re willing to sacrifice efficiency for the sake of increasing your growth rate. However, because fastscaling takes place in an environment of certainty, the costs are well understood and predictable. Fastscaling is a good strategy for gaining market share or trying to achieve revenue milestones. Indeed, the financial services industry is often happy to finance fastscaling, whether by buying stocks and bonds or lending money. Analysts and bankers feel confident that they can create elaborate financial models that work out to the penny the likely ROI of a fastscaling investment.

**Blitzscaling** means that you’re willing to sacrifice efficiency for speed, but without waiting to achieve certainty on whether the sacrifice will pay off. If classic start-up growth is about slowing your rate of descent as you try to assemble your plane, blitzscaling is about assembling that plane faster, then strapping on and igniting a set of jet engines (and possibly their afterburners) while you’re still building the wings. It’s “do or die,” with either success or death occurring in a remarkably short time.

Given these definitions, you might wonder why anyone would ever pursue blitzscaling. After all, it combines the gut-wrenching uncertainty of start-up growth with the potential for a much bigger, more embarrassing, more consequential failure. Blitzscaling is also hard to implement. Unless you’re like Microsoft or Google and can finance your growth from an exponentially growing revenue stream, you’ll need to convince investors to give you money, and it’s much harder to raise money from investors for a calculated gamble (blitzscaling) than for a sure thing (fastscaling). To make matters worse, you usually need *more* money to blitzscale than to fastscale, because you have to keep enough capital in reserve to recover from the many mistakes you’re likely to make along the way.

Yet despite all of these potential pitfalls, blitzscaling remains a powerful tool for entrepreneurs and other business leaders. If you’re willing to accept the risks of blitzscaling when others aren’t, you’ll be able to move faster than they will. If the prize to be won is big enough, and the competition to win it is intense enough, blitzscaling becomes a rational, even optimal strategy.

Once you convince the market for capital and the market for talent—which include clients and partners, as well as employees—to invest in your scale-up, you have the fuel required to start blitzscaling. At that point, your objective switches from going from zero to one to going from one to one billion in an incredibly compressed time frame.

A company might employ different types of scaling at different points in its life cycle. The canonical sequence that companies like Google and Facebook have gone through begins with classic start-up growth while establishing product/market fit, then shifts into blitzscaling to achieve critical mass and/or market dominance ahead of the competition, then relaxes down to fastscaling as the business matures, and finally downshifts to classic scale-up growth when the company is an established industry leader. Together, this sequence of scaling generates a classic “S-curve” of growth, with slower initial growth followed by rapid acceleration, eventually easing its way into a gentle plateau.

![](blob:https://johnfactotum.github.io/7474a8cc-b212-41f6-a28b-76d44e60cfbe)

Of course, this canonical sequence is greatly simplified. The scaling cycle applies not just to whole companies but to individual products and business lines; the aggregate curves of these scaling cycles generate the overall scaling curve for the company.

For example, Facebook began as a classic blitzscaling story. The year-over-year revenue growth during its first few years of existence were 2,150 percent, 433 percent, and 219 percent, going from zero to $153 million in revenue in 2007. Then the company went through a key transition, and growth dropped into the double-digit range as Facebook struggled with both monetization and the shift from desktop to mobile. Fortunately, Facebook founder Mark Zuckerberg made two important moves: he personally led a shift from desktop-first to mobile-first, and he hired Sheryl Sandberg as the company’s COO, who in turn built Facebook into an advertising sales juggernaut. Growth rose back into the triple-digit range, and, by 2010, these moves had pushed Facebook’s revenues to over $2 billion. We’ll examine both of these key moves in greater detail later in the book, with Facebook’s shift to mobile featured in our analysis of Facebook’s business model, and Facebook’s hiring of Sheryl Sandberg in the section on the key transition from contributors to managers to executives.

Apple illustrates how this overlap looks over multiple decades. In its storied history, Apple went through complete scaling cycles for the Apple II, the Macintosh, the iMac, and the iPod (with the cycle for the iPhone still under way). It’s worth noting that Apple failed to launch any blitzscalable products after the Apple II and the Mac until Steve Jobs returned and launched the iMac, iPod, and iPhone. It was part of Steve’s rare genius that time and time again he was able to pick the right product for Apple to blitzscale, even without slowing down for a period of classic start-up growth to gather feedback from the market.

The scaling curve applies to every blitzscaler, regardless of industry or geography. The same multiple S-curve graph that describes Facebook or Apple also describes Tencent, which launched with QQ, then added a second curve for WeChat after QQ reached maturity in 2010. Just when you’ve finished blitzscaling one business line, you need to blitzscale the next to maintain your company’s upward trajectory. And as blitzscaling continues to spread, established companies with mature business lines should consider turning to intrapreneurs to blitzscale new business units.

# THE THREE BASICS OF BLITZSCALING

Blitzscaling requires you to move at a pace that is almost certainly uncomfortable for your team. You will definitely make many mistakes as you navigate an environment full of uncertainty; the art lies in developing the skill to learn quickly from those mistakes and return to a relentlessly rapid advance. But first, it’s critical to understand three basics.

## *1. BLITZSCALING IS BOTH AN OFFENSIVE STRATEGY* AND *A DEFENSIVE STRATEGY.*

On offense, blitzscaling allows you to do several things. First, you can take the market by surprise, bypassing heavily defended niches to exploit breakout opportunities. For example, Slack’s rapid growth after its launch blindsided a host of entrenched competitors like Microsoft and Salesforce.com. Second, you can leverage your lead to build long-term competitive advantages before other players are able to respond. We’ll explore this concept in greater detail later on. Third, blitzscaling opens up access to capital, because investors generally prefer to back market leaders. You can win this mantle if you blitzscale, and with it raise more money more easily and more quickly than your lagging competitors.

On defense, blitzscaling lets you set a pace that keeps your competitors gasping simply to keep up, affording them little time and space to counterattack. Because they’re focused on responding to your moves, which can often take them by surprise and force them to play catch-up, they don’t have as much time available to develop and execute differentiated strategies that might threaten your position. Blitzscaling helps you determine the playing field to your great advantage.

## *2. BLITZSCALING THRIVES ON POSITIVE FEEDBACK LOOPS, IN THAT THE COMPANY THAT GROWS TO SCALE FIRST REAPS SIGNIFICANT COMPETITIVE ADVANTAGES.*

In April 2014, McKinsey & Company published a report entitled “Grow fast or die slow,” which analyzed the life cycles of three thousand software and Internet companies, and found that positive feedback loops made rapid growth the key factor in financial success:

> First, growth yields greater returns. High-growth companies offer a return to shareholders five times greater than medium-growth companies. Second, growth predicts long-term success. “Supergrowers”—companies whose growth was greater than 60 percent when they reached $100 million in revenues—were eight times more likely to reach $1 billion in revenues than those growing less than 20 percent.

We believe that the mechanism behind the power of blitzscaling is “first-scaler advantage.” Once a scale-up occupies the high ground in its ecosystem, the networks around it recognize its leadership, and both talent and capital flood in.

For one, top professionals understand that they can have a greater impact working for the market leader. Meanwhile, joining a scale-up that is clearly a “rocket ship” offers many of the financial rewards of working for an early-stage start-up, with far more certainty and far less risk. Scale-up employees are paid market salaries, receive equity upside, and have a very good chance of becoming rich, if not filthy rich. By attracting the best people, scale-ups increase their ability to build and bring to market great products, which in turn increases their ability to rapidly scale.

A parallel calculus applies to investors. Venture capitalists (VCs) make investment decisions based on the confidence interval they have in their investment thesis. Achieving scale shrinks those intervals and makes it easier to decide to invest. And because the network that connects investors—especially within a tight-knit ecosystem like Silicon Valley—can disseminate this information quickly and broadly, a blitzscaling company can raise capital on a massive scale. This capital infusion can fuel explosive growth, which shrinks the confidence intervals even further.

Paradoxically, globalization has both leveled the playing field for entrepreneurs around the world *and* increased the value of being in a premier scaling hub like Silicon Valley or China. Because the rest of the world believes that these ecosystems have an advantage in scaling up start-ups, those start-ups and their investors attract capital (human and financial) from all over the world, further bolstering their ability to keep growing. This is a key reason why scale-ups like Uber and Pinterest have achieved a scale and valuation that dwarf those of most publicly traded companies. Due to my role at Greylock Partners, I can’t comment on the valuations of Dropbox and Airbnb, but they occupy a similar place in the ecosystem.

Consider the case of two very similar companies, Twitter and Tumblr. Both had brilliant, product-oriented founders in Evan “Ev” Williams and David Karp. Both were hot social media start-ups. Both grew at a remarkable rate after establishing product/market fit. Both had a major impact on popular culture. Yet Twitter went public and achieved a market capitalization that peaked at nearly $37 billion, while Tumblr was acquired by Yahoo!—another start-up that used blitzscaling to become a scale-up, only to decline and fade away—for “only” $1 billion.

Was this dumb luck on Twitter’s side? Perhaps. Luck always plays a larger role than founders, investors, and the media would like to admit. But a major difference was that Twitter could draw on numerous networks for advice and help that Tumblr could not. For example, Twitter was able to bring in Dick Costolo, a savvy executive with prior scaling experience at Google. In contrast, even though Tumblr was arguably the most prominent start-up in its New York City ecosystem, it couldn’t easily draw upon a pool of local talent who had experience dealing with rapid growth. According to Greylock’s John Lilly, for every executive role that Tumblr needed to fill, there were less than a handful of candidates in all of New York City. This paucity of talent made hiring difficult; the company was reluctant to replace existing employees due to a lack of better alternatives. Without the ability to hire an executive team that could blitzscale, Tumblr decided to sell the company.

Of course, while geography can present challenges to blitzscaling, they become much more solvable if you’re aware of them. For example, over the past decade, Priceline—the world’s most successful online travel company—has been able to blitzscale from its headquarters in Connecticut. The CEO who led Priceline during its growth phase, Jeffery Boyd, saw advantages to this geographic isolation, noting that the company’s location meant that it faced fewer bidding wars for the key software engineers and designers needed to support the rapid growth of the business.

It’s extremely difficult for later entrants to compete directly with a blitzscaling company that has first-scaler advantage. Unless these players find a different game in which they can capture this advantage, they’ll simply become irrelevant.

## *3. DESPITE ITS INCREDIBLE ADVANTAGES AND POTENTIAL PAYOFFS, BLITZSCALING ALSO COMES WITH MASSIVE RISKS.*

Until recently, “Move fast and break things” was Facebook’s famous motto. Yet rapid growth can cause nearly as many problems as it solves. As Mark Zuckerberg told me in an interview for my *Masters of Scale* podcast, “We got to a point where it was taking us more time to go back and fix the bugs and issues that we’re creating than the speed that we were gaining by going faster.” In one famous incident, a summer intern introduced a bug that brought down the entire Facebook site for thirty minutes.

There is a scientific term for out-of-control growth in the human body: “cancer.” In this context, uncontrolled growth is clearly undesirable. The same is true for a business. Successful blitzscaling means that you’re maintaining at least some level of control by rapidly fixing the things that will inevitably get broken so that the company can maintain its furious pace without flaming out or collapsing in on itself. Like an American football player streaking down the field for a game-winning touchdown, even a company that has achieved first-scaler advantage can lose the ball prior to crossing the goal line if it takes on a bigger risk than it can handle.

Blitzscaling is risky from a management perspective as well. Reinventing your leadership style, your product, and your organization at every new phase of scale won’t be easy, but it is necessary. In the words of leadership guru Marshall Goldsmith, “What got you here won’t get you there.”

Market share and revenue growth earn headlines, but you can’t achieve customer and revenue scale without scaling up your organization, in terms of the size and scope of your staff, as well as your financial, product, and technology strategy. If the organization doesn’t grow in lockstep with its revenues and customer base, things can quickly spiral out of control.

For example, during a period of blitzscaling in the late 1980s and early 1990s, Oracle Corporation focused so single-mindedly on sales growth that its organization lagged badly on both technology (where it fell behind archrival Sybase’s) and finance and nearly went bankrupt as a result. It took the turnaround efforts of Ray Lane and Jeff Henley to stave off disaster and reposition Oracle for its later success.

Blitzscaling your organization will require hard choices and sacrifices; for example, the people who are adept at launching a company aren’t necessarily going to be the right people to scale it, as the Oracle example above demonstrates. Later in the book we’ll discuss how successful blitzscalers consciously manage growth rather than letting it manage them.

# THE FIVE STAGES OF BLITZSCALING

Blitzscaling a start-up isn’t a linear process; a global giant isn’t simply a start-up that’s been multiplied by one thousand, working out of a gleaming high-rise headquarters instead of a grimy garage. Each major increment of growth represents a qualitative as well as quantitative change. Drew Houston of Dropbox expressed this well when he told me, “The chessboard keeps adding new pieces and new dimensions over time.”

In the physical sciences, materials often undergo phase changes as their circumstances (e.g., temperature and pressure) change. Ice melts into water; water boils into steam. As a start-up scales up from one phase to the next, it undergoes fundamental changes as well.

And in the same way that ice skates are useless on water, and you can’t skip rocks on water vapor, the approaches and processes that worked for one phase break down once the scale-up reaches the next phase.

This book is designed to help you successfully navigate the phase changes you’ll face on the path to global dominance.

Throughout this book, we will refer to the five key stages of blitzscaling using the metaphor of a community. Since the most obvious, visible, and impactful change in a scale-up is the number of people it employs, we’ll define the stages based on the number of employees in the company, or its organizational scale.

# THE FIVE STAGES OF BLITZSCALING

*Stage 1 (Family)*

*1–9 employees*

*Stage 2 (Tribe)*

*10s of employees*

*Stage 3 (Village)*

*100s of employees*

*Stage 4 (City)*

*1000s of employees*

*Stage 5 (Nation)*

*10000s of employees*

Each stage has critical differences when it comes to management and leadership. When you’re head of a nuclear Family, you have close relationships with all of your Family members. When you’re the head of a whole Nation, you’re responsible for the lives of a multitude of people, most of whom you’ll never meet. (Later in the book we’ll talk about how to optimize your people management strategy as your company grows.)

It’s important to remember that while these powers of ten provide a clear and consistent set of categories, real life is often messier. For example, a start-up with a tight-knit team might feel and act like a Family even if it has nearly twenty employees. So these definitions are meant simply to offer a useful set of guidelines.

We also recognize that the number of employees is only one of several measures of an organization’s scale. Some of the other measures of scale include the number of users (user scale), the number of customers (customer scale), and total annual revenues (business scale). These measures usually, but don’t always, move in lockstep. While it’s nearly impossible to achieve customer scale or business scale without organizational scale—customers require customer service representatives, and revenues typically require salespeople—it is possible to achieve user scale without organizational scale. Consider the example of Instagram: when that company was acquired by Facebook for $1 billion, it had over one hundred million users but just thirteen employees and no significant revenues.

The fact that the phases don’t always move in lockstep is a *feature* of blitzscaling, not a bug. As we’ll discuss, operational scalability is one of the primary growth limiters that scale-ups need to address. When a business can grow users, customers, and revenues faster than the number of employees without collapsing under the weight of its own growth, the business can achieve greater profitability and keep growing without being as tightly constrained by the need for financial or human capital. In contrast, when the number of employees grows faster than users, customers, and revenues, it’s a major red flag that could indicate issues with the fundamental business model.

Nevertheless, for the sake of simplicity, this book will typically define the stage of a company by its organizational scale. A Family-stage company will have one to nine employees, a Tribe-stage company will have ten to ninety-nine employees, and so on. When exceptions arise, we’ll specifically call them out to avoid confusion.

# THE THREE KEY TECHNIQUES OF BLITZSCALING

Through much study of, direct access to, and conversation with the leadership at companies such as Google, Amazon, and Facebook—and through my own experiences as an entrepreneur and an investor—we’ve been able to identify the three key techniques applied by entrepreneurs and investors to build dominant companies. These basic principles do not depend on geography and can be adapted to build great companies in any ecosystem, albeit with varying degrees of difficulty.

## *TECHNIQUE #1: BUSINESS MODEL INNOVATION*

The first technique of blitzscaling is to design an innovative business model that can truly grow. This sounds like a Start-ups 101–level insight, but it’s astounding how many founders miss this key element. A major mistake made by many start-ups around the world is focusing on the technology, the software, the product, and the design, but neglecting to ever figure out the business. And by “business” we simply mean how the company makes money by acquiring and serving its customers. In contrast, despite the popular “engineers are gods” narrative prevalent in Silicon Valley, the companies and founders we universally hail as geniuses aren’t just technology nerds—they’re almost always business nerds too. At Google, Larry Page and Sergey Brin built great search algorithms, but it was their innovations to the search engine *business model*—specifically, considering relevance and performance when displaying advertisements rather than simply renting space to the highest bidder—that drove their massive success.

As the world has gone digital, business model innovation has become even more important. So many technologies are available as services, which are on demand and built to be integrated, that technology is no longer as strong a differentiator, while figuring out the right combinations of services to bring together into a breakthrough product has become a major differentiator. Most of today’s successful companies are more like Tesla, which combines a set of technologies that already existed, rather than SpaceX, which had to pioneer new ones.

Business model innovation is how start-ups are able to outcompete established competitors who typically hold a host of advantages over any upstarts. As a start-up, Dropbox competes with giants like Microsoft and Google, who ought to have major advantages in technology, finance, and market power. Dropbox founder and CEO Drew Houston knows that his company can’t simply rely on better technology or outexecuting the competition: “If your playbook is the same as your competitor’s, you are in trouble, because chances are they are just going to run your playbook with a lot more resources!”

Drew had to design a better business model, in which the focus on sharing files means that the number of files Dropbox has to store (or in the past, pay Amazon to store) increases far more slowly than the value created for the customer and thus the revenues Dropbox can collect from those customers. Uber and Airbnb also built large businesses at incredible speed based on novel business models rather than unprecedented new technologies. If technological innovation alone were enough, federal research labs would produce $100 billion companies on a regular basis. Spoiler alert: they don’t.

This is not to say that technology innovation is unimportant. Technology innovation is the most common trigger for launching a new market or upending an existing one. Uber wasn’t the first company to try to improve the experience of hailing a taxi. But prior to the technological innovation of the smartphone, complete with wireless Internet connection and GPS-enabled location-based services, Uber’s business model simply wouldn’t have worked. These innovations reduced the friction for both driver and rider, making Uber’s core UberX ridesharing model a mass-market possibility for the first time.

Nor can companies afford to ignore technology innovation after they successfully blitzscale their way to City or Nation stage. Each and every one of the technology companies worth over $100 billion has used technology leadership to reinforce its competitive advantages. Amazon may have started as a simple online retailer with no unique technology, but today its technological prowess in cloud computing, automated logistics, and voice recognition help to maintain its dominance. In fact, the megacompanies built by blitzscaling are often the ones buying the technology innovators, much as Google bought DeepMind and Facebook bought Oculus.

Technology innovation is a key factor in retaining the gains produced by business model innovation. After all, if one technology innovation can create a new market, another technology innovation can render it obsolete, seemingly overnight. While Uber has achieved massive scale, the greatest threat to its future doesn’t come in the form of direct competitors like Didi Chuxing, though these are formidable threats. The greatest threat to Uber’s business is the technology innovation of autonomous vehicles, which could make obsolete one of Uber’s biggest competitive advantages—its carefully cultivated network of drivers—essentially overnight.

The key is to combine new technologies with effective distribution to potential customers, a scalable and high-margin revenue model, and an approach that allows you to serve those customers given your probable resource constraints.

Ideally, you design your business model innovation before you start your company. This is what happened when I cofounded LinkedIn. The key business model innovations for LinkedIn, including the two-way nature of the relationships and filling professionals’ need for a business-oriented online identity, didn’t just happen organically. They were the result of much thought and reflection, and I drew on the experiences I had when founding SocialNet, one of the first online social networks, nearly a decade before the creation of LinkedIn. But life isn’t always so neat. Many companies, even famous and successful ones, have to develop their business model innovation after they have already commenced operations.

PayPal didn’t have a business model when it began operations (I was a key member of the PayPal executive team). We were growing exponentially, at 5 percent per day, and we were losing money on every single transaction we processed. The funny thing is that some of our critics called us insane for paying customers bonuses to refer their friends. Those referral bonuses were actually brilliant, because their cost was so much lower than the standard cost of acquiring new financial services customers via advertising. (We’ll discuss the power and importance of this kind of viral marketing later on.)

The insanity, in fact, was that we were allowing our users to accept credit card payments, sticking PayPal with the cost of paying 3 percent of each transaction to the credit card processors, while charging our users nothing. I remember once telling my old college friend and PayPal cofounder/CEO Peter Thiel, “Peter, if you and I were standing on the roof of our office and throwing stacks of hundred-dollar bills off the edge as fast as our arms could go, we still wouldn’t be losing money as quickly as we are right now.” We ended up solving the problem by charging businesses to accept payments, much as the credit card processors did, but funding those payments using automated clearinghouse (ACH) bank transactions, which cost a fraction of the charges associated with the credit card networks. But if we had waited until we had solved this problem before blitzscaling, I suspect we wouldn’t have become the market leader.

## *TECHNIQUE #2: STRATEGY INNOVATION*

The most obvious element of blitzscaling is the pursuit of extreme growth, which, when combined with an innovative business model, can generate massive value and long-term competitive advantage. Many start-ups believe they are pursuing a strategy of extreme growth, when in fact they have the *goal* and the *wish* for extreme growth but no understanding of an actual strategy that will get them there. To achieve your goals, you have to know what you plan to do and, just as important, what you plan *not* to do. Also, growth doesn’t create value in and of itself; for that, it has to be paired with a working business model. It’s easy to achieve extreme customer and revenue growth if your company sells $20 bills for $1, but “we’ll make it up in volume” won’t allow you to build any sustainable value.

For successful blitzscaling, the competitive advantage comes from the growth factors built into the business model, such as network effects, whereby the first company to achieve critical scale triggers a feedback loop that allows it to dominate a winner-take-all or winner-take-most market and achieve a lasting first-scaler advantage. For example, Uber’s strategy of aggressive city-by-city expansion allows its customers to hail rides with fewer delays than its competitors. Uber wants you to be able to get a ride faster with Uber than with anyone else. This attracts more customers, which attracts more drivers, which increases the liquidity of the marketplace, which allows customers to hail rides even more quickly, which attracts more customers, and so on. Early Uber investor Bill Gurley laid out Uber’s strategy in his 2012 blog post “All Markets Are Not Created Equal.”

> As the company grows, they are able to facilitate more cars on the road, and along with their investment in route and load optimization, this allows for shorter and shorter pickup times. The experience gets better and better the longer they are in the market.

Blitzscaling goes beyond just a strategy of aggressive growth because it involves doing things that don’t make sense according to traditional business thinking, such as prioritizing speed over efficiency despite an uncertain environment. At the same time, blitzscaling also goes beyond just risk taking. It may be risky to bet the company, as Walt Disney did when he borrowed against his own life insurance to build Disneyland, but it’s not blitzscaling. Blitzscaling would have involved inefficiencies like paying construction crews to work twenty-four hours a day in order to get Disneyland open a few months earlier, or reducing ticket prices 90 percent to get to one million visitors faster—knowing that those one million visitors were networked to ten million more.

Here is one of the ruthless practices that has helped make Silicon Valley so successful: Investors will look at a company that is on an upward trajectory but doesn’t display the proverbial hockey stick of exponential growth and conclude that they need to either sell the business or take on additional risk that might increase the chances of achieving exponential growth. Achieving 20 percent annual growth, which would delight Wall Street analysts covering any other industry, simply isn’t enough to transform a start-up into a multibillion-dollar company fast enough. Silicon Valley venture capitalists want entrepreneurs to pursue exponential growth even if doing so costs more money and increases the chances that the business could fail, resulting in a bigger loss. Dropping below even 40 percent annual growth is a warning sign for investors.

This mindset can be difficult for people to understand. “Why should I risk it all and potentially blow up what is a successful, growing business?” they might rightfully ask. The answer is that blitzscaling businesses tend to play in winner-take-most or winner-take-all markets. The greater risk for a successful, growing business is to move too slowly and allow its competitors to win market leadership and first-scaler advantage.

Nokia is a great example of the cost of caution. In 2007, Nokia was the world’s largest and most successful maker of mobile phones, with a market capitalization of just under $99 billion. Then Apple and Samsung came blazing into the market. In 2013, Nokia sold its money-losing handset operations to Microsoft for $7 billion, and in 2016 Microsoft sold its feature phone assets and the Nokia handset brand to Foxconn and HMD for just $350 million. That’s a drop in value for Nokia’s mobile phone business from somewhere in the neighborhood of $99 billion to $350 million in less than a decade—a decline of over 99 percent.

At the time, Nokia’s decisions may have seemed to make sense. Nokia actually continued growing even after the launch of the iPhone and Google’s Android operating system. Nokia hit its peak in terms of unit volume when it shipped 104 million phones in 2010. But Nokia’s sales declined after that, and were surpassed by Android in 2011 and iPhone in 2012. By the time Nokia’s management realized the existential threat facing them, it was too late; even the desperation play of aligning themselves with Microsoft as its exclusive Windows Phone partner couldn’t reverse the decline.

Because blitzscaling often requires spending significant amounts of capital in ways that traditional business wisdom would consider “wasteful,” implementing a financial strategy that supports this aggressive spending is a critical part of blitzscaling. For example, Uber often uses heavy subsidies on both sides of the marketplace when it launches in a new city, lowering fares to attract riders and boosting payments to attract drivers. By paying out more than it takes in on those early trips, Uber is able to reach critical scale faster than a more conservative competitor. Given the winner-take-most nature of the ridesharing market, that “wasteful” spending has helped Uber achieve a dominant market position in the cities in which it operates. Of course, that strategy isn’t possible without the ability to raise massive amounts of capital on favorable terms. In Uber’s case, it has been able to raise nearly $9 billion between its founding and the writing of this book. At some point, Uber will have to demonstrate the ability to significantly improve its unit economics, or its investors will get very grumpy. This concern helps explain Uber’s significant investments in autonomous vehicle technology, which could eliminate its biggest expense—driver payments—in one fell swoop.

The willingness to take on the risks of blitzscaling is one of the major reasons why Silicon Valley has produced such a disproportionate share of blockbuster companies in comparison to other geographies. To be fair, it has also produced a disproportionate share of financial disasters—hence the word “risk” when talking about blitzscaling. But as the rise of juggernauts like Alibaba and Spotify illustrates, blitzscaling is also starting to take off around the world.

## *TECHNIQUE #3: MANAGEMENT INNOVATION*

The final technique required for blitzscaling is management innovation. This is necessary because of the extreme strains placed on the organization and its employees by hypergrowth.

I am fond of pointing out to entrepreneurs and executives that “in theory, you don’t need practice.”

What I mean is that no matter how brilliant your business model and growth strategy, you won’t be able to build a real-world (i.e., non-theoretical) blockbuster company without a lot of practice. But that problem is magnified when you’re trying to blitzscale.

The kind of growth involved in blitzscaling typically means major human resources challenges. Tripling the number of employees each year isn’t uncommon for a blitzscaling company. This requires a radically different approach to management than that of a typical growth company, which would be happy to grow 15 percent per year and can take time finding a few perfect hires and obsessing about corporate culture. As we will discuss in more detail later in the book, companies that blitzscale have to rapidly navigate a set of key transitions as their organizations grow, and have to embrace counterintuitive rules like hiring “good enough” people, launching flawed and imperfect products, letting fires burn, and ignoring angry customers.

Over the course of this book, we’ll see how business model, growth strategy, and management innovation work together to form the high-risk, high-reward process of blitzscaling.`,
		half: `Blitzscaling is a framework and set of tactics that allow companies to achieve massive scale quickly, often at an uncomfortable pace, as exemplified by Amazon's meteoric rise from 151 employees in 1996 to 541,900 in 2017. The dramatic increase in revenues, from $5.1 million to a forecasted $177 billion during the same period, reflects this rapid growth. Dropbox's Drew Houston likened it to the exhilarating yet daunting experience of "harpooning a whale." Unlike traditional strategies that emphasize calculated risks and efficiency, blitzscaling involves making rapid decisions with less confidence and accepting operational inefficiencies to gain speed. The goal is to capture new or disrupted markets, where the biggest risk is playing too cautiously. Critics have questioned Amazon's approach of consuming capital without consistent profits, but its strategy has proven successful in securing key markets like online retail and cloud computing. Blitzscaling requires substantial financial and human capital, as well as the ability to adapt the organizational structure dynamically, akin to adjusting a rocket mid-flight. This high-risk, high-reward strategy is increasingly feasible today, particularly with the advent of transformative technologies.

Historically, rapid growth often came from software and software-enabled hardware, like the Fitbit or Tesla, where software allows quick innovation and recovery from errors. Today, software is extending beyond traditional high-tech industries, as noted by Marc Andreessen's assertion that "software is eating the world." This fusion of software (bits) with physical products (atoms) enables continuous updates and improvements, such as Tesla's software upgrades for car performance. The integration of software into various industries accelerates change, akin to increasing the “clock speed” of the world’s CPUs, making innovations emerge faster and more simultaneously. Unlike the past, where technological waves like personal computers arrived sequentially, we now see concurrent innovations in cloud computing, AI, AR/VR, and more. This broad impact creates new opportunities across the economy, from precision medicine revolutionizing healthcare to smart grids enhancing power efficiency and computational biology improving life. Blitzscaling drives this transformative reach by prioritizing speed over efficiency amid uncertainty, distinct from mere rapid growth, as it focuses on swift scaling even at the cost of temporary inefficiencies.

Efficiency speed is all about integrating productivity with agility, ensuring that tasks are completed not only quickly but also with optimal performance. It’s the art of balancing speed without compromising on quality, making sure that every effort counts. This means utilizing tools and techniques that streamline processes, eliminate unnecessary steps, and drive results with precision. By focusing on efficiency speed, you’re not just getting things done faster, but smarter, ultimately leading to better outcomes and a more seamless workflow.

"Uncertainty" can feel like a heavy cloud lingering over our lives, twisting and turning our thoughts into knots of doubt and fear. It’s the unsettling feeling of not knowing what comes next and the paralyzing experience of grappling with the unknown. We often crave control and predictability, but life, with its inherent unpredictability, rarely grants us that comfort. Embracing uncertainty, though difficult, can open the door to growth, innovation, and resilience. It challenges us to let go of rigid expectations and adapt, fostering a deeper appreciation for the present and an openness to life's endless possibilities. It’s a complex, often unnerving journey, but it's within this journey that we find the strength to navigate the ever-changing landscape of our existence.

Blitzscaling is all about achieving rapid growth by prioritizing speed over efficiency during times of uncertainty, ideal for start-ups desperate to capture a market before competitors. In contrast, classic start-up growth involves steady, deliberate scaling, focusing on sustainability and minimizing risks. Certainty here allows for careful planning and resource management. Once a company matures into a classic scale-up, it can adopt ‘fastscaling’ techniques, which aim to maintain rapid expansion while introducing more operational efficiencies and reduced risks. This hybrid approach balances the aggressive blitzscaling tactics with the prudent strategies of classic start-up growth.

Starting a company feels like assembling an airplane while falling off a cliff, prioritizing efficiency to slow your descent, thus allowing time to learn about your market, technology, and team until achieving product/market fit as defined by Eric Ries and Steve Blank. Once certainty about the environment is attained, classic scale-up growth focuses on resource efficiency and maximizing ROI. Fastscaling trades some efficiency for higher growth rates in a predictable and understood environment, typically appealing to investors due to the clarity in ROI projections. Blitzscaling, on the other hand, sacrifices efficiency and operates without complete certainty, symbolizing a high-stakes, rapid growth strategy aimed at outpacing competition despite significant risks and potential needs for substantial investment. This approach, used by companies like Google and Facebook, can lead to rapid and exponential growth, followed by stabilization through fastscaling and classic scale-up growth once market dominance is achieved. This scaling pattern can be seen throughout the life cycles of successful firms like Facebook and Apple, which have gone through multiple scaling cycles for different products. The critical aspect of blitzscaling is the willingness to operate in discomfort, learning quickly from inevitable mistakes to maintain relentless progress.

Blitzscaling serves both as an offensive and defensive strategy, enabling companies to capture markets by surprise, build long-term competitive advantages, and access capital more easily, as illustrated by Slack's rapid growth outpacing established competitors. Defensively, it sets a relentless pace, forcing competitors to focus on catching up rather than developing differentiated strategies. This approach thrives on positive feedback loops, where companies that scale first gain significant advantages, attracting top talent and investment, as evidenced by high-growth companies achieving far greater returns and success. A "first-scaler advantage" helps companies like Uber and Pinterest reach valuations far surpassing most public companies. Geographic elements also play a role; for instance, Twitter capitalized on Silicon Valley's rich pool of experienced talent for scaling, unlike Tumblr, which struggled in New York City's talent-scarce environment and ended up selling to Yahoo! Successful examples like Priceline demonstrate that while geography can pose challenges, awareness and strategic isolation, as seen with its Connecticut headquarters, can mitigate these issues. Ultimately, blitzscaling creates a formidable barrier for late entrants unless they significantly differentiate their approach.

Blitzscaling, while offering incredible advantages and potential payoffs, inherently comes with massive risks.

Until recently, Facebook embraced the motto “Move fast and break things,” but rapid growth entailed its own challenges. As Mark Zuckerberg shared on my Masters of Scale podcast, the rapid pace often necessitated more time fixing issues than the gains achieved from moving quickly. One notable incident involved a summer intern introducing a bug that crashed the entire site for thirty minutes. Analogous to cancer in the human body, unchecked growth in business is equally detrimental. Successful blitzscaling involves efficiently addressing inevitable disruptions to maintain momentum without collapsing. As in American football, even a first-scaler advantage can be lost if risks aren't managed. Scaling requires constant reinvention of leadership, products, and organizational strategies at each new phase, aligning market share and revenue growth with organizational capacity. For instance, during its rapid expansion in the late '80s and early '90s, Oracle prioritized sales over technology and finance, nearly leading to bankruptcy until a turnaround. Scaling up involves difficult decisions, like replacing initial team members who may not suit the company's new phase. As Dropbox's Drew Houston noted, each growth phase necessitates different strategies, akin to how tools useful on ice are ineffective on water.

This book is designed to help you successfully navigate the phase changes you’ll face on the path to global dominance.

Throughout this book, we'll explore the five key stages of blitzscaling using the metaphor of a community. Since the most noticeable, visible, and impactful shift in a scale-up is the increase in the number of people it employs, we'll define these stages based on the number of employees in the company, also known as its organizational scale. Welcome to the journey of blitzscaling, starting with Stage 1: Family.

If your business has a small team of 1–9 employees, it's crucial to maximize agility and foster a collaborative environment. In such a close-knit setting, each team member plays a critical role in driving the company's success and has the opportunity to contribute meaningfully to various projects. Communication and adaptability are key, as the team dynamics can significantly influence business outcomes. Embrace the strengths and unique skills of each individual, and encourage an atmosphere of innovation and support. This approach not only enhances productivity but also cultivates a positive workplace culture that fuels growth and achievement.

- **Stage 2 (Tribe):** This stage involves tens of employees.
- **Stage 3 (Village):** At this stage, an organization grows into hundreds of employees.
- **Stage 4 (City):** Once the employee count reaches into the thousands, the organization can be considered at the city stage.
- **Stage 5 (Nation):** When the workforce expands into the tens of thousands, the organization has reached the nation stage.

Each stage of management and leadership, from a nuclear Family to a Nation, requires different approaches. While tight-knit start-ups might feel like a Family, even with nearly twenty employees, broader organization scales can involve millions of users or significant revenues with far fewer employees, like Instagram with its thirteen employees and over one hundred million users at the time of its acquisition by Facebook. This book classifies company stages primarily by employee count: Family-stage (1-9 employees), Tribe-stage (10-99 employees), and so on. However, organization scale is just one measure; user scale, customer scale, and business scale are other crucial metrics. These often, but not always, grow together, a feature not a bug in blitzscaling. The primary growth limiters include operational scalability, which, if managed well, enables business profitability and growth. Conversely, a disproportionate increase in employees versus users, customers, or revenues signals potential business model issues. Our discussion on optimizing people management and strategic exploitation of these scaling principles draws from extensive study and insights from industry leaders and personal entrepreneurial experiences.

# Technique #1: Business Model Innovation

The first technique of blitzscaling is designing an innovative business model that can grow efficiently, which is a surprisingly overlooked aspect by many start-ups who focus excessively on technology, software, and product design without a clear strategy for monetization. While Silicon Valley often celebrates "engineers as gods," successful companies often owe their triumphs to business acumen as much as technological prowess. Larry Page and Sergey Brin, for example, weren't only tech whizzes; their business model innovations at Google, particularly in ad relevance and performance, catapulted their success. As the digital landscape evolves, business model innovation outshines mere technological differentiation. Successful companies, like Tesla, often differentiate themselves by integrating existing technologies into groundbreaking products, unlike SpaceX, which pioneers entirely new technologies. Business model innovation is crucial for startups to compete with established giants, as seen in Dropbox's strategy to outmaneuver Microsoft and Google by optimizing file-sharing efficiencies. Companies like Uber and Airbnb scaled rapidly through innovative business models rather than groundbreaking tech. While technological innovation is vital for initiating and sustaining market leadership, as demonstrated by Amazon's evolution in cloud computing and logistics, the synergy of tech and business model innovation retains competitive advantages. For instance, Uber's rise would have faced dire challenges without smartphone-based technology but now must confront the looming threat of autonomous vehicles. Ultimately, blending new technologies with scalable revenue models, efficient distribution, and resource-conscious strategies is essential for success, ideally built into the business model from the start, though some companies refine it along the way, as LinkedIn did with insights from earlier ventures like SocialNet.

PayPal’s early days were marked by rapid growth and substantial losses, partly due to offering referral bonuses and absorbing credit card transaction fees. At one point, I joked with co-founder Peter Thiel about how we were losing money faster than if we were throwing it off the roof. We eventually addressed this issue by charging businesses and using lower-cost automated clearinghouse (ACH) transactions. This approach, a hallmark of "blitzscaling," involves pursuing extreme growth with innovative strategies, often incurring short-term inefficiencies for long-term market dominance. Blitzscaling emphasizes the importance of speed over efficiency in uncertain situations, leveraging network effects to build a competitive moat, as seen in companies like Uber and its focus on improving customer experience through rapid expansion. This method, characterized by heavy up-front spending and the ability to secure massive capital, is foundational to Silicon Valley's success but also carries significant risk, as evidenced by Nokia's fall from dominance due to slow adaptation. Blitzscaling’s acceptance is growing globally, showcased by companies like Alibaba and Spotify.

The final technique essential for blitzscaling is management innovation due to the immense pressures hypergrowth imposes on organizations and their employees. I often remind entrepreneurs and executives that “in theory, you don’t need practice,” highlighting that even the most brilliant business model and growth strategy require substantial real-world application to build a successful company. This challenge is intensified with blitzscaling, which typically involves significant human resources hurdles, such as tripling the employee count annually. This rapid growth necessitates a radically different management approach compared to a typical growth company, which might aim for 15 percent annual growth and can afford to meticulously select hires and focus on corporate culture. Blitzscaling companies, however, must rapidly navigate key organizational transitions and embrace counterintuitive practices like hiring “good enough” people, launching imperfect products, letting fires burn, and ignoring angry customers. Throughout this book, we’ll explore how business models, growth strategies, and management innovations converge to drive the high-risk, high-reward blitzscaling process.`,
		quarter: `Blitzscaling is a strategy and set of tactics enabling companies to achieve massive scale quickly, typified by Amazon's rapid expansion from 151 employees in 1996 to 541,900 in 2017, and a revenue leap from $5.1 million to a projected $177 billion. Similarly, Dropbox's Drew Houston compared blitzscaling to "harpooning a whale," illustrating its thrilling yet risky nature. Unlike traditional approaches focused on calculated risks and operational efficiency, blitzscaling pushes for rapid decision-making with less certainty, embracing inefficiencies to speed up market capture, especially in disruptive environments. While Amazon's strategy of capital consumption without consistent profits has faced criticism, it has successfully secured essential markets like online retail and cloud computing. Blitzscaling demands significant financial and human resources, and the ability to dynamically adjust organizational structures, akin to fine-tuning a rocket mid-flight. This high-risk, high-reward method is more feasible today due to transformative technologies, with software playing a crucial role in rapid innovation and recovery from errors, as emphasized by Marc Andreessen's notion that "software is eating the world." The integration of software into various industries accelerates change, increasing the "clock speed" of global innovation. Unlike the sequential technological waves of the past, today’s concurrent advancements—in cloud computing, AI, AR/VR—create widespread economic opportunities, from precision medicine to smart grids and computational biology. Blitzscaling thus prioritizes speed over efficiency in uncertain conditions, distinct from mere rapid growth, by emphasizing swift scaling despite temporary inefficiencies, ultimately blending productivity with agility to achieve better, smarter outcomes.

"Uncertainty" can feel like a heavy cloud over our lives, twisting thoughts into knots of doubt and fear. It brings the unsettling feeling of not knowing what comes next and the paralyzing experience of grappling with the unknown. We often crave control and predictability, but life rarely grants that comfort. Embracing uncertainty, though difficult, can lead to growth, innovation, and resilience. It challenges us to let go of rigid expectations and adapt, fostering a deeper appreciation for the present and an openness to life's possibilities. It's a complex, often unnerving journey, but within it, we find the strength to navigate the ever-changing landscape of our existence.

Blitzscaling revolves around achieving rapid growth by prioritizing speed over efficiency in uncertain times, targeting market capture before competitors, unlike classic start-up models that grow steadily with risk minimization. As companies mature, they can employ fastscaling to maintain growth while improving operational efficiencies and reducing risks. Blitzscaling, used by giants like Google and Facebook, involves tolerating discomfort, making quick decisions, and learning from mistakes to outpace competitors, capture markets, build competitive advantages, and attract top talent and investment. This strategy can cause significant disruptions but is crucial for rapid market dominance. Scaling stages, from Family (1-9 employees) to Nation (tens of thousands), require different management approaches. Successful blitzscaling combines tech innovation with business model innovation to scale efficiently, as demonstrated by companies like Uber, Airbnb, and Dropbox. The path includes adapting management practices to manage hypergrowth pressures. The book aims to guide through these phases, emphasizing the integration of new technologies, scalable revenue models, and strategic resource management for enduring success.`,
	},
	"demo/reid_hoffman/blitzscaling/2.business_model_innovation": {
		index: `# **PART II**

# Business Model Innovation

Of the three core techniques of blitzscaling, the first and most foundational is to design an innovative business model capable of exponential growth.

The story of entrepreneurship in the Internet era is a story of this kind of business model innovation.

Think back to the dot-com era, which stretched roughly from the IPO of Netscape in 1995 until the NASDAQ began to crash in 2000. During this period, enormous numbers of start-ups and pretty much every established company tried to build great Internet businesses, yet nearly all of them failed. The problem was, most of them simply tried to cut and paste existing business models onto the new online medium. You can’t transplant a heart from one species into another and expect it to thrive.

If you had asked stock market analysts in 1995 which companies were best positioned to dominate the Internet, most would have pointed to existing giants like Microsoft and Time Warner, which invested millions in Internet businesses like MSN and Pathfinder. Others would have mentioned “pure play” dot-com start-ups like eToys, which combined proven business models like the “category killer” store with the new online medium.

Yet when the wreckage of the dot-com crash cleared, the most successful companies still charging full steam ahead were the few start-ups that were designed around totally new business models, such as Amazon, eBay, and Google.

Walmart should have dominated online retail, yet Amazon emerged and practically wrote the bible for e-commerce, including consumer reviews, shopping carts, and free shipping. Newspapers and phone book companies should have been able to transfer their information businesses to the online world, but Yahoo! and then Google stepped up to the plate. They built the search engines that indexed the world’s information, and Google developed the business model that made it worth more than all traditional media companies combined.

In contrast, and much to their misfortune, start-ups that relied purely on technology innovation without any real business model innovation largely went bust. Companies like eToys that tried to “Amazon” various markets, but without Amazon’s front- and back-office innovations, crashed and burned once the financial markets began to demand profits rather than just expensive revenue growth. Even Netscape, whose Netscape Navigator mainstreamed Web browsing, and whose IPO kicked off the dot-com boom, was forced to sell itself off to AOL. Netscape engineers invented JavaScript, SSL, and all kinds of cool technology for the Internet that are still used today, but Netscape accepted the status quo when it came to using tried-and-true business models rather than developing new ones that were enabled by its own technology innovation. Unfortunately for Netscape, its competitor Microsoft already understood those business models all too well and knew exactly how to use its economic might and resources to pull their levers. In the first “browser war,” Microsoft preinstalled its Internet Explorer on all new Windows computers, then gave away its Web server software, Internet Information Server (IIS), which effectively destroyed Netscape’s business model.

Could Netscape have succeeded with a different strategy? We believe so. Consider that one of the ways that Netscape monetized its Navigator browser was to sell the sponsorship of its Net Search button to the Excite search engine for $5 million. Netscape believed that the browser itself was the key, while search was simply a sideline. It was left to two pairs of Stanford graduate students, Jerry Yang and David Filo (Yahoo!) and Larry Page and Sergey Brin (Google), to prove that search was a much bigger business. Google’s innovative model of selling text ads next to search results via an automated marketplace allowed it to build a franchise so dominant that it later withstood a series of frontal assaults by Microsoft, including a marketing program in which Microsoft essentially paid people to use its Bing search engine.

The same story has been repeated in multiple waves since. Facebook and LinkedIn dominate social networks even though AOL, Microsoft (Hotmail), and Yahoo! (Yahoo! Mail) controlled most consumer online identities when those social networks first emerged. Alibaba beat eBay in China. Uber outflanked the taxi companies. Airbnb has more room listings than any hotel company in the world.

These success stories are technology companies, sure. But as we’ve seen, technological innovation alone is insufficient—even when its impact on the future is huge. Services like Craigslist, Wikipedia, and IMDb (the Internet Movie Database) were early, influential Internet innovators, but they still never became massively (financially) valuable on their own.

The real value creation comes when innovative technology enables innovative products and services with innovative business models. Even though the business models of Google, Alibaba, and Facebook might seem obvious—even inevitable—after the fact, they weren’t widely appreciated at the time they launched. How many people in 1999 would have realized that running tiny text ads next to the equivalent of an electronic card catalog would lead to the world’s most valuable software company? Or that setting up an online shopping mall for China’s emerging middle class would lead to a $100 billion business? Which of you in 2004 would have predicted that letting people see what their friends are talking about by staring at a tiny screen on a handheld computer would become the dominant form of media? Great companies and great businesses often seem to be bad ideas when they first appear because business model innovations—by their very definition—can’t point to a proven business model to demonstrate why they’ll work.

To really understand why these business models succeed, we need to clearly define what we mean by “business model” in the first place. Part of the problem is that the term can be interpreted in so many different ways. The great management thinker Peter Drucker wrote that business models are essentially theories composed of assumptions about the business, which circumstances might require to change over time. Harvard Business School professor and author Clay Christensen believes that you need to focus on the concept of the “job-to-be-done”; that is, when a customer buys a product, she is “hiring” it to do a particular job. Then there’s Brian Chesky of Airbnb, who said simply, “Build a product people love. Hire amazing people. What else is there to do? Everything else is fake work.”

As Andrea Ovans aptly put it in her January 2015 *Harvard Business Review* article, “What Is a Business Model?”, it’s enough to make your head swim! For the purposes of this book, we’ll focus on the basic definition: a company’s business model describes how it generates financial returns by producing, selling, and supporting its products.

What sets companies like Amazon, Google, and Facebook apart, even from other successful high-tech companies, is that they have consistently been able to design and execute business models with characteristics that allow them to quickly achieve massive scale and sustainable competitive advantage. Of course, there isn’t a single perfect business model that works for every company, and trying to find one is a waste of time. But most great business models have certain characteristics in common. If you want to find *your* best business model, you should try to design one that maximizes four key growth factors and minimizes two key growth limiters.

# DESIGNING TO MAXIMIZE GROWTH: THE FOUR GROWTH FACTORS

## *GROWTH FACTOR #1: MARKET SIZE*

The most basic growth factor to consider for your business model is market size. This focus on market size may sound obvious, and it’s right out of Pitch Deck 101 for start-ups, but if you want to build a massive company, you need to begin with the basics and eliminate ideas that serve too small of a market.

A big market has both a large number of potential customers and a variety of efficient channels for reaching those customers. That last point is important; a market consisting of “everyone in the world” might seem large, but it isn’t reachable in any efficient way. We’ll discuss this in greater depth when we look at distribution as a key growth factor.

It’s not easy to judge the size of a market, or what pitch decks and venture capitalists often refer to as TAM (total available market). Predicting TAM and how it will grow in the future is one of the main sources of uncertainty in blitzscaling. But predicting it correctly and investing accordingly when others are still paralyzed by fear is also one of the main opportunities for unexpectedly high returns, as we’ll see in the cases of Airbnb and Uber.

Ideally, the market itself is also growing quickly, which can make a smaller market attractive and a large market irresistible.

In Silicon Valley, the competition for venture capital exerts a strong pressure on entrepreneurs to focus on ideas that are going after big markets. Venture capital firms might raise hundreds of millions or even billions of dollars from their investors—limited partners like pension funds and university endowments—who are seeking above-market returns to compensate them for taking a chance on privately held companies rather than simply investing in the Coca-Colas of the world. To deliver these above-market returns, venture capital funds need to *at least* triple their investors’ money. A $100 million venture capital fund would need to return $300 million over the typical seven- to ten-year life of a fund to achieve an above-market internal rate of return of 15 to 22 percent. A $1 billion fund would need to return $3 billion. Since most venture capital investments either lose money or barely break even, the only realistic way that venture capitalists can achieve these aggressive goals is to rely on a small number of incredibly successful investments. For example, Benchmark Capital invested $6.7 million in eBay in 1997. Less than two years later, eBay went public, and Benchmark’s stake was worth $5 billion, which is a 745 times return. The specific fund that made that investment, Benchmark Capital Partners I, took $85 million from investors and returned $7.8 billion, for a 92 times return. (The initial investors in Facebook did even better, but were individuals rather than firms.)

Given the desire for home runs like eBay, most venture capitalists filter investment opportunities based on market size. If a company can’t achieve “venture scale” (generally, a market of at least $1 billion in annual sales), then most VCs won’t invest, even if it is a good business. It simply isn’t large enough to help them achieve their goal of returning more than three times their investors’ money.

When Brian Chesky was pitching venture capitalists to invest in Airbnb, one of the people he consulted was the entrepreneur and investor Sam Altman, who later became the president of the Y Combinator start-up accelerator. Altman saw Chesky’s pitch deck and told him it was perfect, except that he needed to change the market-size slide from a modest $30 million to $30 billion. “Investors want B’s, baby,” Altman told Chesky. Of course, Altman wasn’t telling Chesky to lie; rather, he argued that if the Airbnb team truly believed in their own assumptions, $30 million was a gross underestimate, and they should use a number that was true to their convictions. As it turns out, Airbnb’s market was indeed closer to $30 billion.

When evaluating market size, it’s also critical to try to account for how lower costs and product improvements can expand markets by appealing to new customers, in addition to seizing market share from existing players. In 2014, Aswath Damodaran, a professor of finance at NYU’s Stern School of Business, estimated that Uber was probably worth roughly $6 billion, based on its ability to ultimately win 10 percent of the global taxi market of $100 billion, or $10 billion. According to Uber’s own projections, in 2016 the company processed over $26 billion in payments. It’s safe to say that the $10 billion market was a serious underestimate, as the ease of use and lower cost of Uber and its competitors expanded the market for transportation-as-a-service.

As Aaron Levie, the founder of the online file storage company Box noted in a tweet in 2014, “Sizing the market for a disruptor based on an incumbent’s market is like sizing a car industry off how many horses there were in 1910.”

The other factor that can lead to underestimating a market is neglecting to account for expanding into additional markets. Amazon began as Amazon Books, the “Earth’s Biggest Bookstore.” But Jeff Bezos always intended for bookselling to serve as a beachhead from which Amazon could expand outward to encompass his massive vision of “the everything store.” Today, Amazon dominates the bookselling industry, but thanks to relentless market expansion, book sales represent less than 7 percent of Amazon’s total sales.

The same effect can be seen in the financial results of Apple. In the first quarter of 2017, Apple generated $7.2 billion from the sale of personal computers, a category the company pioneered and once dominated. That’s a great number to be sure, but, over that same financial quarter, Apple’s total revenue was a whopping $78.4 billion, which meant that Apple’s original market accounted for less than 10 percent of its total sales.

My Greylock colleague Jerry Chen, who helped Diane Greene scale VMware’s virtualization software into a massive business, likes to point out, “Every billion-dollar business started as a ten-million-dollar business.”

But whether you are creating a new market, expanding an existing market, or relying on adjacent markets to get to those “B’s” that investors want (baby), you need to have a plausible path to get from here to there. This leads us to one of my favorite growth factors to discuss with entrepreneurs: distribution.

## *GROWTH FACTOR #2: DISTRIBUTION*

The second growth factor needed for a strong, scalable business is distribution. Many people in Silicon Valley like to focus on building products that are, in the famous words of the late Steve Jobs, “insanely great.” Great products are certainly a positive—we’ll discuss the lack of product quality as a growth *limiter* later on—but the cold and unromantic fact is that a good product with great distribution will almost always beat a great product with poor distribution.

Dropbox is a company with a great product, but it succeeded because of its great distribution. In an interview for Reid’s *Masters of Scale* podcast, founder and CEO Drew Houston said that he believes that too many start-ups overlook the importance of distribution:

> Most of the orthodoxy in Silicon Valley is about building a good product. I think that’s because most companies in the Valley don’t survive beyond the building-the-product phase. You have to be good at building a product, then you have to be just as good at getting users, then you have to be just as good at building a business model. If you’re missing any of the links in the chain, the whole chain is broken.

The challenge of distribution has become even greater in the “mobile first” era. Unlike the Web, where search engine optimization and e-mail links were broadly applicable and successful distribution channels, mobile app stores offer little opportunity for serendipitous product discovery. When you go to Apple’s or Google’s app store, you’re searching for a specific product. Few people install apps just for the hell of it. As a result, the business model innovators who have succeeded (e.g., Instagram, WhatsApp, Snap) have had to find creative ways to get broad distribution for their product—without spending a lot of money. These distribution techniques fall into two general categories: leveraging existing networks and virality.

### *A) Leveraging Existing Networks*

New companies rarely have the reach or resources to simply pour money into advertising campaigns. Instead, they have to find creative ways to tap into existing networks to distribute their products.

When I was at PayPal, one of the major vehicles for distribution of our payment service was settling purchases on eBay. At the time, eBay was already one of the largest players in e-commerce, and by the beginning of 2000 already had ten million registered users. We tapped into this user base by building software that made it extremely easy for eBay sellers to automatically add a “Pay with PayPal” button to all of their eBay listings. The amazing thing is that customers did so even though eBay had its own rival payments service, Billpoint! But sellers were required to add Billpoint manually to each of their listings; PayPal did it for them.

Many years later, Airbnb was able to perform a similar feat by leveraging the online classified service Craigslist. Based on a suggestion from Y Combinator’s Michael Seibel, Airbnb built a system that allowed and encouraged its hosts to cross-post their listings to the much-larger Craigslist. Hosts were told, “Reposting your listing from Airbnb to Craigslist increases your earnings by $500 a month on average,” and were allowed to do so by clicking a single button. This took serious technology skills—unlike many platforms, Craigslist doesn’t have an application programming interface (API) that allows other software to interact with it—but it was technology innovation for the purposes of distribution innovation, not product innovation. “It was a kind of a novel approach,” Airbnb founder Nathan Blecharczyk said of the integration. “No other site had that slick an integration. It was quite successful for us.”

Leveraging an existing network can have downsides, of course. What the existing network gives (or unknowingly allows to be taken), the existing network can also take away. Zynga, the leading social games company, achieved great success leveraging Facebook for distribution, but had to dramatically reengineer its distribution model after Facebook decided to stop allowing people playing Zynga games to post their progress to their Facebook friends. (Disclosure: I am a member of Zynga’s board of directors.) Zynga founder Mark Pincus was farsighted enough to build a strong enough franchise to survive the change.

In contrast, so-called content farms like Demand Media that leveraged Google’s search platform to generate website traffic and advertising revenues never recovered after Google tuned its algorithms to deprioritize content from what it called “junk” websites.

Despite these dangers, leveraging existing networks can be a critical part of a business model, especially if these networks can provide a “booster rocket” that is later supplemented with virality or network effects.

### *B) Virality*

“Viral” distribution occurs when the users of a product bring more users, and those users bring additional users, and so on, much like an infectious virus spreads from host to host. Virality can either be organic—occurring during the course of normal usage of the product—or incentivized by some kind of reward.

After launching LinkedIn, the team and I devoted significant time and energy to figuring out how to improve organic virality; that is, how to make it easier for existing users to invite friends to use the service. One way we did this was to refine what have become some of the standard tools of virality, such as address book importers. For example, we built software that allowed LinkedIn to connect to our users’ Outlook contacts, which made it very easy for them to invite their most important connections.

But equally important was an unanticipated source of virality. As it turned out, users wanted to use their LinkedIn pages as their primary professional identity on the Internet. Having a page like this to point others to—with all the details of their professional life together in one place—generated value not only for the user, but for the people viewing the page, and it made viewers realize that they should get their own LinkedIn profile. As a result, we added public profiles as a systematic tool to boost both the member value proposition and our viral growth rate.

At PayPal, we combined organic and incentivized virality. The payment product was inherently viral; if someone e-mailed you money using PayPal, you had to set up an account to get paid. But we enhanced this organic virality with monetary incentives. If you referred a friend to PayPal, you got $10, and your friend got $10. This combination of organic and incentivized virality allowed PayPal to grow 7 to 10 percent per day. As the PayPal network grew, we reduced the incentives to $5 and $5, then finally eliminated them altogether.

Incentives don’t have to be monetary; like PayPal, Dropbox used a similar combination of organic virality (as users share files with nonusers) and incentivized virality (Basic account holders get 500 MB of extra storage per user they refer; Pro account holders get 1 GB) to grow. Even though Dropbox invested in partnerships with leading PC makers like Dell, Drew Houston credits virality with driving the company’s rapid growth, helping it double its one hundred thousand users at launch to two hundred thousand users just ten days later, then skyrocket to one million users just seven months after that\*.\*

If your distribution strategy focuses on virality, you also have to focus on retention. Bringing new users in through the front door doesn’t help you grow if they immediately turn around and leave. According to Houston, Dropbox discovered this truth the hard way, when activation rates revealed that only 40 percent of the people signing up were actually putting files in their Dropbox and linking them to their computers. In an interview for my *Masters of Scale* podcast, Drew described a scene reminiscent of the television show *Silicon Valley* (but with a happier ending):

> What we did is we went on Craigslist and offered $40 to anyone who’d come in for half an hour—a poor man’s usability test. We’re like, “All right, sit down. This is an invitation to Dropbox in your e-mail. Go from here to sharing a file with this e-mail address.” Zero of the five people we tested succeeded. Zero of the five even came close. This was just stunning. We’re like, “Oh my God, this is the worst product ever created.” So we made a list of like eighty things in this Excel spreadsheet, then just sanded down all these rough edges in the experience, and watched our activation rate climb.

Virality almost always requires a product that is either free or freemium (i.e., free up to a certain point, after which the user has to pay to upgrade—Dropbox, for example, offers 2 GB of free storage). We can’t recall a single instance of a company that grew to a massive scale by leveraging the virality of a paid product.

One of the most powerful distribution innovations is to combine both strategies. Facebook was able to do this by harnessing the organic virality of a social network (where users invite other users to join them) and leveraging existing networks centered around campuses by rolling out the product on a college-by-college basis. We’ll discuss Facebook’s rollout strategy in greater depth when we consider network effects.

## *GROWTH FACTOR #3: HIGH GROSS MARGINS*

One of the key growth factors that entrepreneurs often overlook is the power of high gross margins. Gross margins, which represent sales minus the cost of goods sold, are probably the best measure of long-term unit economics. The higher the gross margin, the more valuable each dollar of sales is to the company because it means that for each dollar of sales, the company has more cash available to fund growth and expansion. Many high-tech businesses have high gross margins by default, which is why this factor is often overlooked. Software businesses have high gross margins because the cost of duplicating software is essentially zero. Software-as-a-service (SaaS) businesses have a slightly higher cost of goods sold because they need to operate a service, but thanks to cloud providers like Amazon, this cost is becoming smaller all the time.

In contrast, “old economy” businesses often have low gross margins. Growing wheat is a low-margin business, as is selling goods in a store or serving food in a restaurant. One of the most amazing things about Amazon’s success is that it has been able to build a massive business based on retailing, which is generally a low-margin industry. And even Amazon now relies heavily on its high-margin SaaS business, Amazon Web Services (AWS). In 2016, AWS accounted for 150 percent of Amazon’s operating income, which means that the retail business actually lost money.

Most of the valuable companies we’re focusing on in this book have gross margins of over 60, 70, or even 80 percent. In 2016, Google had a gross income of $54.6 billion on sales of $89.7 billion, for a gross margin of 61 percent. Facebook’s gross income was $23.9 billion on sales of $27.6 billion, for a gross margin of 87 percent. In 2015, LinkedIn’s gross margin was 86 percent. As we’ve already discussed, Amazon is the outlier, with a 2016 gross income of $47.7 billion on $136 billion in sales, for a gross margin of 35 percent. Yet even Amazon’s gross margins are greater than those of a “high margin” traditional company like General Electric, which in 2016 had a gross income of $32.2 billion on sales of $119.7 billion, for a gross margin of 27 percent.

High gross margins are a powerful growth factor because, as noted below, not all revenue is created equal. The key insight here is that even though gross margins matter a great deal to the seller, they are irrelevant to the buyer. How often do you consider the gross margin involved when you make a purchase? Would you ever choose Burger King over McDonald’s because Whoppers are lower margin than Big Macs? Typically, you focus solely on the cost to you, and the perceived benefits of the purchase. This means that it’s not necessarily any easier to sell a low-margin product than a high-margin product. If possible then, a company should design a high-gross-margin business model.

Second, high-gross-margin businesses are attractive to investors, who will often pay a premium for the cash-generating power of such a business. As the prominent investor Bill Gurley wrote in his 2011 blog post, “All Revenue Is Not Created Equal,” “Investors love companies where, all things being equal, higher revenues create higher profit margins. Selling more copies of the same piece of software (with zero incremental costs) is a business that scales nicely.” Appealing to investors makes it easier to raise larger amounts of money at higher valuations when the company is privately held (we’ll delve into the details of why this is so important later on), and lowers the cost of capital when the company is publicly traded. This access to capital is a key factor in being able to finance lightning-fast growth.

It’s important to note the difference between potential gross margin and realized gross margin. Many blitzscalers, such as Amazon or the Chinese hardware makers Huawei and Xiaomi, deliberately price their products to maximize market share rather than gross margins. As Jeff Bezos is fond of saying, “Your margin is my opportunity.” Xiaomi explicitly targets a net margin of 1 to 3 percent, a practice it credits Costco for inspiring. All other factors being equal, investors almost always place a much higher value on companies with higher potential gross margins than companies that have already maximized their realized gross margins.

Finally, most of a company’s operational challenges scale based on revenues or unit sales volume, not gross margin. If you have a million customers who generate $100 million per year in sales, the cost to serve those customers doesn’t change whether your gross margin is 10 percent or 80 percent; you still need to hire enough people to respond to their support requests. But it’s a lot easier to afford good customer support when you have $80 million in gross margin to spend rather than $10 million.

Conversely, it’s a lot easier to sell and service 125,000 customers who generate $12.5 million per year in sales and $10 million in gross margin than it is to have to sell and service a million customers who generate $100 million in sales to achieve that same $10 million in gross margin. That’s eight times as many customers and eight times the revenues, which means eight times as many salespeople, customer service representatives, accountants, and so on.

Designing a high-gross-margin business model makes your chances of success greater *and* the rewards of success even greater. As we’ll see in a later section, high gross margins have helped even nontech businesses, such as the Spanish clothing retailer Zara, grow into global giants.

## *GROWTH FACTOR #4: NETWORK EFFECTS*

Market size, distribution, and gross margins are important factors in growing a company, but the final growth factor plays the key role in *sustaining* that growth long enough to build a massively valuable and lasting franchise. While the past twenty years have driven improvements in the first three growth factors, the rise in Internet usage around the world has pushed network effects to levels never before seen in our economy.

The increasing importance of network effects is one of the main reasons that technology has become a more dominant part of the economy.

At the end of 1996, the five most valuable companies in the world were General Electric, Royal Dutch Shell, the Coca-Cola Company, NTT (Nippon Telegraph and Telephone), and ExxonMobil—traditional industrial and consumer companies that relied on massive economies of scale and decades of branding to drive their value. Just twenty-one years later, in the fourth quarter of 2017, the list looked very different: Apple, Google, Microsoft, Amazon, and Facebook. That’s a remarkable shift. Indeed, while Apple and Microsoft were already prominent companies at the end of 1996, Amazon was still a privately held start-up, Larry Page and Sergey Brin were still a pair of graduate students at Stanford who were two years away from founding Google, and Mark Zuckerberg was still looking forward to his bar mitzvah.

So what happened? The Networked Age happened, that’s what.

Technology now connects all of us in ways that were unthinkable to our ancestors. Over two billion people now carry smartphones (many of them made by Apple, or using Google’s Android operating system) that keep them constantly connected to the global network of everything. At any time, those people can find almost any information in the world (Google), buy almost any product in the world (Amazon/Alibaba), or communicate with almost any other human in the world (Facebook/WhatsApp/Instagram/WeChat).

In this highly connected world, more companies than ever are able to tap into network effects to generate outsize growth and profits.

We’ll use the simple layman’s definition of network effects in this book:

> A product or service is subject to positive network effects when increased usage by any user increases the value of the product or service for other users.

Economists refer to these effects as “demand-side economies of scale” or, more generally, “positive externalities.”

The magic of network effects is that they generate a positive feedback loop that results in superlinear growth and value creation. This superlinear effect makes it very difficult for any node in the network to switch from an incumbent to an alternative (“customer lock-in”), since it is almost impossible for any new entrant to match the value of plugging into the existing network. (Nodes in these networks are typically customers or users, as in the canonical example of the fax machine, or the more recent example of Facebook, but can also be data elements or other fundamental assets valuable in a business.)

The resulting phenomenon of “increasing returns to scale” often results in an ultimate equilibrium in which a single product or company dominates the market and collects the majority of its industry’s profits. So it’s no surprise that smart entrepreneurs strive to create (and smart investors want to invest in) these network effects start-ups.

Several generations of start-ups have tapped these dynamics to build dominant positions, from eBay to Facebook to Airbnb. To accomplish these goals, it’s critical to develop a rigorous understanding of how network effects work. My Greylock colleague Simon Rothman is one of the world’s premier experts on network effects from building eBay’s $14 billion automotive marketplace. Simon warns, “A lot of people try to bolt on network effects by doing things like adding a profile. ‘Marketplaces have profiles,’ they reason, ‘so if I add profiles, I’ll be adding network effects.’ ” Yet the reality of building network effects is a bit more complicated. Rather than simply imitate specific features, the best blitzscalers study the different types of network effects and design them into their business models.

### *Five Categories of Network Effects*

On his industrial organization of information technology website, the NYU professor Arun Sundararajan classifies network effects into five broad categories:

1. **Direct Network Effects:** Increases in usage lead to direct increases in value. (Examples: Facebook, messaging apps like WeChat and WhatsApp)

2. **Indirect Network Effects:** Increases in usage encourage consumption of complementary goods, which increases the value of the original product. (Example: Adoption of an operating system such as Microsoft Windows, iOS, or Android encourages third-party software developers to build applications, increasing the value of the platform.)

3. **Two-Sided Network Effects:** Increases in usage by one set of users increases the value to a different set of complementary users, and vice versa. (Example: Marketplaces such as eBay, Uber, and Airbnb)

4. **Local Network Effects:** Increases in usage by a small subset of users increases the value for a connected user. (Example: Back in the days of metered calls, certain wireless carriers allowed subscribers to specify a limited number of “favorites” whose calls didn’t count against the monthly allotment of call minutes.)

5. **Compatibility and Standards:** The use of one technology product encourages the use of compatible products. (Example: within the Microsoft Office suite, Word’s dominance meant that its document file format became the standard; this has allowed it to destroy competitors like WordPerfect and fend off open-source solutions like OpenDocument.)

Any of these different network effects can have a major impact; Microsoft’s ability to tap into multiple network effects with Windows and Office contributed greatly to its unprecedentedly durable franchise. Even today, Windows and Office remain dominant in the PC market; it’s simply that other platforms like mobile have achieved similar or greater importance.

### *Network Effects Both Produce* and *Require Aggressive Growth*

A key element of leveraging network effects is the aggressive pursuit of network growth and adoption. Because the impact of network effects increases in a superlinear fashion, at lower levels of scale, network effects actually exert downward pressure on user adoption. Once all your friends are on Facebook, you have to be on Facebook too. But conversely, why would you join Facebook if none of your friends had joined yet? The same is true for the first user of marketplaces like eBay and Airbnb.

With network effects businesses, you can’t start small and hope to grow slowly; until your product is widely adopted in a particular market, it offers little value to potential users. Economists would say that the business has to get past the “tipping point” where the demand curve intersects with the supply curve. Companies like Uber subsidize their customers in an attempt to manipulate the demand curve to reach that tipping point faster; the bet is that losing money in the short term may allow you to make money in the long term, once you’re past the tipping point.

One challenge that this approach produces is the (eventual) need to eliminate the subsidies in order to make the unit economics work. When I was at PayPal, one of the things we did to encourage adoption was to proclaim that the service would always be free. This meant eating the transaction costs of accepting credit card payments. I wish I could say we had a grand plan. We had hoped that we could make up for the credit card transaction fee subsidy by making money off the float—the funds being kept in PayPal. Unfortunately, this came nowhere close to offsetting the fee subsidies, and the company was hemorrhaging money. So we switched PayPal from “always free” to “ACH always free” and started charging fees to accept credit card payments. Fortunately, we already had a loyal following, and our customers accepted the change.

When the business can’t change the economics of the product (free services like Facebook can’t lower their prices), it can instead sway the expectations of potential users. The value users place on the service when deciding whether or not to adopt it depends on both the current level of adoption *and* their expectations for future adoption. If they think others are going to jump on board, the perceived value of the service increases, and they become more likely to adopt it.

This technique is reflected in one of the most influential business books of all time, Geoffrey Moore’s *Crossing the Chasm*. Moore argues that technology companies often run into problems when they try to transition from a market of early adopters to the mainstream—the proverbial “chasm.” He recommends that companies focus on niche beachhead markets, from which the company can expand outward using a “bowling pin” strategy in which these markets help to open up adjacent markets. This strategy is even more important for network effects businesses.

A company can also reshape the demand curve by designing the product to be valuable to the individual user regardless of network adoption. At LinkedIn, for example, we discovered that public LinkedIn profiles had some value independent of the user’s network, since they served as an online professional identity. This gave people a reason to join LinkedIn even if their friends and colleagues hadn’t done so yet.

### *Connectivity Enables Network Effects Businesses*

In addition to supporting network effects, the high connectivity of the world we live in today also makes it easier to reach the tipping point where network effects kick in, and to sustain those network effects and the market dominance they produce.

First, the Internet has driven the cost of discovery for products and services lower than ever. Unlike in the past, when companies needed to offer goods in retail stores or broadcast advertising in order to be visible to customers, today buyers can find whatever they’re looking for on Amazon or other online marketplaces like Alibaba, in app stores, or, when all else fails, by Googling. Because products and services that are already popular will almost always come up first in search results, companies with a competitive advantage can quickly grow to the point where the increasing returns of network effects produce a winner-take-most or winner-take-all market. This also explains why the growth factor of distribution is as or more important to company success as the product itself—without distribution, it is difficult to reach the tipping point.

After network effects take hold, the efficiencies enabled by the Networked Age make it easier to sustain the pace of rapid growth. In the past, rapid customer growth inevitably led to rapid organizational growth and to dramatic increases in the overhead required to coordinate a large number of employees and teams. Today’s networks allow companies to sidestep these traditional growth limiters, such as when Apple used Foxconn to get around the potential limitation of its manufacturing infrastructure (more on this in the next section). The more you can remove those limiters, the more dominant a network effects–driven business can grow. This is why companies like Google that have surpassed the $100 billion mark in annual revenues are still growing at over 20 percent per year.

Finally, the remarkable profitability of these companies gives them the financial resources to expand into new fields and invest in the future. The S-curve of innovation argues that the rate of adoption of every innovation eventually slows as the market saturates. However, companies like Apple have mastered the strategy of investing in new products that let them hop onto additional S-curves. Apple hopped from music players to smartphones to tablets, and it is no doubt spending some of its vast profits chasing the next S-curve. The premium that the public markets grant these companies also helps them use mergers and acquisitions (M&A) to jump these curves, much as Facebook did with Instagram, WhatsApp, and Oculus, and Google did with DeepMind.

Of course, network effects don’t apply to every company or market, even if they are superficially similar—as many companies and their investors discovered to their chagrin during the dot-com bust, the Great Recession, and the funding slowdown of 2016. This is why the best entrepreneurs try to design innovative business models that leverage network effects. One of the reasons that Google is Google and Yahoo! is now part of AOL (which in turn is owned by Verizon) is that Google focused on AdWords (a marketplace with strong network effects) while Yahoo! tried to become a media company (a traditional model based on economies of scale).

Much of Silicon Valley’s historical success in building giant companies can be traced to its cultural emphasis on business model innovation, which results in the creation of network effects–driven businesses. The irony is that many people in Silicon Valley couldn’t define a network effect or what caused it if asked. Yet simply because so many entrepreneurs are trying so many different business models, they can end up stumbling into powerful network effects. Craig Newmark simply started e-mailing his friends about local events in 1995; almost twenty-two years later, network effects have kept Craigslist a dominant player in online classifieds despite operating with a skeleton crew and making seemingly no changes to the website design during that entire period!

This is where an emphasis on speed also plays an important role. Because Silicon Valley’s entrepreneurs focus on designing business models that can get big fast, they are more likely to incorporate network effects. And because the fierce local competition forces start-ups to grow so aggressively (i.e., blitzscale), Silicon Valley start-ups are more likely to reach the tipping point of network effects before start-ups from less aggressive geographies.

One of the motivations for this book is to help entrepreneurs from around the world emulate these successes by teaching them how to systematically design their businesses for blitzscaling. When you design your business model to leverage network effects, you can succeed anywhere.

# DESIGNING TO MAXIMIZE GROWTH: THE TWO GROWTH LIMITERS

Building key growth factors into your innovative business model is only half the battle. It is fiendishly difficult to grow an amazing business, in part because it is fiendishly easy to run smack into obstacles that *limit* your growth. A key component of business model innovation is designing around these growth limiters.

## *GROWTH LIMITER #1: LACK OF PRODUCT/MARKET FIT*

Product/market fit enables rapid growth, while the lack of it makes growth expensive and difficult. The concept of product/market fit originates in Marc Andreessen’s seminal blog post “The Only Thing That Matters.” In his essay, Andreessen argues that the most important factor in successful start-ups is the combination of market and product.

His definition couldn’t be simpler: “Product/market fit means being in a good market with a product that can satisfy that market.”

Without product/market fit, it’s impossible to grow a start-up into a successful business. As Andreessen notes,

> You see a surprising number of really well-run start-ups that have all aspects of operations completely buttoned down, HR policies in place, great sales model, thoroughly thought-through marketing plan, great interview processes, outstanding catered food, 30" monitors for all the programmers, top tier VCs on the board—heading straight off a cliff due to not ever finding product/market fit.

Unfortunately, it’s far easier to define product/market fit than it is to establish it!

When you start a new company, the key product/market fit question you need to answer is whether you have discovered a nonobvious market opportunity where you have a unique advantage or approach, and one that competing players won’t see until you’ve had a chance to build a healthy lead. It’s usually difficult to find such an opportunity in a “hot” space; if an opportunity is obvious to everyone, the chance that you’ll be the one who succeeds is exceedingly low.

Most nonobvious opportunities arise from a change in the market that the incumbents aren’t willing or able to adapt to. In many cases, this can be a disruptive technological innovation, but it can also be a change in the law or financial regulations, the rise of a new group of customers, or any other major shift. For example, Charles Schwab was able to build his eponymous financial empire by leveraging the deregulation of brokerage commissions to launch a discount brokerage.

Frequently, you won’t be able to fully validate product/market fit before you commit to building a company. But you should try. As authors and entrepreneurs, we’re huge fans of Eric Ries and his lean start-up methodology. It is an excellent process for systematically tackling risk. But the fact is that most start-ups don’t follow that process; instead, their chosen experiment is “Do we succeed or run out of money?”

The best way for a small, resource-strapped team to assess potential strategies is to leverage what we dubbed “network intelligence” in our previous book, *The Alliance*. Even a small group of founders is likely to have a huge collective personal network of smart people with relevant knowledge or experience. Initiate a conversation, inviting them to challenge your idea and tell you what else you should consider.

Of course, even the best network intelligence won’t guarantee that you’ve actually found product/market fit during this design phase. The only way to truly prove product/market fit is to get the product into the hands of real users. But entrepreneurs can and should do their research, and try to design their business model to maximize their chances of achieving product/market fit as quickly as possible.

## *GROWTH LIMITER #2: OPERATIONAL SCALABILITY*

Designing a scalable economic model isn’t enough if you can’t scale up your operations to meet demand. Too often, entrepreneurs dismiss the challenges of operational scalability by saying, “Managing explosive growth is a high-class problem.” High-class problems are still problems; it may feel better for your ego to be wrestling with the issues of growth rather than simply trying to avoid missing payroll, but both can still kill your company. Rather than dismiss these challenges, the wisest innovators design operational scalability into their models.

### *A) Human Limitations on Operational Scalability*

A significant number of operational issues arise simply because of human limitations. As much as we might wish that we and our colleagues could work tirelessly and seamlessly, regardless of the scale of the organization, the fact is that growth causes us to trip over a wide array of issues.

If you are leading a small founding team with four members, you have to worry about your direct relationship with the three other cofounders, plus their direct relationships with one another. Combinatorial mathematics tells us that this means you need to manage the relationships between six pairs of individuals (\[4\*3\] / 2). Now imagine that you hire two employees, for a total team size of six. Now you need to manage the relationships between fifteen pairs (\[6\*5\] / 2). You increased the team size by 50 percent, but the number of relationships you need to manage went up by 150 percent. The math just gets more daunting from there. And that only considers the relationships of individual pairs of team members, not the relationships between any three members, any four members, and so on.

One approach is to design a business model that requires as few human beings as possible. Some software companies employ business models that allow them to achieve massive success with minimal numbers of employees. The founders of WhatsApp, Jan Koum and Brian Acton, designed a clever business model that addressed some of the key growth factors (their messaging service leveraged both classic network effects and the existing distribution network of telephone address books to grow faster) but also managed to skirt around issues of operational scalability. WhatsApp had a freemium business model; the service was free for a year, after which it cost $1 per year. This low-friction model essentially eliminated the need for people working in functions like sales, marketing, and customer service, allowing WhatsApp to grow to five hundred million monthly active users by the time of its acquisition by Facebook, with a staff of just forty-three employees, a ratio of over ten million active users per employee!

Another approach is to find ways to outsource work to contractors or suppliers. Airbnb’s strategy for photographing its hosts’ rooms offers an instructive example. Early on, Airbnb’s founders discovered that one of the key factors that increased the chances of renting a room on Airbnb was the quality of the photographs of that room. It turns out that most of us aren’t professional photographers, and our poorly composed, poorly shot cell phone pictures don’t do a good job of conveying the awesomeness of our living spaces. So the founders took to the road, visiting hosts and taking photographs for them. Obviously, personally visiting every host was hardly a scalable solution, so the the task was soon outsourced to freelance photographers. As Airbnb grew, the strategy shifted from the founders managing a short list of photographers, to an employee managing a large group of photographers, to an automated system managing a global network of photographers. Founder Brian Chesky describes this strategy succinctly: “Do everything by hand until it’s too painful, then automate it.”

Ultimately, even with clever business models and automation, nearly every massively successful company requires thousands or even tens of thousands of employees. Smart techniques can delay the reckoning, but not forever. Later on, we’ll discuss some of the management innovations that allow companies to handle this kind of organizational growth and scale.

### *B) Infrastructure Limitations on Operational Scalability*

The other main challenge of operational scalability comes from the strain of scaling up the nonhuman infrastructure of the business. It doesn’t matter how much demand you generate if your infrastructure can’t handle it. Infrastructure limitations can even be fatal to a company’s ambitions. Consider the examples of the social networks Friendster and Twitter.

While many have forgotten it now, Friendster was the first (pre-Facebook) online social network to break through into the mainstream (disclosure: I was an early investor in Friendster). Launched in March 2003, Friendster rode viral growth to millions of users within months. Before the year was out, Friendster-mania was such a cultural phenomenon that founder Jonathan Abrams appeared on the late-night television program *Jimmy Kimmel Live!* But Friendster’s massive growth brought massive headaches, especially on the infrastructure side. Despite a talented technology team, Friendster’s servers couldn’t handle the growth, and it became common for Friendster profiles to take up to forty seconds to load. By the beginning of 2005, a faster new entrant, MySpace, was generating more than ten times the number of pageviews as Friendster, which never recovered. MySpace, of course, ultimately lost the consumer social networking war to Facebook, which is a story we’ll discuss in detail later in this book.

Twitter came close to melting down in the same way, but managed to recover in time to build a massive business. When Twitter began its rise in the late 2000s, it became infamous for its “Fail Whale,” a whimsical error message that appeared whenever its servers couldn’t handle the load. Unfortunately for Twitter, the Fail Whale made fairly regular appearances, especially when big news hit, such as the death of the recording artist Michael Jackson in 2009 (to be fair, Twitter was hardly the only website that had these issues when the King of Pop passed away) or the 2010 World Cup. Twitter invested serious resources into rearchitecting both its systems and its engineering processes to be more efficient. Even with this strenuous effort, it took several years to “tame” the Fail Whale; it wasn’t until after Twitter made it through the 2012 US presidential election night without melting down that the company’s then–creative director Doug Bowman announced that the Great Blue Whale had been put to death.

One of the main reasons for the very large increase in the growth of valuable Web companies that we’ve seen in recent years is Amazon’s cloud offering, Amazon Web Services (AWS), which has helped many such businesses navigate around infrastructure limitations. Dropbox, for example, was able to scale up its storage infrastructure much more quickly and easily because it used AWS storage, eliminating the need to build and maintain its own arrays of hard disks.

AWS reflects one of the ways that Amazon has made operational scalability a competitive advantage. Web services like AWS tap into what Harvard Business School professor Carliss Baldwin and former Harvard Business School professor Kim Clark refer to as “the power of modularity.” As Baldwin and Clark describe in their book, *Design Rules, Vol 1: The Power of Modularity,* this principle makes it possible for a company like Amazon and its customers to build complex products out of smaller, standardized subsystems. But the power of modularity goes beyond just software development and engineering. By building easy-to-integrate subsystems like payments and logistics, Amazon makes its entire business more flexible and rapidly adaptable.

The equivalent to AWS on the hardware side is China. Hardware start-ups are able to manage infrastructure limitations and scale much more quickly by tapping into Chinese manufacturing capabilities, either directly or by working with companies like the custom manufacturing design firm PCH. The smart thermostat maker Nest, for example, had only 130 employees when it was acquired by Google for $3 billion, largely because it had outsourced all of its manufacturing to China.

In contrast, Tesla Motors has seen its growth held back by infrastructure limitations. Due to the complexities of its manufacturing process, Tesla’s production rates have lagged behind those of other automakers, the result being that its award-winning vehicles are almost always sold out, with back orders measured in months and even years. Demand generation is not a problem for Tesla; meeting that demand is.

# PROVEN BUSINESS MODEL PATTERNS

Whether by design or not, the business models of rapidly growing companies often follow proven patterns that tap into growth factors and bypass growth limiters. These patterns will be described in more detail below, but here it bears noting that these high-level patterns are principles rather than exact recipes. Simply adopting any of these particular patterns isn’t enough to ensure an innovative business model, but understanding them does provide an entrepreneur with a set of good role models.

It is also worth mentioning that not all patterns are created equal. Some common business models follow proven patterns, but nonetheless don’t seem to produce $100 billion businesses or even $10 billion businesses. Take open-source software, which has been wildly successful as a pattern for spreading software products like Linux. Open source, which means offering free, community-created software that users can modify, arose to prominence during the dot-com era and has been an integral part of the world’s technology stack ever since.

The story of open-source software fits the pattern of business model innovation. Open-source software serves a large market, has powerful distribution via open-source software code repositories, benefits from the network effects of standards and compatibility, and neatly avoids many of the human limitations on operational scalability by tapping into a distributed community of volunteer contributors rather than building a large organization of employees.

Yet even the most successful open-source business, Red Hat, has a market capitalization of “only” about $15 billion, and that’s after being in business for two decades. The empirical evidence suggests that open source is a pattern that is valuable for engagement but not for building a massively profitable business.

In order for a pattern to be proven, it must be able to demonstrate that multiple massively valuable businesses follow it. Based on that criterion, we’ve assembled the following list of proven patterns to help inspire your own business model innovation.

## *PROVEN PATTERN #1: BITS RATHER THAN ATOMS*

Google and Facebook are largely software businesses that focus on electronic bits rather than material atoms. Bits-based businesses have a much easier time serving a global market, which in turn makes it easier to achieve a large market size. Bits are also far easier to move around than atoms, so bits-based businesses can more easily tap into distribution techniques like virality, and their ability to be highly networked provides more opportunities to leverage network effects. Bits-based businesses tend to be high-gross-margin businesses because they have fewer variable costs.

Bits also make it easier to design around growth limiters. You can iterate more quickly on software products (many Internet companies release new software daily) than on physical products, making it faster and cheaper to achieve product/market fit. And bits-based businesses, as we saw with WhatsApp, can get away with far fewer employees than most of their atom-based counterparts.

Back in 1990, the futurist George Gilder demonstrated his prescience when he wrote in his book *Microcosm,* “The central event of the twentieth century is the overthrow of matter. In technology, economics, and the politics of nations, wealth in the form of physical resources is steadily declining in value and significance. The powers of mind are everywhere ascendant over the brute force of things.”

Just over twenty years later, in 2011, the venture capitalist (and Netscape cofounder) Marc Andreessen validated Gilder’s thesis in his *Wall Street Journal* op-ed “Why Software Is Eating the World.” Andreessen pointed out that the world’s largest bookstore (Amazon), video provider (Netflix), recruiter (LinkedIn), and music companies (Apple/Spotify/Pandora) were software companies, and that even “old economy” stalwarts like Walmart and FedEx used software (rather than “things”) to drive their businesses.

Despite—or perhaps because of—the growing dominance of bits, the power of software has also made it easier to scale up atom-based businesses as well. Amazon’s retail business is heavily based in atoms—just think of all those Amazon shipping boxes piled up in your recycling bin! Amazon originally outsourced its logistics to Ingram Book Company, but its heavy investment in inventory management systems and warehouses as it grew turned infrastructure limitations from a growth limiter to a growth factor. On the retail side, merchants pay Amazon to manage their inventories and logistics for them, while the massive computer systems that Amazon built to operate its retail business gave it the capabilities to launch its AWS business (which is a high-margin, bits-based business!).

## *PROVEN PATTERN #2: PLATFORMS*

Platform economics predates the Networked Age, and even the Industrial Age. Trade-oriented principalities like the Republic of Venice provided a welcoming ecosystem for merchants, complete with currency and the rule of law, as well as taxes to harvest the value of the platform. Technology platforms like Microsoft Windows demonstrated the power of being the chosen platform on which businesses were built back when the World Wide Web was still a glimmer in Tim Berners-Lee’s eye (Sir Berners-Lee wrote his proposal for a global hypertext system in 1989). Yet despite the proven value of platforms in the pre-Internet era, the Networked Age has made them vastly more powerful and valuable.

Rather than being limited like the Republic of Venice to a specific geography, today’s software-based platforms can achieve global distribution almost immediately. And since transactions on today’s platforms are conducted through application programming interfaces (APIs) rather than person-to-person negotiations, they proceed swiftly, seamlessly, and in incredible volumes, all with barely any human intervention.

If a platform achieves scale and becomes the de facto standard for its industry, the network effects of compatibility and standards (combined with the ability to rapidly iterate and optimize the platform) create a significant and lasting competitive advantage that can be nearly unassailable. This dominance lets the market leader “tax” all the participants who want to use the platform, much as levies were imposed in the bygone Republic of Venice. For example, the iTunes store takes a 30 percent share of the proceeds whenever a song, a movie, a book, or an app is sold on that platform. These platform revenues tend to have very high gross margins, which generate cash that can be plowed back into making the platform even better. Amazon’s merchant platform, Facebook’s social graph, and, of course, Apple’s iOS ecosystem are great examples of the power of platforms.

## *PROVEN PATTERN #3: FREE OR FREEMIUM*

“Free” has an incredible power that no other pricing does. The Duke behavioral economist Dan Ariely wrote about the power of free in his excellent book *Predictably Irrational,* describing an experiment in which he offered research subjects the choice of a Lindt chocolate truffle for 15 cents or a Hershey’s Kiss for a mere penny. Nearly three-fourths of the subjects chose the premium truffle rather than the humble Kiss. But when Ariely changed the pricing so that the truffle cost 14 cents and the Kiss was free—the same price differential—more than two-thirds of the subjects chose the inferior (but free) Kisses.

The incredible power of free makes it a valuable tool for distribution and virality. It also plays an important role in jump-starting network effects by helping a product achieve the critical mass of users that is required for those effects to kick in. At LinkedIn, we knew that our basic accounts had to be free if we wanted to get to the million users we theorized represented critical mass.

Sometimes you can offer a product for free and still be profitable; in the advertising-driven business model, a large enough mass of free users can be valuable even if they never pay for your service. Facebook, for example, doesn’t charge its users a dime, but it is able to generate large amounts of high-gross-margin revenue by selling targeted advertising. But sometimes a product doesn’t lend itself to the advertising model, as is the case with many services used by students and educators. Without third-party revenue, the problem with offering your product to users for free is that you can’t offset your lack of sales by “making it up in volume.”

Here is where the innovation of freemium comes in. The venture capitalist Fred Wilson coined the term in a 2006 blog post (based on a suggestion from Jarid Lukin), but the business model itself predates the term, having its origin in the “shareware” model for selling software in the 1980s. The free product was a tool for discovery and gaining a critical mass of users, while the paid version of the software allows the business to extract value from those users once its value is clear. Dropbox is one of the premier examples of a successful freemium business—by giving away 2 GB of storage, Dropbox attracted a massive user base, a reasonable percentage of which decides to pay for the value and convenience of additional storage.

## *PROVEN PATTERN #4: MARKETPLACES*

Marketplaces represent one of the most successful business model patterns, with the dot-com era’s Google and eBay and today’s Alibaba and Airbnb standing out as examples of important, valuable companies that follow this pattern. One reason marketplaces are powerful is because they often tap into two-sided network effects. While it is difficult to create a successful marketplace from a cold start, the first marketplace that does manage to achieve liquidity—the ability for buyers and sellers to quickly and efficiently find a counterparty to conduct a transaction—becomes very attractive to both sides of the market. As buyers and sellers pour in, the marketplace becomes even more attractive to both parties, triggering a positive feedback loop that makes it very hard for new entrants to win any market share.

Marketplaces also offer key advantages beyond the obvious network effects. By creating a liquid market where buyers and sellers both participate, the dynamic forces of supply and demand price their transactions better than any human judgment could. The more efficient the prices in a marketplace, the more value it creates, because that means more transactions that *might* create value actually occur. In contrast, in illiquid markets, sellers often misprice their products, resulting in fewer sales and less value creation than optimal.

The best example of the benefits of efficient market pricing is probably Google’s AdWords advertising marketplace. AdWords allows anyone to bid on targeted keywords, in any quantity, so even the smallest businesses can tap into global distribution. Contrast this to the traditional advertising market, in which large clients spend millions of dollars paying advertising agencies to run expensive thirty-second television ads during coveted programming like the Super Bowl broadcast. Google’s system also measures advertising quality; ads targeted at its audience to generate the most paid click-throughs are favored. The net effect is that consumers are shown the most effectively targeted ads, without the overhead of a middleman like Don Draper and his three-martini lunch. Google also increases its own gross margin, because, unlike commercials during a television broadcast, search-based ad space is virtually unlimited and costs Google next to nothing.

Although marketplaces, even local ones, have always been a powerful business model, the changes ushered in by the Networked Age have made them potentially more valuable than ever. But unlike a local market with its size constraints—think of an old-fashioned bazaar in the center of a populous city—online marketplaces tap a global market. And by connecting buyers and sellers instead of holding inventory or managing logistics (and thus dealing in bits rather than atoms), online marketplaces avoid many of the growth limits of human or infrastructure scalability.

## *PROVEN PATTERN #5: SUBSCRIPTIONS*

When Salesforce.com first launched its on-demand customer relationship management product, there were many legitimate questions about this new software-as-a-service (SaaS) model. Selling software as a subscription, delivered via the Internet, represented a major departure for enterprise software vendors. The previous model of selling permanent licenses for on-premise software and charging for maintenance provided more cash up front than monthly or annual subscriptions. The personnel required to support the model were also different; selling and supporting on-premise software required field salespeople and sales engineers to install pilot deployments, while the new SaaS model required additional staff to provide 24/7 data center coverage and support.

As it turns out, of course, SaaS eventually became the dominant business model for enterprise software. The cash flow disadvantages and required personnel shifts were real concerns, but mainly for existing players in the market. New SaaS businesses like Salesforce.com and Workday were designed and built around the new model, giving them a major advantage over existing players who tried to convert their on-premise software businesses to subscription ones.

Subscription Internet services have been successful because the sales and delivery model provides a larger market size and better distribution than traditional packaged software. Due to the cost and overhead of the extensive field operations required to support on-premise software, traditional enterprise software licenses had to be in the six- or seven-figure range simply to make the model work. This meant that software vendors focused on the needs of only the largest customers.

In contrast, Salesforce.com and other SaaS vendors can sell software licenses in any quantity, not only to Fortune 500 companies, but also to midmarket and small to medium-sized businesses, significantly enlarging their potential market. Internet delivery and self-service allow new forms of distribution that weren’t possible in the packaged software world, such as Dropbox’s viral incentive of additional free storage for referring new customers.

Nor is the pattern of Internet subscriptions limited to enterprise software. The dominant players in both music (Spotify, Pandora) and video (Netflix, Hulu, Amazon) also enjoy lower overhead and greater distribution by using the subscription business model.

Another, less obvious benefit to this model is that once a subscription business achieves scale, the predictability of its revenue streams allows it to be more aggressive with long-term investments, since it isn’t obliged to maintain large cash balances to weather short-term variations in the business. This financial firepower can represent a major competitive advantage. For example, Netflix, which announced plans to invest $6 billion in original content for its streaming service in 2017, has exploited its direct subscription model to outspend classic television networks, which have to rely on less robust revenue streams like payments from cable providers and advertising sales.

## *PROVEN PATTERN #6: DIGITAL GOODS*

One of the emerging patterns that build on new platforms and services is the business of selling digital goods. Sitting at the intersection of “bits rather than atoms” and platforms, digital goods are intangible products that, arguably, have no intrinsic value—but they can still make for a profitable and scalable business. For example, the messaging service LINE derives significant revenues by selling “stickers”: images that are incorporated into the text of smartphone messages. In 2014, its first year of operation, LINE’s sticker business generated $75 million in revenue. That figure grew to $270 million in 2015, which represented over a quarter of LINE’s total revenues. Not bad for an intangible product with no intrinsic value!

Digital goods have also become a key business model in the video game industry, with in-game purchases of digital items that can help players advance in the game or advertise their status. Market-wide revenue from in-app purchases are projected to outstrip paid-app downloads in 2017, $37 billion to $29 billion.

In addition to enjoying the advantages of any bits-based business, digital goods tend to have nearly 100 percent gross margins, since they are purely digital and usually do not add significantly to infrastructure or overhead costs.

## *PROVEN PATTERN #7: FEEDS*

One of the most underrated and underappreciated proven patterns is the news feed. Facebook’s powerful network effects allow the site to attract its users, but its innovation of the news feed has made it a world-class business. Yet Facebook is hardly the only feed-centric success story. Companies like Twitter, Instagram, and Slack have all built multibillion-dollar market values around the news feed pattern.

The power of the news feed comes from its ability to drive user engagement, which in turn drives both advertising revenue and long-term retention. As Facebook has demonstrated, a news feed with sponsored updates is the most effective way to monetize proverbial Internet “eyeballs.” Facebook’s News Feed’s dominance of the online advertising market is only exceeded by Google’s AdWords, and AdWords starts with the significant built-in advantage of capturing active consumer intent rather than simply the desire to be amused. For example, how many people visit Facebook with the intention of going shopping? The magic of the news feed model has been its ability to monetize bored people catching up on what their friends are doing.

Of course, effective use of the news feed model requires a lot of sophisticated technology. Facebook doesn’t just insert sponsored updates at random. The company knows your interests better than you do, based on all the items you’ve ever clicked on, liked, or otherwise engaged with. It can carefully target the advertisements it shows you based on your individual habits and the context of what surrounds them in your feed. This targeting ability explains why Facebook succeeded in monetizing this model when other feed-based products like RSS readers failed.

This pattern is so powerful that Twitter, whose product is essentially one long news feed, is still an important Internet company despite barely changing its product in nearly a decade (going from 140 characters to 280 characters doesn’t count). Twitter is a business that scaled massively because of the power of business model innovation, not product or technology innovation.

# THE UNDERLYING PRINCIPLES OF BUSINESS MODEL INNOVATION

Underlying the proven patterns of business model innovation are larger principles that can help refine those patterns or even create new ones. These principles aren’t themselves business models, but they often power the technological innovation that enables business model innovation.

## *UNDERLYING PRINCIPLE #1: MOORE’S LAW*

Moore’s Law is the fundamental principle that puts the “Silicon” in Silicon Valley, and has powered the worldwide ascent of the technology industry. Moore’s Law is named after its codifier, Intel cofounder Gordon Moore, who coined the term in a paper he wrote in 1965, observing that the number of transistors that could be crammed onto the surface of a silicon chip appeared to double each year. While Moore revised his eponymous law in 1975 to a doubling of transistors every twenty-four months, the industry has since settled on a broad consensus of eighteen months. Today, Moore’s Law no longer refers specifically to transistor density; rather, it predicts that computing power tends to double every eighteen months. In recent years, this growth in computing power has been driven by the transition to multicore, multithreaded computing. Perhaps in the future, Moore’s Law will be met by quantum computing, optical chips, the use of DNA, or something even more impossible to foresee. The point is, it appears that the true limit to Moore’s Law is human engineering ingenuity, not solid-state physics.

Moore’s Law matters because the relentless increase in computing power that it predicts acts as a constant source of technological innovation, which, as we have seen, can help enable business model innovation. For many years, the power of Intel’s central processing units (CPUs) was measured by their “clock rate”—the number of times per second that the CPU could perform an operation. While clock rate is no longer a good measure of computing power, it is still a good metaphor for how Moore’s Law drives the world of computer technology: each tick of the clock enables new technologies, driving faster and faster innovations.

Increasing computing power allowed the shift from gigantic mainframes to smaller minicomputers to personal computers, all the way to today’s smartphones and wearables. We’ve seen similar increases in things like network bandwidth, allowing the Web to shift from text to images to audio to video, and in the future, 3-D and virtual reality (VR). Yet today’s smartphones aren’t simply smaller versions of IBM mainframes—remember, technology innovation enables business model innovation.

The best entrepreneurs don’t just follow Moore’s Law; they anticipate it. Consider Reed Hastings, the cofounder and CEO of Netflix. When he started Netflix, his long-term vision was to provide television on demand, delivered via the Internet. But back in 1997, the technology simply wasn’t ready for his vision—remember, this was during the era of dial-up Internet access. One hour of high-definition video requires transmitting 40 GB of compressed data (over 400 GB without compression). A standard 28.8K modem from that era would have taken over four months to transmit a single episode of *Stranger Things*. However, there was a technological innovation that would allow Netflix to get partway to Hastings’s ultimate vision—the DVD.

Hastings realized that movie DVDs, then selling for around $20, were both compact and durable. This made them perfect for running a movie-rental-by-mail business. Hastings has said that he got the idea from a computer science class in which one of the assignments was to calculate the bandwidth of a station wagon full of backup tapes driving across the country! This was truly a case of technological innovation enabling business model innovation. Blockbuster Video had built a successful business around buying VHS tapes for around $100 and renting them out from physical stores, but the bulky, expensive, fragile tapes would never have supported a rental-by-mail business.

(As hard as it may be for some readers to comprehend, when we were in college, we would often drive to a Blockbuster Video store on a Friday or Saturday night, pay a couple of bucks to rent a VHS tape of a movie, and use a landline telephone to call Domino’s to order a pizza before popping the videotape into a VCR that was connected to a twenty-five-inch standard-definition cathode-ray tube.)

DVD technology allowed Netflix to create a completely new business model. Rather than renting out individual movies and being charged exorbitant late fees if they failed to return the VHS tape in time, Netflix customers paid $20 per month for a subscription to “unlimited” movies—provided they checked out just one movie at a time. This allowed Netflix to eliminate Blockbuster’s widely loathed late fees and capture the powerful and certain revenue stream from the proven model of a subscription service. Netflix took off, and even went public as a DVD-by-mail service.

But Hastings never lost sight of his ultimate vision for Netflix—on-demand television delivered via the Internet. And as Moore’s Law continued to work its magic, making computers ever more powerful and Internet bandwidth ever greater and cheaper, Netflix bided its time, waiting for streaming video to become viable.

“When we first started raising money in 1997, we thought we’d be mostly streaming in 5 years,” Hastings told us when he visited our Blitzscaling class at Stanford. “In 2002, we had no streaming. So we thought that by 2007, it would be half our business. In 2007, we were still nowhere. So we made the same prediction. And this time we were wrong the other way—by 2012, streaming was 60% of our business.” It may have taken longer than Hastings expected, but Moore’s Law eventually came through for him.

Today, Netflix is synonymous with television on demand delivered via the Internet, and it has created an entirely new category of “binge watching.” As of 2017, 53 percent of American adults say that their household has access to Netflix, and the service is growing rapidly across the rest of the world. Netflix has used the financial power of its subscription model to become one of the premier sources of original video content, from television shows like *Stranger Things,* to movies like *Beasts of No Nation,* to events like comedian Dave Chappelle’s comeback stand-up comedy specials.

Traditional television commissions large numbers of pilot episodes, the majority of which never make it to series, trying to produce optimistically named “Must See TV” to appeal to a broad audience, which has to be convinced to tune in every single week. In contrast, the on-demand model allows Netflix to cater to many different audiences rather than program a small number of thematic channels, as cable television does. Broadcast television succeeded by providing the same thing to all its viewers—a model driven by the technological innovation of broadcasting content via wireless signals and later coaxial cable. Netflix succeeds by providing a carefully personalized experience to each of its many viewers, giving it a huge advantage over its traditional television competitors. Moreover, Netflix produces exactly what it knows its customers want based on their past viewing habits, eliminating the waste of all those pilots, and only loses customers when they make a proactive decision to cancel their subscription. The more a person uses Netflix, the better Netflix gets at providing exactly what that person wants. And increasingly, what people want is the original content that is exclusive to Netflix. The legendary screenwriter William Goldman famously wrote of Hollywood, “Nobody knows anything.” To which Reed Hastings replies, “Netflix does.” And all this came about because Hastings had the insight and persistence to wait nearly a decade for Moore’s Law to turn his long-term vision from an impossible pipe dream into one of the most successful media companies in history.

Moore’s Law has worked its magic many other times, enabling new technologies ranging from computer animation (Pixar) to online file storage (Dropbox) to smartphones (Apple). Each of those technologies followed the same path from pipe dream to world-conquering reality, all driven by Gordon Moore’s 1965 insight.

## *UNDERLYING PRINCIPLE #2: AUTOMATION*

Blitzscaling companies use automation. If they have the ability to perform a task (which is a big if), computers are almost always faster, cheaper, and more reliable than human beings. Furthermore, computers continue to get faster and cheaper, doubling in power every eighteen months according to Moore’s Law, as opposed to human beings, who evolve over the course of millions of years according to Darwin’s principle of natural selection.

In 2014, the journalist Jan Vermeulen compared the original Apple II (introduced in 1977) with the then state-of-the-art iPhone 5S. He found that in the intervening thirty-seven years, Apple’s products had become 2,600 times faster in terms of clock speed (from a 1 MHz single-core CPU to a 1.3 GHz dual-core CPU) and had 16,384 times the amount of RAM. That’s three to four orders of magnitude of improvement in the span of a single human generation. And that massive delta doesn’t even take into account that the Apple II was a desktop computer with a bulky cathode-ray tube monitor, and the iPhone 5S was a portable supercomputer that people carried in their pockets.

The same year that the Apple II was introduced, Joe Bottom set a world record by swimming the 50-meter freestyle in 23.74 seconds, for a brisk pace of just under 7.6 km/h (4.7 mph). If human swimming speed had increased as quickly as the computing speed in Apple’s products, the world record in 2014 would have been 19,700 km/h (12,250 mph)—not quite enough to achieve orbital velocity, but about twenty-five times the speed of the average commercial jetliner. The actual human world record for the 50-meter freestyle in 2014 was 20.91 seconds, for a more modest 11 percent improvement.

That’s the power that automation taps into.

The power of automation applies not just to direct-to-consumer products like the iPhone but also to internal processes and capabilities. Think of the value that automation creates by increasing the productivity in Amazon’s warehouses, or by making it easier to keep Google’s server farms running 24/7.

## *UNDERLYING PRINCIPLE #3: ADAPTATION, NOT OPTIMIZATION*

At a higher level of abstraction, successful scale-ups place more emphasis on adaptation than optimization. Rather than the giant assembly lines of Detroit automakers, which trace their origins to Henry Ford’s Model T, the current generation of Silicon Valley companies practice continuous improvement, whether through an emphasis on speed or the constant experiments and A/B testing of growth hacking. This emphasis makes sense in an environment where companies need to seek product/market fit for new and rapidly changing products and markets. Consider how Amazon expanded into new markets like AWS rather than simply honing its retail capabilities, or how Facebook has been able to adapt to the shift from a text-based social network accessed via desktop Web browsers to an image- and video-based social network accessed via smartphones (and soon, perhaps, VR).

## *UNDERLYING PRINCIPLE #4: THE CONTRARIAN PRINCIPLE*

My friend Peter Thiel has written eloquently about the power of being a contrarian in his book *Zero to One*.

> Whenever I interview someone for a job, I like to ask this question: “What important truth do very few people agree with you on?”
>
> This question sounds easy because it’s straightforward. Actually, it’s very hard to answer. It’s intellectually difficult because the knowledge that everyone is taught in school is by definition agreed upon. And it’s psychologically difficult because anyone trying to answer must say something she knows to be unpopular. Brilliant thinking is rare, but courage is in even shorter supply than genius.

Being contrarian is often critical to the process of creating a massively valuable technology company. As we’ve discussed, key growth factors like distribution and network effects tend to provide disproportionate rewards to a company that is the first in its space to achieve critical scale. Being contrarian and right gives you a huge advantage because you get a head start on achieving scale.

If your company is pursuing an opportunity that nearly everyone agrees is very attractive, you’re likely to have a difficult time distancing yourself from your army of competitors. But if your company is pursuing an opportunity that conventional wisdom ignores or disdains, you will probably have the time you need to refine your business model innovation into a well-oiled machine. Amazon pursued e-commerce when most people didn’t think consumers would feel comfortable using credit cards online. Google launched its search engine when most people thought search was a mature commodity. And Facebook built its social network when most people believed social networking to be either useless, a market dominated by MySpace, or both.

As we’ve already seen, most great ideas look dumb at first. Being contrarian doesn’t mean that dumb people disagree with you; it means that smart people disagree with you! Remember what happened when Brian Chesky, Joe Gebbia, and Nathan Blecharcyzk tried to pitch Airbnb? Investors like Paul Graham literally couldn’t imagine why people would ever use the service. This doesn’t happen because investors are dumb; most venture capitalists and angel investors are smart, and most smart, successful people would probably agree that investing in proven ideas is better than investing in unproven ones.

The problem is that, by definition, business model innovation involves trying something that is new, and thus unproven!

In this book, we’ve tried to lay out a set of tools, principles, and patterns that you can use to design, invest in, or evaluate an innovative business model. Many venture capitalists like to brag that they are masters of “pattern matching”—but here we must caution not all pattern matching is helpful. The bad kind of pattern matching is what B- and C-grade investors love—the Hollywood high-concept pitch. The movie *Speed* was famous for its high-concept pitch: “*Die Hard* on a bus.” And if you’re the first person to make the connection, you might succeed. *Speed* was in fact a commercial success, mostly because it did in fact live up to its description. But the success of *Speed* led to a raft of derivative and inferior movies, ranging from Steven Seagal’s *Under Siege* (“*Die Hard* on a ship”) to Steven Seagal’s *Executive Decision* (“*Die Hard* on a plane”). When an investor funds “Uber for Pets,” that’s bad pattern matching.

The good kind of pattern matching involves understanding what medical science terms “the mechanism of action.” *Speed* works because confining the action to a bus that has to stay at a certain speed or higher to avoid setting off a bomb creates built-in dramatic tension—especially given the famously bad traffic in Los Angeles. Airbnb works because it has a large market, because travelers spreading awareness from city to city creates virality, and because it follows the proven pattern of an online marketplace.

To help you get a feel for applying our principles of business model innovation, let’s practice by analyzing some of today’s great businesses and how they follow those principles.

# ANALYZING A FEW BILLION-DOLLAR BUSINESS MODELS

## *CASE #1: LINKEDIN*

When we started LinkedIn in 2002, the recent dot-com bust had led most people to consider the consumer Internet industry to be dead. The last thing venture capitalists were willing to do was provide millions of dollars to fund rapid growth. Despite this fact, I thought there was a big opportunity available, and was able to guide LinkedIn through the start-up growth phase until we could raise the capital to really blitzscale.

This is the story of how it happened.

### *Market Size*

The key insight behind LinkedIn was that the Internet was shifting from anonymous cyberspace to an extension of the real world, and thus your online identity was an extension of your real identity. Readers of my generation might remember the famous *New Yorker* cartoon with the caption “On the Internet, nobody knows you’re a dog.” I didn’t think this kind of anonymity would work in a professional context, hence the need for a professional online identity. And though our thesis was contrarian at the time, my cofounders and I were fairly confident that the market of “all white-collar professionals” was sufficiently large to represent a major opportunity.

### *Distribution*

In order to raise money to scale LinkedIn, we had to find a way to prove our distribution strategy. Unfortunately, investors thought of us as “Friendster for business relationships,” which was bad pattern matching and made about as much sense to them as “Tinder for business relationships” would to today’s VCs. Instead, we had to find a way to use the money and reputation I had acquired by helping build PayPal to get LinkedIn to the point where people would invest.

The first step was to assemble a small, super-scrappy team. We got our first office by squatting in the building of a friend’s failing start-up. “Just clean up after yourselves so we can get the lease deposit back, and you can use it for three months,” he told me. I leveraged my reputation to secure a small investment, but I knew we needed to show significant progress in distribution before we could raise our next round. Since we didn’t have the capital to pay for traditional marketing, we implemented a number of techniques similar to what people today call “growth hacking” to get to one million users, which allowed us to raise money from Greylock.

Our core distribution strategy was organic virality, much as it had been at PayPal. Our users would invite their contacts via e-mail because it helped them build their networks and keep track of their key connections. But the initial level of virality simply wasn’t enough. We couldn’t offer PayPal’s kind of financial incentives, so instead we built things like the e-mail address book importer so that we could increase the number of invitations and let our users know when their contacts joined the service.

### *Gross Margins*

Gross margins were important because it became apparent that our user growth was always going to be surpassed by that of the leading consumer social networks. At this point, MySpace had eclipsed Friendster, and Facebook was quickly gaining on MySpace—and all of them had far more users than LinkedIn. Our argument was that our professional users were far more valuable, but to prove that argument we had to demonstrate our ability to earn significant high-margin revenues.

The first business model pattern we tried was a freemium subscription service. The free LinkedIn.com service limited the number of requests a user could send to friends of friends (InMails), and when users hit those limits, they would be offered the chance to upgrade to a premium subscription. This subscription revenue was enough to get us to cash-flow profitability, but it wasn’t growing fast enough to be truly compelling.

The key inflection point came when we discovered that companies were willing to pay for the ability to scan LinkedIn profiles to find the best job candidates. So we offered it to companies as an enterprise subscription product, and once we proved that this new model was a source of significant high-gross-margin revenues, we had the confidence to blitzscale.

### *Network Effects*

The long-term value of LinkedIn was always intended to come from network effects. As a professional social network, LinkedIn leveraged both direct and two-sided network effects, as well as becoming a standard format for presenting one’s professional identity. The direct network effects come from the fact that each additional LinkedIn user makes the network slightly more valuable to all other LinkedIn users. The two-sided network effects occur because more users attract more corporate employers, while more employers increase the value of LinkedIn as a passive job-hunting tool. Finally, by becoming an integral part of most people’s professional online identities, LinkedIn has become a standard that has largely replaced the traditional résumé. Just one of these network effects would probably be enough to create first-scaler advantage; all three working together built a massive strategic moat that protected the LinkedIn business from any new entrants, and even from attempts by consumer networks like Facebook to take away the professional market.

### *Product/Market Fit*

Finding product/market fit for our enterprise product was the key inflection point in the business. How did we do it? We focused on getting market feedback as quickly as possible. We hired a salesperson, gave him some mock-ups of an enterprise product, and sent him to visit potential customers. It turned out that they all wanted to buy it!

### *Operational Scalability*

Blitzscaling LinkedIn presented two major operational scalability challenges, beyond the obvious one of supporting a global social network with hundreds of millions of users. First, to support the business, we actually had to develop, maintain, and update two different products. Without the consumer product, companies wouldn’t see the value of our enterprise product. Without the enterprise product, we couldn’t make enough money to build a great business. We had to do both. It’s hard to find an engineering expert who would recommend fracturing your product and engineering group to work on two largely separate products, but that’s precisely what we did, despite the inefficiency and messiness.

Second, we had to rapidly scale a salesforce while we were still developing the product they were selling. This took a lot of hard work on the part of LinkedIn’s CEOs, Dan Nye and then Jeff Weiner, and their teams. But where we could, we also used technology to help alleviate scaling constraints. Our “Merlin” tool helped make our salespeople more productive (and thus scalable) by automating much of their manual work. Merlin would analyze usage patterns and tell each salesperson which companies to call, how they were already using LinkedIn, and even create a personalized sales deck for each individual prospect!

## *CASE #2: AMAZON*

### *Market Size*

Jeff Bezos’s original vision for Amazon was to take advantage of unlimited digital shelf space to run a store where a customer could buy literally anything. Amazon began with books because this represented a large enough market with a product amenable to e-commerce (durable, fairly standard sizes, readily available through wholesale distributors). Since then, Amazon has steadily expanded from books into many other verticals, and today very nearly lives up to Bezos’s vision of an “everything store” (though you still can’t buy automobiles on Amazon…yet). Retail is a truly gargantuan market and Amazon has captured an almost unthinkable portion of it and even made its market much bigger by launching Amazon Web Services. Now, in addition to being “the everything store,” Amazon also provides much of the Internet’s computing power, bandwidth, and storage (including for other dominant companies like Netflix).

### *Distribution*

Amazon was one of the first companies to fully grasp the possibilities of the Internet as a distribution platform in creating the first successful affiliate program, Amazon Associates, which incentivizes individuals and owners of other websites to refer customers to Amazon in exchange for a share of the revenues generated. This allows Amazon to turn everyone else’s websites and online communications into a powerful distribution channel. Even today, if you see a book title on the Internet, or in a tweet or an e-mail signature, and you follow that link, you’ll probably find yourself on Amazon’s website via an affiliate link.

### *Gross Margins*

Amazon actually scores fairly poorly on this growth factor, though this is largely a function of the industry rather than being specific to Amazon. Retail is a relatively low-margin business, and Amazon’s devotion to offering low prices further hurts margins. Even today, Amazon’s retail business isn’t profitable (though it probably could be if the health of the company required it; for example, Amazon’s core North American operations are profitable—it’s just that its profits are outweighed by the losses generated by Amazon’s efforts in Asia).

Yet even within Amazon’s retail business, we detect signs that these low gross margins are actually part of a long-term strategy that can generate high gross margins, even on retail sales. It’s no secret that Amazon dominates e-commerce; in 2017, analysts like Slice Intelligence reported that Amazon accounted for 44 percent of US e-commerce sales in 2016, and predicted the figure would be even higher in the future. But what is often overlooked is that Amazon’s retail business consists of two very different units. The first is Amazon’s traditional retail operation, in which Amazon buys products from suppliers and sells them to its customers. The second, far less well-known unit is Amazon’s marketplace, which lets third-party sellers sell their products on Amazon. Those third-party sellers store their inventory in Amazon warehouses and pay Amazon to deliver their products to their customers. If you’ve ever shopped on Amazon, you’ve probably bought a product from a third-party seller; Jeff Bezos has said that almost 50 percent of units purchased on Amazon come from them. Because this marketplace business doesn’t require tying up Amazon’s capital in inventory (it ties up the third-party sellers’ capital instead), its gross margins likely resemble high-margin eBay’s more than it does low-margin Walmart’s. As Benchmark’s Matt Cohler notes, “I sometimes wonder if Amazon’s owned-inventory business is just a marketing loss leader and a capital-intensive competitive moat.”

Where Amazon is already tapping into high gross margins is with its AWS business. Remember, 150 percent of its operating margins in 2016 came from AWS, which accounted for $12.2 billion in revenue and over $3 billion in operating income. The high gross margins of AWS allow Amazon to invest heavily in maintaining its lead over its competitors. Indeed, AWS is estimated to hold over 40 percent of the market for cloud computing infrastructure, more than its three biggest rivals—Microsoft, Google, and IBM—put together!

### *Network Effects*

Amazon is relatively weak on network effects. One customer’s use of Amazon doesn’t make it more valuable for another customer, with the possible exception of Amazon’s product reviews. Yet whatever direct network effects exist because of product reviews pales in comparison to the impact of network effects on something like Facebook. Amazon technically is a marketplace with two-sided network effects, thanks to its third-party sellers, but one side is largely missing: Amazon sellers are attracted by Amazon’s massive customer base, but Amazon’s customer base is largely indifferent to those sellers. Amazon does benefit from scale effects, and explicitly uses the “flywheel” framework of author and strategy guru Jim Collins. Brad Stone summarized this approach in his book on Amazon, *The Everything Store*:

> Lower prices led to more customer visits. More customers increased the volume of sales and attracted more commission-paying third-party sellers to the site. That allowed Amazon to get more out of fixed costs like the fulfillment centers and the servers needed to run the website. This greater efficiency then enabled it to lower prices further. Feed any part of this flywheel, they reasoned, and it should accelerate the loop.

Yet as impressive as Amazon’s flywheel is, when compared with the powerful superlinear effect of most network effects, it is merely linear or sublinear. Fortunately, Amazon does benefit from strong network effects in one of its units.

Most of Amazon’s network effects, like most of its gross margins, come from its AWS business. The AWS platform benefits from both indirect network effects and compatibility and standards. The success of AWS encourages developers and development products like Docker to rely on it as their infrastructure of choice, which makes AWS even more successful (while the emergence of AWS as a standard makes it easier for services built on the platform to connect via API).

### *Product/Market Fit*

Amazon has rarely struggled with product/market fit in its core business. For the most part, because it was tapping into an existing—and thriving—retail market, Amazon was able to leap into hypergrowth almost immediately. Even AWS met with rapid uptake, helped by Amazon’s savvy decision to lead with its simplest product, S3 (Simple Storage Service), before expanding to more complicated ones. It is important to remember that Amazon has had many failures outside its core business. Amazon’s powerful core retail operations didn’t allow it to take over auctions or payments from eBay or PayPal, and its Fire Phone was a costly and fruitless attempt to take on Apple and Android.

### *Operational Scalability*

Amazon has managed operational scalability so well that it might be the best in the world at this task.

On the human side, Jeff Bezos has been able to guide Amazon with a strong and steady hand while allowing business leaders like Andy Jassy, the CEO of AWS, or Jeff Wilke, the global head of the consumer business, to run large portions of the company. This delegation has allowed Amazon to grow to over 541,900 employees as of 2017, making it one of the ten largest employers in the United States.

On the infrastructure side, Amazon has deftly shifted from minimizing infrastructure spending, as it did during its early years by using techniques such as outsourcing logistics to book distributors like Ingram, to becoming one of the world’s great infrastructure companies. Amazon is so good at infrastructure that its fastest-growing and most profitable business (AWS) is all about allowing other companies to leverage Amazon’s computing infrastructure. Amazon also makes money by offering Fulfillment by Amazon to other merchants who envy its mastery of logistics, which ought to strike fear into the hearts of frenemies like UPS and FedEx. In addition to its eighty-six gigantic fulfillment centers, Amazon also has at least fifty-eight Prime Now hubs in major markets, allowing it to beat UPS and FedEx on performance by offering same-day delivery of purchases in less than two hours. Amazon has also built out “sortation” centers that let it beat UPS and FedEx on price by shipping small packages via the United States Postal Service for about $1 rather than paying FedEx or UPS around $4.50.

## *CASE #3: GOOGLE*

### *Market Size*

Google’s market size was dramatically underestimated at the outset. When Google came on the scene, many considered it “yet another search engine” in a market that was already dominated by companies like Yahoo! and Lycos. Even in the unlikely event that Google was able to capture a significant share of the search market, it would still be a niche player in comparison to, say, Yahoo!, which was a portal with major properties like Yahoo! Mail and Yahoo! Finance.

Observers failed to realize two things. First, Google’s business model innovation—the relevance-based, revenue-maximizing, self-service advertising system of AdWords—allowed it to generate far more revenue per search than its predecessors. Second, the importance of search was growing at a faster rate than the Internet as a whole. As the Internet grew and the amount of content increased at a superlinear rate, so did the difficulty of filtering and finding relevant information, making search increasingly important. Combine that effect with the rapid growth of the Internet itself, and the result was a massive market.

Google has astutely expanded the market since then by leveraging the power of its business model to make and monetize key acquisitions like Android, Google Maps, and YouTube.

### *Distribution*

Google’s technology receives most of the credit for the company’s success, and it is impressive. However, this means that Google’s skillful use of the distribution growth factor is often overlooked.

To go from “yet another search engine” to “the last search engine” (as my old friend Peter Thiel put it in his 2014 Stanford lecture “Competition Is for Losers”), Google had to leverage a series of existing networks and partners. For example, Google’s bold deal to power AOL’s search results helped the company grow its search business by orders of magnitude. Later, other distribution bets like the Firefox partnership, the acquisition of Android, and the creation of the Chrome browser all paid off and helped maintain Google’s distribution dominance.

Google also found ways to leverage small partners as well, with its AdSense program for Web publishers feeding more raw traffic into the AdWords machine.

### *Gross Margins*

Google is a phenomenally profitable company, with an enviable margin of 61 percent in 2016. But this profitability didn’t happen by accident or luck; the credit belongs to Google’s AdWords business model. As we discussed in our section on business model patterns, the advertising-supported media model hasn’t worked for the Internet. Yet when Google first emerged, this was the dominant business model being pursued by major players like Yahoo! and Lycos. Google adopted the self-service advertising auction model of Overture, added its own refinement of selecting ads based on considerations of relevance and quality as well as bid prices, and pursued a business model of capturing purchase intent rather than just gathering eyeballs. This purchase intent proved to be far more valuable per unit of traffic, enabling Google to earn fat margins.

Google has since used the financial power of its gross margins to place big bets that other companies might shy away from, such as investing in Android and Chrome, two products that were going up against dominant competitors (Apple’s iOS in mobile phone software and Microsoft and Firefox in Web browsers). Google has also used its margins to fund radical experiments like X (formerly Google X) and Waymo (self-driving cars). These bets may or may not pay off, but even if they fail, Google’s margins give it the ability to recover quickly and keep going.

### *Network Effects*

Google has leveraged network effects quite a bit in its major business lines, though not, ironically enough, in its core search product!

The mobile traffic app Waze is a classic example of a direct network effect. Waze harnesses each user’s location to create a more accurate model of traffic conditions, while also letting drivers easily report events such as traffic accidents, speed traps, and stopped cars on the side of the road. Then Waze makes all that data public to everyone using the app. In other words, the more Wazers on the road, the more accurate that road information becomes. Each additional user creates value for all the previous users.

The Android mobile operating system is a classic example of indirect network effects. Its broad adoption by end users increases the incentives for developers to create Android versions of their applications. The increased availability of useful apps encourages more people to use devices that run on the plaftorm.

YouTube is a classic example of two-sided network effects. YouTube brings together video creators and consumers—the more content is created, the more people show up to consume it. The more consumers who show up, the more incentive there is to create content.

Finally, Google’s G Suite provides a great example of the power of compatibility and standards (ironically enough, much like Microsoft Office, its archrival) as well as local network effects. When users share Google Docs or Google Sheets with others, they lock in anyone who wants to collaborate on those documents to do the same. This is especially common in individual networks like a project team or school. Once some of the school’s teachers start using Google Docs for homework assignments, the pressure builds for all of them to standardize on Google Docs, and for children and parents to adopt it as well. Chris speaks from experience here.

### *Product/Market Fit*

Google got the product/market fit for its core search and AdWords product incredibly right. Even from the start, Google’s search results were better than those of its competitors. But many people don’t realize that it actually took Google a long time to find the right product for the right market. Google started off trying to sell enterprise search appliances, a tool that sits inside a corporate data center, indexing content stored on a company’s servers, then offering a Google search box to find items within that content. Next, Google tried the advertising-supported model by running DoubleClick ads; ironically enough, Google would later buy DoubleClick. Fortunately, Google found product/market fit by refining Overture’s advertising auction model. Google’s AdWords product was so much better at monetizing search through its self-service, relevance-driven, auction system that by the time those competitors managed to play catch-up, Google had amassed the financial resources that allowed it to invest whatever was necessary to maintain product superiority.

Google doesn’t always get product/market fit right (and if it had run out of money before hitting upon AdWords, the search business might have died before ever achieving that fit). This is a reflection of its very intentional product management philosophy, which relies on bottom-up innovation and a high tolerance for failure. When it works, as in Gmail, which was a bottom-up project launched by Paul Buchheit, it can produce killer products. But when it fails, it results in *killed* products, as demonstrated by projects like Buzz, Wave, and Glass. To overcome this risk of failure, Google relies on both its financial strength (which comes from its high gross margins, among other things) and a willingness to decisively cut its losses. For example, when Google bought YouTube (which had clearly achieved product/market fit), it was willing to abandon its own Google Video service, even though it had invested heavily in that product.

Other massively successful companies take a very different approach. In contrast to Google, where new ideas can come from anywhere in the company and there are always many parallel projects going on at the same time, Apple takes a top-down approach that puts more wood behind fewer arrows. Apple keeps its product lines small and tends to work on a single major product at a time. One philosophy isn’t necessarily better than the other; the important thing is simply to find that product/market fit quickly, before your competition does.

### *Operational Scalability*

Unsurprisingly for an engineering-driven organization, Google excels in operational scalability. For one thing, its heavy investment in its own tools and infrastructure has allowed its engineering organization to fine-tune its infrastructure for high performance as the company has grown.

Google has innovated in people scalability as well. While most of Google’s people management practices are smart but relatively straightforward—for example, Google uses smaller teams to work on new products and larger teams to sustain and grow existing products—Google has invested heavily in people analytics and data to determine things like the optimum number of interviews per candidate (no more than five) and to improve practices for recruitment, performance reviews, and so on.

## *CASE #4: FACEBOOK*

### *Market Size*

Market size is one of the key reasons that many failed to appreciate the potential value of Facebook in its early days. At the time, the elevator pitch for Facebook would have been “social network for college students.” This description, which combined a new and unproven product category with a specific (and narrow) audience, made Facebook sound like a niche product. But by the time I invested in Facebook, Mark Zuckerberg’s vision was far broader and more valuable. Mark wanted Facebook to be the default way that people stayed in touch with their friends, which was and is an enormous market. Of course, even when Mark pitched his broader vision, many investors didn’t believe him, much to their later regret.

### *Distribution*

Facebook excelled at distribution. As noted earlier, Facebook’s early focus on college students, which caused some to dismiss it as a niche product, was actually part of an extremely successful distribution strategy. To achieve incredible virality, Facebook would deliberately delay launching at a college campus until over 50 percent of the students had requested it so that local critical mass was reached almost immediately.

Facebook further benefited from leveraging existing friend networks to expand outward from its original college user base. As users experienced the benefits of staying connected via Facebook, they naturally wanted to add their off-line friends to the network.

### *Gross Margins*

Like Google, Facebook started its life without an effective revenue model. But once it discovered the value of sponsored posts within a news feed, Facebook was able to become wildly profitable. About 90 percent of Facebook’s revenue today comes from advertising sales, and the company achieves an astounding 87 percent gross margin.

This gross margin allows Facebook to invest heavily in talent and technology. It has also allowed Mark Zuckerberg to make canny (and expensive) acquisitions, like Instagram and WhatsApp, to become a dominant player in mobile as well as desktop social networks, and also long-term future bets like Oculus.

### *Network Effects*

We’ve already talked about how Facebook leverages classic direct network effects (the more users that join the platform, the greater the value of Facebook to every other Facebook user) and local network effects (once it becomes the dominant social network at a college, it becomes extremely difficult for any other player to pry away Facebook’s users).

Facebook also experiences some helpful indirect network effects thanks to its platform services, such as the Graph API (which allows developers to leverage the Facebook social graph of users and their relationships) and Facebook Connect (which allows users to log in to a Web service using Facebook rather than create a new account for that service).

### *Product/Market Fit*

Facebook achieved product/market fit for its core consumer experience almost immediately, hence its rapid growth. However, part of what makes Facebook a great company and Mark Zuckerberg a great CEO is that Facebook has been able to achieve product/market fit in additional and less obvious areas at other points in the company’s history.

Many people forget how Facebook struggled with the transition from desktop to mobile. Facebook’s initial mobile product provided a slow, suboptimal experience, and adoption of that product was accordingly slow. Fortunately for Facebook, Mark Zuckerberg saw that the market was going mobile and put a moratorium on new feature development in order to focus the entire team on building a new, far superior mobile product. In parallel, he also moved quickly and decisively to acquire Instagram and WhatsApp; when they were announced, both acquisitions were considered pricey, but in hindsight they were clearly bargains. Today, Facebook has over 1.7 billion active mobile users each month, and mobile advertising accounts for 81 percent of the company’s advertising revenue. Over 56 percent of Facebook users access the service exclusively via mobile.

Equally important was Facebook’s ability to achieve product/market fit for its advertisers. When Facebook began, the conventional wisdom was that user-generated content like Facebook would never be able to attract advertisers, who would not want their brands appearing with poor-quality or even inappropriate content. Google’s search model was what worked in online advertising. Facebook was able to overturn the conventional wisdom by developing algorithms to block inappropriate content, and by learning from Twitter’s sponsored update model and incorporating ads into the Facebook News Feed. The news feed model has been especially effective for monetizing mobile usage. In a return to what worked in the print world, advertisements are intermixed with content, and as you page through the magazine or scroll through the feed, you encounter advertisements as part of your normal flow, as opposed to the interruptions of pop-up or takeover ads, or the easily ignored static placement of the traditional banner ad. Yet Facebook’s News Feed is even better for advertisers than a magazine, because Facebook’s core social actions (clicking, liking, sharing) train users to engage with whatever appears in the News Feed, including advertisements!

### *Operational Scalability*

How did Facebook successfully overcome the growth limiter of operational scalability? On the technology side, one of the philosophies that helped Facebook become successful was its famous motto “Move fast and break things.” This emphasis on speed, which came directly from Mark Zuckerberg, allowed Facebook to achieve rapid product development and continuous product improvement. Even today, every new software engineer who joins Facebook is asked to make a revision to the Facebook codebase (potentially affecting millions or even billions of users) on his or her first day of work. However, as Facebook’s user base and engineering team grew to a massive size, Mark had to change the philosophy to “Move fast and break things with stable infrastructure.”

While this new motto might seem self-contradictory, Mark explains that it focuses on a higher-level goal. “The goal is to move fast,” Mark told me. “When we were smaller, being willing to break things allowed us to move faster. But as we grew, the willingness to break things actually started slowing us down, because increasing complexity made it harder and harder to fix things once they broke. By taking the extra time to focus on stable infrastructure, we reduce the impact and time to recover from breaking things, so that we can actually move faster.”

# WHAT COMES AFTER A STRONG, PROVEN BUSINESS MODEL?

If you believe you’ve designed a business model that can support massive growth and value creation, the next step is to decide on your strategy. That’s where strategy innovation comes in.`,
		half: `In Part II of the discussion on Business Model Innovation, it's clear that formulating an innovative business model is crucial for exponential growth, particularly in the Internet era. The dot-com boom of the late 1990s illustrated that simply transplanting existing business models onto the online medium often led to failure. Giants like Microsoft and Time Warner, as well as start-ups like eToys, faltered because they didn't adapt their models to the new medium. However, innovative business models propelled companies like Amazon, eBay, and Google to massive success. These companies redefined their industries with novel strategies—Amazon revolutionized e-commerce, Google monetized search, and Facebook changed social networking. Technological innovation alone wasn't enough; success required innovative products and services underpinned by innovative business models. The narrative underscores that a viable business model must generate financial returns, scale rapidly, and create a sustainable competitive edge, with companies like Amazon, Google, and Facebook exemplifying these principles. The text concludes by emphasizing that while there is no one-size-fits-all business model, most successful ones share traits that maximize growth and minimize limits, highlighting the importance of market size as a key growth factor.

The most basic growth factor for your business model is market size, a fundamental concept for start-ups covered in Pitch Deck 101. If you aim to build a massive company, start by dismissing ideas that target too small of a market. A big market doesn't just mean a large number of potential customers; it also includes efficient channels to reach them. For instance, “everyone in the world” is a large market, but not easily accessible. This complexity in determining market size, or total available market (TAM), creates uncertainty in blitzscaling. However, correctly predicting TAM and investing when others are hesitant can lead to high returns, as demonstrated by Airbnb and Uber. A quickly growing market, even if initially small, can offer tremendous potential and make a sizable market even more appealing.

In Silicon Valley, the fierce competition for venture capital forces entrepreneurs to target large markets to promise substantial returns. Venture capital firms, funding through millions or even billions from entities like pension funds and university endowments, seek high returns that necessitate tripling their investments over a typical span of seven to ten years. This requires VCs to rely on a few exceptionally successful investments, such as Benchmark Capital's $6.7 million investment in eBay in 1997, which returned $5 billion, or a 745 times return. Consequently, VCs focus on ventures that can achieve "venture scale" of at least $1 billion in annual sales, often passing on smaller but otherwise viable businesses. Sam Altman advised Airbnb's Brian Chesky to project a market size in line with their ambitious vision, increasing their pitch from $30 million to $30 billion, which was more accurate. Companies like Uber exemplify this, surpassing initial market estimates through appealing innovations and expanding user bases. Similarly, Amazon's evolution from a bookstore to "the everything store" showcases how market expansion boosts a company's reach and profitability beyond initial projections.

Apple's financial results underscore the importance of distribution in sustaining and scaling a business. In Q1 2017, Apple's personal computer sales hit $7.2 billion, but this made up less than 10% of their $78.4 billion total revenue. As Greylock’s Jerry Chen observes, scaling requires a clear path from modest beginnings to massive outputs. Crucially, effective distribution is often more decisive for success than product quality alone. Dropbox thrived not just because of its great product but due to stellar distribution, a sentiment echoed by its CEO, Drew Houston, who finds many start-ups overlook this. In today’s mobile-first era, distributing apps is more challenging, necessitating innovative methods to reach broad audiences without hefty costs. This has led successful companies like Instagram and WhatsApp to utilize two main distribution strategies: leveraging existing networks and harnessing virality.

When I was at PayPal, distributing our payment service through eBay was a game-changer. By 2000, eBay had ten million registered users, and we leveraged this by creating software that automatically added a “Pay with PayPal” button to eBay listings. This was a hit despite eBay's own Billpoint service, which sellers had to add manually. Similarly, Airbnb, on advice from Y Combinator’s Michael Seibel, successfully tapped into Craigslist by developing technology to seamlessly repost Airbnb listings to the classifieds site, significantly boosting host earnings. This integration was notable because Craigslist lacked an API, making it a technological marvel focused on innovative distribution rather than product changes. However, leveraging existing networks can backfire. Zynga thrived by integrating with Facebook but had to adapt when Facebook restricted game-related posts. Fortunately, Zynga's founder, Mark Pincus, had built a resilient franchise. In contrast, content farms like Demand Media, which relied on Google's search algorithms for traffic, struggled and failed when Google adjusted its algorithms to sideline what it considered “junk” content.

Despite the inherent risks, utilizing existing networks can be crucial for business models, particularly when these networks act as a “booster rocket” that can later be enhanced with virality or network effects.

“Viral” distribution means existing users of a product bring more users, creating a ripple effect similar to how a virus spreads. This virality can happen naturally or through incentives. After launching LinkedIn, our focus was on enhancing organic virality, such as making it easier for users to invite friends via address book import tools, like connecting LinkedIn to Outlook contacts. Unexpectedly, users began using their LinkedIn profiles as their professional online identity, boosting viral growth when others sought to do the same. At PayPal, combining organic and incentivized virality proved effective, with monetary rewards for referrals helping drive rapid growth. Similarly, Dropbox used organic sharing and storage incentives to expand quickly, learning the importance of user retention through rigorous usability testing and refining the user experience. Virality generally suits free or freemium models, and combining organic and incentivized strategies can be powerful, as evidenced by Facebook's college-by-college rollout. Additionally, high gross margins, especially in high-tech businesses, are crucial for funding growth, since they allow more cash flow for expansion due to minimal costs of goods sold, as seen in software and SaaS companies.

In contrast to low-margin "old economy" businesses like agriculture, retail, and food service, Amazon's success in the typically low-margin retail industry is noteworthy, though it now heavily relies on its high-margin Amazon Web Services (AWS). In 2016, AWS accounted for 150 percent of Amazon’s operating income, highlighting retail losses. Most valuable companies have gross margins exceeding 60 percent, such as Google (61%) and Facebook (87%). Amazon's gross margin was 35 percent, higher than General Electric's 27 percent. High gross margins attract investors because they prefer businesses where higher revenues yield higher profit margins, facilitating easier fundraising and lower capital costs. Blitzscalers like Amazon and Xiaomi often prioritize market share over gross margins, with investors valuing potential gross margins over realized ones. High gross margins make it easier to cover operational costs like customer support and fuel faster growth. Lastly, network effects have been instrumental in transforming the most valuable companies from traditional industrial and consumer firms to tech giants like Apple, Google, Microsoft, Amazon, and Facebook, driven by the rise of the Internet and global connectivity.

In our highly interconnected world, companies can achieve extraordinary growth and profitability by harnessing network effects. For simplicity, we’ll define network effects in layman's terms in this book.

A product or service benefits from positive network effects when increased usage enhances its value for all users, creating a "demand-side economy of scale" or "positive externality." These effects generate a positive feedback loop, leading to superlinear growth and value creation. This makes it tough for any node (often customers or users, such as those in fax machine or Facebook networks) to switch to an alternative, resulting in "customer lock-in." This phenomenon often leads to "increasing returns to scale," where one product or company dominates the market and reaps the majority of profits. It's no wonder that smart entrepreneurs and investors are keen on network-effects-based start-ups like eBay, Facebook, and Airbnb. To achieve dominance, understanding and designing network effects into business models is crucial. My colleague Simon Rothman, a leading expert on network effects, cautions against merely adding superficial features like profiles. Instead, true blitzscalers study and implement various types of network effects. NYU professor Arun Sundararajan categorizes these into five broad types on his industrial organization of information technology website.

**Direct Network Effects:** Usage directly increases value. (Examples: Facebook, WeChat, WhatsApp)

**Indirect Network Effects:** Usage promotes complementary goods, boosting the original product’s value. (Example: OS adoption like Windows, iOS, or Android encourages third-party app development, enhancing platform value.)

**Two-Sided Network Effects:** Usage by one user group enhances value for another. (Example: Marketplaces like eBay, Uber, Airbnb)

**Local Network Effects:** Usage by a small user subset increases value for connected users. (Example: Metered call carriers allowing “favorites” with unlimited calls.)

**Compatibility and Standards:** One product’s use encourages compatible product use. (Example: Word’s dominance turned its format into the standard, leading to the decline of competitors like WordPerfect.)

Network Effects Produce and Require Aggressive Growth: The importance of network effects means businesses must aggressively grow and adopt their networks. The impact increases superlinearly; at low scales, network effects dampen user adoption. Companies must hit a “tipping point” where supply meets demand for the product to have value. Businesses like Uber subsidize customers to reach this tipping point quickly. During my time at PayPal, we initially offered free credit card payments to attract users. This tactic led to significant losses, forcing us to charge fees eventually, but our loyal customers accepted the change. For free services like Facebook, shaping user expectations can enhance perceived service value, encouraging adoption. Geoffrey Moore’s *Crossing the Chasm* highlights the difficulty tech companies face transitioning from early adopters to the mainstream. Moore suggests focusing on niche markets and using them as beachheads to expand. This strategy is vital for network effects businesses. Designing products valuable to individual users, regardless of network adoption, reshapes the demand curve. LinkedIn profiles, for instance, provided value independent of network size, by serving as online professional identities. Connectivity fuels Network Effects Businesses.

In today's hyper-connected world, the ease of reaching the tipping point for network effects has significantly increased, supporting and sustaining the network effects that drive market dominance. This high connectivity not only fosters network effects but also helps maintain their influence, ensuring lasting market control.

The Internet has significantly reduced the cost of product and service discovery, allowing companies with a competitive edge to rapidly scale through network effects, resulting in winner-take-all markets. Online platforms like Amazon and Google help popular products rise to the top, and the power of distribution has become crucial to reaching a tipping point. In the Networked Age, companies can avoid traditional growth barriers, such as overhead from rapid organizational expansion, by leveraging networks, as Apple did with Foxconn. This scalability allows tech giants like Google to continue growing at high rates and invest in future innovations, effectively moving from one product S-curve to another, like Apple transitioning from music players to smartphones. Network effects, while not universal, are integral to Silicon Valley's success, driven by a culture of business model innovation. Successful entrepreneurs design business models that leverage these effects for rapid growth, as seen with Craigslist. The concept of "blitzscaling" helps startups reach a tipping point faster, but overcoming growth limiters like product/market fit and operational scalability is essential. Product/market fit, a concept emphasized by Marc Andreessen, involves finding a nonobvious market opportunity that companies can dominate. Entrepreneurs are encouraged to use network intelligence to validate their ideas, though true product/market fit is ultimately proven by user adoption. On the other hand, operational scalability is crucial for handling explosive growth, and designing models that address human limitations and logistical challenges can prevent high-class problems from hindering success.

Managing a small founding team of four requires overseeing relationships between six pairs, but increasing the team to six members escalates the number of relationships to fifteen pairs, a 150% rise in complexity. This exponential increase underscores the challenges of operational scalability as team size grows. One solution is to adopt a business model that minimizes the need for a large workforce. For instance, WhatsApp founders Jan Koum and Brian Acton leveraged a freemium model and network effects to grow rapidly with just forty-three employees, achieving a ratio of over ten million users per employee. Another strategy is outsourcing, exemplified by Airbnb's initiative to enhance listing photos through freelance photographers, which evolved from manual efforts by founders to automated management of a global network. Despite these strategies, sustaining long-term success typically necessitates a substantial workforce, though innovative management techniques can help companies navigate this growth. Future discussions will delve into these innovations and how they support scaling operations.

The other major challenge of operational scalability arises from the pressure of expanding the nonhuman infrastructure of a business. No matter how much demand you drum up, it's pointless if your infrastructure can't support it. These limitations can be fatal to a company’s ambitions, as illustrated by the social networks Friendster and Twitter.

Friendster, the first mainstream online social network before Facebook, launched in March 2003, quickly amassing millions of users. Its founder, Jonathan Abrams, even appeared on Jimmy Kimmel Live! However, the rapid growth overwhelmed Friendster's infrastructure, leading to long load times, which allowed MySpace to eclipse it by 2005. MySpace, however, eventually lost to Facebook. Twitter faced similar struggles with its famous "Fail Whale" error during high-traffic events such as Michael Jackson's death in 2009 and the 2010 World Cup, but managed to rearchitect its systems, overcoming these issues by the 2012 US presidential election. A significant factor behind the recent surge in web company growth has been Amazon Web Services (AWS), which has enabled companies like Dropbox to scale their infrastructure efficiently without building their own.

AWS exemplifies how Amazon has turned operational scalability into a competitive advantage by leveraging "the power of modularity," a concept articulated by Carliss Baldwin and Kim Clark in their book, *Design Rules, Vol 1: The Power of Modularity*. This principle allows Amazon and its customers to create complex products from smaller, standardized components, not just in software but across its business, enhancing flexibility and adaptability. On the hardware side, China plays a similar role, enabling hardware start-ups to rapidly scale by utilizing its manufacturing capabilities. For instance, Nest managed to grow efficiently with only 130 employees by outsourcing manufacturing, leading to its $3 billion acquisition by Google. Conversely, Tesla Motors has faced growth limitations due to its intricate manufacturing process, resulting in slower production rates and long back orders, highlighting the challenge of scaling to meet high demand despite having an award-winning product.

Whether by design or not, rapidly growing companies often follow proven patterns that leverage growth factors and circumvent growth limiters. While these patterns will be detailed further below, it's crucial to recognize that they are principles, not exact recipes. Adopting these patterns alone won't guarantee an innovative business model, but comprehending them equips entrepreneurs with a set of valuable role models.

Not all business models produce massively profitable businesses, despite following proven patterns. For example, open-source software, which emerged during the dot-com era and has significantly impacted the technology stack, exemplifies business model innovation through free, community-created software. It captures a large market, benefits from network effects, and utilizes distributed volunteer contributions, avoiding scalability issues linked to large employee organizations. However, even Red Hat, the most successful open-source business with a $15 billion market cap after two decades, shows that while open source drives engagement, it doesn't generate massive profits. To qualify as a proven pattern, a model must demonstrate that multiple businesses can achieve significant value with it. Therefore, we've compiled a list of such proven patterns to inspire your business model innovations. **PROVEN PATTERN #1: BITS RATHER THAN ATOMS**.

### The Power of Bits, Platforms, and Freemium Models

Google and Facebook exemplify bits-based businesses, focusing on electronic bits rather than physical atoms, which makes it easier for them to serve a global market and achieve large scales. Such businesses benefit from high gross margins due to lower variable costs and can innovate rapidly through continuous iteration. This is illustrated by WhatsApp's small team managing global operations. George Gilder’s 1990 prediction in "Microcosm" about the ascendance of intellectual resources over physical ones was further validated by Marc Andreessen in 2011, highlighting software-driven giants like Amazon, Netflix, and LinkedIn. Platforms have magnified their value exponentially in the Networked Age, achieving immediate global distribution and seamless API-based transactions, thus cementing competitive advantages through network effects. Dominant platforms like iTunes, Amazon, and Apple's iOS ecosystem benefit from high-margin revenues that can be reinvested to enhance their offerings. Additionally, the freemium model, supported by behavioral insights from Dan Ariely’s research, unveils how offering products for free can alter consumer choices significantly, driving widespread adoption and long-term engagement.

The remarkable power of offering free products can drive distribution and virality by helping achieve the critical mass needed to unleash network effects, as illustrated by LinkedIn's strategy with free basic accounts. By reaching a significant user base, even free users can be monetized effectively, as demonstrated by Facebook's lucrative targeted advertising revenue. However, when the advertising model isn't suitable, especially for educational services, the freemium model offers a solution. Coined by venture capitalist Fred Wilson in 2006, freemium emerged from the 1980s shareware concept and utilizes a free version to attract users and a paid version to monetize them. Dropbox exemplifies this by offering 2 GB free storage, converting a fraction of users to paid plans for additional storage. Another successful model is marketplaces, with giants like Google, eBay, Alibaba, and Airbnb. These platforms thrive on two-sided network effects, creating liquidity where buyers and sellers can efficiently connect. Once a marketplace achieves this liquidity, it triggers a positive feedback loop, making it difficult for new entrants to capture market share.

Marketplaces offer significant advantages beyond the obvious network effects. By enabling a liquid market where supply and demand dynamically price transactions, they ensure more efficient pricing and greater value creation through more transactions. Illiquid markets, in contrast, often result in mispricing and reduced sales. A prime example is Google’s AdWords marketplace, which allows anyone to bid on targeted keywords, democratizing access to global distribution for even the smallest businesses. This contrasts with traditional advertising, where large clients pay exorbitant sums for TV ads during prime time, like the Super Bowl. Google’s system favors ads that generate the most paid click-throughs, showing consumers the most relevant ads without the overhead of intermediaries. By dealing in virtually unlimited, low-cost ad space, Google increases its gross margin. The Networked Age has amplified the value of marketplaces, allowing them to tap into a global market without the limitations of physical infrastructure, thereby overcoming traditional growth constraints.

When Salesforce.com introduced its on-demand CRM product, many questioned the viability of the SaaS model, which differed significantly from the traditional permanent license and on-premise software approach. SaaS shifted the payment structure to subscriptions and necessitated 24/7 data center support, affecting cash flow and staffing needs. Despite initial concerns, SaaS like Salesforce.com and Workday thrived due to broader market reach and more efficient distribution compared to older, on-premise models. SaaS’s success extends beyond enterprise software, influencing industries like music and video streaming, exemplified by Spotify, Pandora, Netflix, and Hulu, that benefit from lower overhead and predictable revenue. This predictability allows for substantial long-term investment, as seen with Netflix’s $6 billion content investment. Additionally, digital goods have emerged as profitable ventures within SaaS, such as LINE’s sticker sales and in-game purchases in the video game industry, both of which boast high margins and scalability.

One of the most underrated yet powerful patterns is the news feed, which has significantly contributed to the success of companies like Facebook, Twitter, Instagram, and Slack. Facebook's innovation with the news feed has driven user engagement, advertising revenue, and long-term retention, making it a world-class business despite attracting users initially through network effects. The model's success lies in its ability to monetize users' desire for amusement by strategically targeting advertisements based on their interests and engagement history, unlike other feed-based products like RSS readers. This capability has positioned Facebook's News Feed as a leader in online advertising, second only to Google's AdWords, which benefits from capturing active consumer intent. Even Twitter's continued relevance and massive scale can be attributed to the power of the news feed model, underscoring the impact of business model innovation over mere product or technology changes.

Beneath the established patterns of business model innovation lie fundamental principles that not only help refine these patterns but also pave the way for creating new ones. Although these principles are not business models in their own right, they often drive the technological advancements that make business model innovation possible.

### UNDERLYING PRINCIPLE #1: MOORE’S LAW

Moore’s Law, coined by Intel cofounder Gordon Moore, is the principle that has fundamentally driven the success of Silicon Valley and the global tech industry. Initially stated in 1965, it observed the annual doubling of transistors on a silicon chip, later adjusted to every eighteen months. Though it originally referred to transistor density, Moore’s Law now predicts the doubling of computing power every eighteen months, a growth currently fueled by multicore, multithreaded computing. The ultimate limit of Moore’s Law seems to be human ingenuity rather than physics. This principle has consistently spurred technological innovation and business models, transitioning from gigantic mainframes to personal tech like smartphones. It’s seen similar impacts on network bandwidth, advancing the Web from text to multimedia, and potentially, VR in the future. Visionary entrepreneurs like Reed Hastings of Netflix have not just followed Moore’s Law but anticipated its progression. Despite technological limitations in 1997, Hastings foresaw streaming TV via the Internet, initially leveraging DVDs as a bridge to his ultimate vision.

Hastings realized that movie DVDs, then selling for around $20, were compact and durable—perfect for a movie-rental-by-mail business. Inspired by an assignment from a computer science class, he saw how technological innovation could enable a new business model that differed from Blockbuster's VHS tape rentals. VHS tapes, being bulky and fragile, were impractical for mail rental. Instead, Netflix utilized DVDs to offer a subscription service with unlimited movies for $20 per month, avoiding the late fees dreaded by Blockbuster customers. Although Netflix initially hinged on mailing DVDs, Hastings envisioned streaming as the future. Despite underestimating the timeline of streaming’s viability, advancements in computer power and internet bandwidth eventually made on-demand television feasible, transitioning Netflix into a dominant streaming service by 2012. Today, Netflix is synonymous with online television, creating "binge watching" and leveraging its subscription model to fund original content like *Stranger Things* and *Beasts of No Nation*. Unlike traditional TV, which bets on broadly appealing pilots, Netflix’s personalized on-demand service curates content based on viewer habits, ensuring satisfaction and reducing cancellations. This personalized approach, empowered by Hastings' patience with Moore's Law, transformed Netflix into one of the most successful media companies, proving that with persistence, a revolutionary idea can evolve from an improbable vision into reality.

Blitzscaling companies harness the power of automation because, if feasible, computers outperform humans in speed, cost, and reliability. This advantage is further amplified by Moore’s Law, which states that computing power doubles every eighteen months, contrasting human evolution's sluggish pace. For instance, journalist Jan Vermeulen highlighted a staggering improvement between the 1977 Apple II and the 2014 iPhone 5S, noting a 2,600-fold increase in clock speed and 16,384 times more RAM, all within one human generation. To illustrate further, if human athletic performance had matched this growth, swimming speeds would be unfathomably faster; however, actual records show only a modest 11 percent improvement. This disparity underscores the power of automation, which enhances not only consumer products such as the iPhone but also optimizes internal operations in companies like Amazon and Google, driving productivity and efficiency to unprecedented levels.

### UNDERLYING PRINCIPLE #3: ADAPTATION, NOT OPTIMIZATION

At a higher level of abstraction, successful scale-ups prioritize adaptation over optimization. Unlike the static, giant assembly lines of Detroit automakers dating back to Henry Ford’s Model T, modern Silicon Valley companies like Amazon and Facebook embrace continuous improvement and constant experimentation. Amazon, for instance, didn’t just perfect its retail capabilities, but diversified into new markets like AWS. Similarly, Facebook evolved from a text-based social network on desktops to an image- and video-rich platform on smartphones. This adaptive approach is crucial for achieving product/market fit in rapidly changing environments.

### UNDERLYING PRINCIPLE #4: THE CONTRARIAN PRINCIPLE

My friend Peter Thiel eloquently discusses the power of being contrarian in his book *Zero to One*.

Whenever I interview someone for a job, I like to ask, “What important truth do very few people agree with you on?” This question is deceptively simple, posing both intellectual and psychological challenges. The knowledge taught in schools is commonly agreed upon, and stating an unpopular truth requires courage. Contrarian thinking, often crucial for creating valuable technology companies, gives a significant advantage because it allows a company to achieve critical scale without much competition. Examples like Amazon, Google, and Facebook show that their success stemmed from pursuing dismissed opportunities. Being contrarian means smart people disagree with you; remember Airbnb’s founders, who faced skepticism from investors. This happens because innovation involves unproven ideas. In this book, we provide tools to design and evaluate innovative business models, while cautioning against bad pattern matching, like “Uber for Pets.” Effective pattern matching involves understanding mechanisms of action, such as Airbnb’s large market and viral city-to-city growth. Let’s practice analyzing billion-dollar business models using our principles of business model innovation.

Sure, here's the summarized version in markdown:

---

In CASE #1: LINKEDIN, the professional networking giant successfully navigated a complex landscape to become a leading social platform for career-oriented individuals. Distinguishing itself from other social media, LinkedIn focused heavily on creating value through professional engagement and information sharing. The platform's unique selling proposition lies in its capacity to connect users with potential employers, foster industry-specific content, and provide tools for career development. Remarkably, LinkedIn's approach to monetization—such as premium subscriptions and advertising—has been a pivotal aspect of its growth strategy. This model enabled them to build a robust revenue stream while maintaining the core essence of professional networking. By continually evolving and integrating new features tailored to professional needs, LinkedIn has cemented its status as an indispensable tool in the professional world.

---

When we launched LinkedIn in 2002, the dot-com bust had left many people considering the consumer Internet industry as dead. Venture capitalists were highly reluctant to fund rapid growth with millions of dollars. However, I saw a significant opportunity and managed to steer LinkedIn through the initial start-up growth phase until we could secure the capital needed to truly blitzscale. This is the story of how we made it happen. Market Size.

LinkedIn's foundational insight was recognizing the Internet's shift from anonymous cyberspace to a platform reflecting real-world identities, necessitating a professional online identity. This idea was then unconventional, but my cofounders and I saw a significant opportunity in targeting “all white-collar professionals.” To raise funds for LinkedIn's growth, we needed to demonstrate an effective distribution strategy, but early investors misunderstood us as a "Friendster for business relationships," which was an inaccurate comparison. Leveraging my PayPal reputation, I managed to secure initial investments, and we bootstrapped by setting up in a friend’s failing startup. Our distribution strategy hinged on organic virality, encouraging users to invite their contacts via email to expand their networks, but this alone wasn't sufficient. We innovated with tools like the email address book importer to boost invitations and notify users when their contacts joined, ultimately growing to one million users and securing further investment from Greylock.

Gross margins were crucial for LinkedIn as our user growth couldn’t match the leading social networks like MySpace or Facebook, which had far more users. We argued our professional users were more valuable and needed to demonstrate significant high-margin revenues. Initially, we tried a freemium subscription model, limiting free users' InMail requests and offering premium upgrades, which made us cash-flow profitable but not compellingly so. The game changer came when we realized companies would pay for access to scan LinkedIn profiles for job candidates. This lead us to offer an enterprise subscription product, proving it could generate significant high-gross-margin revenues and gave us the confidence to blitzscale. LinkedIn's long-term value hinged on network effects, leveraging direct and two-sided effects, and becoming a standard for professional identities. Direct effects came from every new user adding value, while two-sided effects attracted more employers, enhancing LinkedIn's job-hunting utility. This combined with LinkedIn becoming integral to professional identities, created a formidable strategic moat. Achieving product/market fit for our enterprise product was pivotal; we quickly got market feedback by hiring a salesperson, equipped with mock-ups, to engage potential customers who all wanted to buy it.

At LinkedIn, we encountered two major operational scalability challenges during our blitzscaling phase. The first was the need to develop, maintain, and update both a consumer product and an enterprise product simultaneously, since each was essential for the success of the other. This unconventional and inefficient approach required significant effort from our engineering team. The second challenge was the rapid scaling of our salesforce, even as the product they were selling was still under development. This huge task was managed by our CEOs, Dan Nye and later Jeff Weiner, along with their teams. To ease the scaling process, we utilized technology like our "Merlin" tool, which made sales operations more efficient by automating tasks. Merlin helped salespeople by analyzing usage patterns, recommending which companies to contact, detailing their use of LinkedIn, and generating personalized sales decks.

Jeff Bezos’s ambition for Amazon was to exploit the limitless space of digital shelves to create a store where customers could purchase virtually anything. Starting with books, a substantial market with products ideal for e-commerce due to their durability, standard sizes, and wholesale distribution availability, Amazon has successfully diversified into numerous other categories. Today, it almost achieves Bezos’s “everything store” vision, though cars are still an exception. Retail, being a massive market, has enabled Amazon to seize a substantial share, further expanded by the creation of Amazon Web Services (AWS), which supplies much of the Internet’s computing power, bandwidth, and storage, even for giants like Netflix. Amazon innovatively leveraged the Internet as a distribution platform by initiating the first effective affiliate program, Amazon Associates, turning numerous third-party websites into strong distribution channels. Despite struggling with low gross margins—common in the retail industry and exacerbated by Amazon’s commitment to low prices—Amazon remains financially viable, with profitable North American operations, though these are offset by losses in Asia.

Amazon's retail business, despite low gross margins, seems to be part of a long-term strategy geared towards high gross margins. Dominating e-commerce, with 44% of US sales in 2016, Amazon's retail operations are split into traditional retail and a lesser-known marketplace for third-party sellers. The marketplace, where sellers use Amazon's logistics for a fee, resembles high-margin eBay more than low-margin Walmart. Jeff Bezos highlighted that nearly 50% of purchases come from third-party sellers. The retail side might act as a loss leader, contrasted by the high-margin AWS, which in 2016 generated over $3 billion in operating income and captured more than 40% of the cloud infrastructure market. While Amazon's network effects are weaker compared to platforms like Facebook, its "flywheel" model driving economies of scale is effective, though linear compared to the superlinear network effects. AWS benefits significantly from network effects, standardization, and compatibility, bolstering its success. Historically, Amazon has rarely struggled with product/market fit in its core businesses, swiftly achieving hypergrowth. However, it has seen notable failures outside its core, such as the Fire Phone. Operational scalability remains an area where Amazon excels, arguably leading globally.

Jeff Bezos' leadership has allowed Amazon to flourish by empowering leaders like Andy Jassy, CEO of AWS, and Jeff Wilke, global head of consumer business, to manage vast parts of the company, contributing to Amazon's growth to over 541,900 employees by 2017. Initially minimizing infrastructure costs by outsourcing logistics, Amazon transformed into a top infrastructure company, excelling in logistics and computing infrastructure, as demonstrated by AWS. AWS represents Amazon's most profitable segment, helping other companies utilize Amazon’s advanced infrastructure. In logistics, Amazon’s Fulfillment by Amazon services pose a significant competitive threat to entities like UPS and FedEx. With eighty-six massive fulfillment centers and fifty-eight Prime Now hubs, Amazon offers superior same-day delivery and cost-effective shipping solutions. It leverages “sortation” centers that utilize USPS for cheaper shipping, dramatically undercutting UPS and FedEx's prices.

When Google entered the scene, it was seen merely as another search engine among giants like Yahoo! and Lycos, with expectations that even a significant market share would still leave it in the shadows of Yahoo!'s comprehensive portal services. However, people overlooked two crucial aspects. First, Google's innovative AdWords model—a relevance-based, revenue-maximizing, self-service advertising system—enabled it to generate significantly higher revenue per search than its predecessors. Second, as the Internet grew exponentially, the task of finding relevant information became increasingly vital, enhancing the importance of search itself. This growth, coupled with the explosion of online content, led to a massive market. Google strategically expanded this market by harnessing the strength of its business model to monetize key acquisitions such as Android, Google Maps, and YouTube.

Google’s advanced technology is often credited for its success, but its strategic use of distribution channels also played a crucial role in transforming it from "yet another search engine" to "the last search engine," as Peter Thiel described in his 2014 Stanford lecture. Significant partnerships, like the deal to power AOL’s search results, boosted Google’s growth. Further deals, such as the Firefox partnership, acquiring Android, and launching the Chrome browser, maintained its distribution dominance. Additionally, the AdSense program for Web publishers reinforced its AdWords machine. Google's remarkable 61 percent margin in 2016 wasn't a stroke of luck but a result of its innovative AdWords model, which capitalized on user purchase intent rather than just attracting eyeballs. This enabled Google to earn significantly higher margins per unit of traffic. These robust margins allowed Google to make bold investments in products like Android and Chrome, and fund experimental projects like X and Waymo. Although Google’s core search product hasn’t directly leveraged network effects, many of its other major business lines have.

The mobile traffic app Waze exemplifies a direct network effect; it uses each user’s location data to improve traffic accuracy and facilitates easy reporting of incidents like accidents or speed traps, with all data shared publicly. The app’s value increases with more users. In contrast, the Android mobile operating system showcases indirect network effects, where high user adoption motivates developers to create Android apps, attracting even more users to the platform. YouTube illustrates two-sided network effects by connecting video creators and viewers, where more creators draw in more viewers, and vice versa. Google’s G Suite demonstrates the power of compatibility, standards, and local network effects, similar to Microsoft Office. Users sharing Google Docs or Sheets within a project team or school create pressure for wider adoption among colleagues, students, and parents. This practical experience underscores the importance of achieving product/market fit.

Google nailed the product/market fit with its core search and AdWords products, which vastly outperformed competitors. However, it wasn't an overnight success—initially, Google attempted to sell enterprise search appliances and later tried advertising-supported models by running DoubleClick ads, which it eventually acquired. The breakthrough came with refining Overture's advertising auction model, making AdWords a powerful self-service, relevance-driven system. Google's intentional product management, emphasizing bottom-up innovation and high tolerance for failure, led to major successes like Gmail but also notable failures, including Buzz, Wave, and Glass. Financial strength and a willingness to cut losses enable Google to navigate these failures effectively—illustrated by its pivot from Google Video to acquiring YouTube. Contrasted with Apple’s top-down, focused product development, Google's approach incubates many parallel projects, leveraging operational scalability honed through substantial investments in infrastructure. Each company's strategy emphasizes the importance of finding product/market fit swiftly to stay ahead of the competition.

Google has excelled in people scalability too. Though many of Google's people management strategies are intuitive, like using smaller teams for new products and larger ones for scaling existing products, they've made a significant investment in people analytics. This data-driven approach helps pinpoint the perfect number of interviews per candidate (no more than five) and refines recruitment and performance review practices. 

**CASE #4: FACEBOOK Market Size**

Market size was a significant factor that many underestimated regarding Facebook's potential in its early days. Initially perceived as a “social network for college students,” it seemed like a niche product in an unproven category with a narrow audience. However, when I invested in Facebook, Mark Zuckerberg had a much broader and valuable vision: making Facebook the default way people stayed in touch with friends, targeting a vast market. Despite pitching this expansive vision, many investors were skeptical and would later regret it. Facebook excelled at distribution by focusing initially on college campuses, ensuring a critical mass before launching and leveraging existing friend networks to expand. This strategy spurred incredible virality as users naturally invited their offline friends to join. Although Facebook initially lacked an effective revenue model, it became immensely profitable through sponsored posts in the news feed, with advertising sales now constituting about 90% of its revenue and an impressive 87% gross margin. This financial success enabled significant investments in talent, technology, and strategic acquisitions like Instagram, WhatsApp, and future bets like Oculus, solidifying its dominance in both mobile and desktop social networks.

Facebook's success hinges on its mastery of direct and local network effects, boosting its value as more users join, and the difficulty competitors face in prying those users away. Additionally, indirect network effects from platform services like the Graph API and Facebook Connect enhance its ecosystem. Achieving product/market fit from the start, Facebook's rapid expansion was marked by overcoming significant challenges, including the transition from desktop to mobile, which initially lagged due to a slow mobile experience. Zuckerberg's decisive focus on mobile improvements and acquisitions such as Instagram and WhatsApp paid off, with mobile users now making up a significant portion of Facebook's usage and revenue. Advertiser product/market fit was crucial, as Facebook's superior content algorithms and innovative News Feed ads countered conventional wisdom and effectively monetized mobile engagement. Operationally, Facebook's "Move fast and break things" motto drove quick advancements, though it evolved to include stable infrastructure to handle the growing complexity. As the platform developed, a dual emphasis on speed and stability allowed continued rapid innovation. With a solid business model in place, future strategy necessitates continued innovation to sustain growth.`,
		quarter: `In Part II of the discussion on Business Model Innovation, the focus is on the importance of innovative business models for exponential growth, especially in the Internet era. The dot-com boom showed that traditional business models often failed online, with companies like eToys and giants like Microsoft struggling. In contrast, Amazon, eBay, and Google thrived by shaping sectors with revolutionary business approaches. Beyond technological advancements, success involves innovative products and services supported by effective business models that ensure financial returns, rapid scaling, and sustained competitive edges. Market size is critical; targeting large markets can predict growth and investment returns, highlighted by Airbnb and Uber's market expansions. In Silicon Valley, VCs prioritize investments that promise at least $1 billion in annual sales, passing over smaller ventures for higher returns, as seen with eBay's success. Effective distribution is paramount, with companies like Dropbox thriving due to exceptional distribution strategies. Leveraging existing networks, such as PayPal with eBay or Airbnb with Craigslist, can jumpstart growth. However, reliance on these networks can backfire, requiring resilience, as seen with Zynga's Facebook integration. Virality also plays a key role in growth, with companies like LinkedIn and Dropbox achieving success through organic and incentivized virality. High gross margins are crucial for funding growth, evident in tech giants like Google and Facebook, contrasting with lower-margin industries. Network effects further drive growth by increasing product value with usage, creating customer lock-in and market dominance. Understanding and embedding network effects is essential, as demonstrated by successful companies like eBay, Facebook, and Airbnb.

### Network Effects & Scalability in Tech Business Models

Network effects amplify product value as user bases grow. Direct network effects make platforms like Facebook more valuable with increased usage, while indirect effects enhance products like Windows through complementary goods. Two-sided network effects, as seen in marketplaces like Uber, connect different user groups for mutual benefit. Local network effects, such as unlimited calls to favorites, and compatibility standards, like Microsoft's Word format, also drive product adoption. To thrive, businesses must aggressively expand to reach a critical mass where supply meets demand. My experience at PayPal, initially offering free credit card payments, highlights the need for such growth strategies despite early losses. Geoffrey Moore's advice to target niche markets is critical for crossing the chasm from early adopters to mainstream users. Connectivity today greatly eases reaching these tipping points, fostering dominant, winner-take-all markets. Efficient scaling, leveraging outsourcing like Airbnb with freelance photographers, or platforms like AWS, as Dropbox did, helps manage rapid growth. Challenges like operational scalability and infrastructure demands, exemplified by Friendster's collapse and Twitter's "Fail Whale" phase, underscore the need for robust systems to support surging user bases. Companies like Amazon and Nest have capitalized on modularity and outsourced manufacturing to maintain flexibility and meet demand, whereas Tesla's complex production lines illustrate the difficulties of scaling physical products. Rapidly growing ventures often emulate proven patterns, emphasizing principles over rigid blueprints, helping entrepreneurs navigate the fast-paced tech landscape.

Despite adhering to established business models, not all companies achieve massive profits. Take open-source software, for instance; though it emerged in the dot-com era and revolutionized the tech stack with free, community-driven innovations, it still struggles with profitability. Red Hat, the most successful open-source entity, reached a $15 billion market cap after two decades but didn't turn massive profits. Proven patterns that create substantial value for multiple businesses are crucial for inspiring business model innovation. One such pattern is "Bits Rather Than Atoms," as seen with Google and Facebook, which leverage lower variable costs and rapid innovation cycles to serve a global market. Platforms like iTunes and Amazon amplify value through network effects and seamless transactions, while the freemium model, popularized by Fred Wilson, drives adoption with free basic services leading to monetization through premium options, such as Dropbox's storage upgrades. Marketplaces also thrive by efficiently connecting buyers and sellers, exemplified by Google’s AdWords, and overcoming growth constraints of physical infrastructure. SaaS models, like Salesforce, have transitioned from traditional on-premise solutions to subscription-based services, benefiting from broader reach and predictable revenue. News feeds, introduced by Facebook, have driven engagement and advertising revenue, proving the power of business model innovation. Underlying all these patterns are fundamental principles like Moore’s Law, which fuel technological advancements and enable business model innovations. 

---

*Inspired by these proven patterns, we encourage you to innovate and refine your business models, leveraging the unique advantages each one offers.*

Moore's Law, named after Intel cofounder Gordon Moore, is a foundational principle that has fueled the success of Silicon Valley and the global tech sector. Initially articulated in 1965, it noted the annual doubling of transistors on a silicon chip, later refined to every eighteen months. This concept now extends to predicting a doubling of computing power within this timeframe, thanks to advances like multicore and multithreaded computing. The relentless pace of Moore's Law is powered by human ingenuity, continually driving technological breakthroughs and innovative business models, transitioning from large mainframes to personal technology such as smartphones. Visionaries like Reed Hastings of Netflix have not just adhered to Moore's Law but anticipated its future implications. Despite the technological constraints of 1997, Hastings foresaw the potential for internet-based TV streaming and used DVDs as a precursor to this vision, creating a movie-rental-by-mail business that avoided late fees and harnessed Moore's Law to later transition to streaming. By 2012, Netflix became a leading streaming service, introducing concepts like "binge watching" and funding original content like "Stranger Things." The personalized, on-demand nature of Netflix's service, driven by viewer habits, underscores Hastings' strategic patience with Moore's Law, ultimately transforming Netflix into a media juggernaut. Blitzscaling companies leverage automation, which, powered by Moore's Law, dramatically outpaces human capabilities in speed, cost, and reliability. The transformation from the 1977 Apple II to the 2014 iPhone 5S exemplifies this growth with staggering improvements in clock speed and RAM. Such advancements highlight automation's role in enhancing consumer products and optimizing corporate operations, significantly boosting productivity and efficiency in companies like Amazon and Google.

### UNDERLYING PRINCIPLE #3: ADAPTATION, NOT OPTIMIZATION

In today's fast-paced world, the key to achieving sustainable development is adaptation, not just optimization. While optimization focuses on making current systems more efficient, adaptation emphasizes flexibility and resilience, allowing systems to evolve and thrive amidst changing conditions. This principle reminds us that clinging to rigid, optimized solutions can be counterproductive in the face of unforeseen challenges. By fostering an adaptive mindset, organizations and individuals can better navigate the complexities of modern life and ensure long-term success. Therefore, it's crucial to prioritize adaptation over mere optimization to cope with continuous change and uncertainty.

At a higher level of abstraction, successful scale-ups prioritize adaptation over optimization. Unlike the static, giant assembly lines of Detroit automakers dating back to Henry Ford’s Model T, modern Silicon Valley companies like Amazon and Facebook embrace continuous improvement and constant experimentation. For example, Amazon diversified beyond retail into new markets like AWS, and Facebook transformed from a text-based social network to a rich media platform on smartphones. This adaptive approach is crucial for achieving product/market fit in rapidly changing environments. UNDERLYING PRINCIPLE #4: THE CONTRARIAN PRINCIPLE, as eloquently discussed by my friend Peter Thiel in his book *Zero to One*, hinges on the power of being contrarian.

Whenever I interview someone for a job, I like to ask, “What important truth do very few people agree with you on?” This seemingly simple question challenges both intellectually and psychologically. Courage is needed to present an unpopular truth in a world where school-taught knowledge is widely accepted. Contrarian thinking is key in creating valuable tech companies, giving them an edge to achieve scale without much competition. Icons like Amazon, Google, and Facebook succeeded by pursuing opportunities dismissed by others. Innovation inherently means smart people will disagree with you, as Airbnb’s founders experienced skepticism from investors. This book offers tools to design and evaluate innovative business models, advising against shallow pattern matching like “Uber for Pets.” Effective pattern matching demands understanding the mechanism of action, exemplified by Airbnb’s massive market and viral growth from city to city. Let’s develop skills to analyze billion-dollar business models utilizing these principles of business model innovation.

LinkedIn's journey to becoming a premier professional networking platform was a masterclass in navigating a complex market and recognizing the shift towards online professional identities. Launched in 2002 amidst the dot-com bust, LinkedIn differentiated itself by emphasizing professional engagement and career development tools, and leveraging organic virality for growth. Early monetization efforts included freemium subscriptions and enterprise products, enabling revenue generation while staying true to its core mission. The company overcame initial funding hurdles, convincing investors of its unique value and eventually securing significant investment from Greylock. Scaling operationally, LinkedIn tackled challenges in maintaining dual focus on consumer and enterprise products, and rapidly expanding its salesforce, aided by technological innovations like the Merlin tool. This strategic approach, paired with the network effects of user growth and employer engagement, solidified LinkedIn’s place in the professional ecosystem. Similar strategic insights were seen in other tech giants like Amazon, Google, and Facebook, each capitalizing on market size, network effects, and innovative monetization to dominate their respective fields.`,
	},
};

export function get(url: string) {

	return content[url];
}
